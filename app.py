import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm # Necesario para el Q-Q plot
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler, LabelEncoder
import time
import warnings
from scipy import stats

from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image, Preformatted
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from reportlab.lib.units import inch

import scikit_posthocs as sp # Nueva importaciÃ³n

import io
import base64
import os

warnings.filterwarnings('ignore')


# --- Language Configuration ---
LANGUAGES = {
    "es": {
        "page_title": "EvaluaciÃ³n de Modelos ML - ValoraciÃ³n Nutricional",
        "app_title": "ğŸ§¬ EvaluaciÃ³n de Modelos ML para ValoraciÃ³n Nutricional AntropomÃ©trica",
        "app_description": "---",
        "sidebar_title": "âš™ï¸ ConfiguraciÃ³n",
        "select_language_label": "Selecciona Idioma:",
        "data_load_section": "Carga de Datos",
        "data_loaded_success": "âœ… Datos cargados correctamente",
        "records_label": "ğŸ“Š Registros:",
        "columns_label": "ğŸ“‹ Columnas:",
        "file_not_found_error": "No se encontrÃ³ el archivo 'datos_pacientes2.csv' en la carpeta actual.",
        "file_load_error": "Error al cargar el archivo: {}",
        "dataset_info_section": "ğŸ“‹ InformaciÃ³n del Dataset",
        "first_rows_label": "**Primeras 5 filas:**",
        "statistical_info_label": "**InformaciÃ³n estadÃ­stica:**",
        "target_variables_section": "ğŸ¯ EvaluaciÃ³n de Variables Objetivo",
        "start_evaluation_button": "ğŸš€ Iniciar EvaluaciÃ³n de Modelos",
        "preprocessing_spinner": "Preprocesando datos...",
        "column_not_found_error": "La columna '{}' no se encontrÃ³ en los datos procesados.",
        "data_split_section": "ğŸ—‚ï¸ DivisiÃ³n de Datos para {}",
        "train_percent": "**Porcentaje de datos de entrenamiento:** {}%",
        "test_percent": "**Porcentaje de datos de prueba:** {}%",
        "model_training_section": "ğŸ¤– Entrenamiento de Modelos para {}",
        "training_spinner": "Entrenando modelos para {}...",
        "training_complete_success": "âœ… Modelos entrenados exitosamente para {}",
        "metrics_section": "ğŸ“Š MÃ©tricas de Rendimiento",
        "training_times_section": "â±ï¸ Tiempos de Entrenamiento",
        "model_label": "Modelo",
        "time_seconds_label": "Tiempo (segundos)",
        "statistical_tests_section": "ğŸ“ˆ Pruebas EstadÃ­sticas Inferenciales",
        "statistical_tests_spinner": "Realizando pruebas estadÃ­sticas para {}...",
        "residuals_normality_test": "Test de Normalidad de Residuos:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-value = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-value = {:.4f} ({})",
        "normal_interpretation": "âœ… Normal",
        "not_normal_interpretation": "âŒ No Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk no pudo ejecutarse: {}",
        "zero_std_error": "{}: Residuos con desviaciÃ³n estÃ¡ndar cero (todos los valores son iguales), no se puede realizar test de normalidad.",
        "no_statistical_results": "No se encontraron resultados de pruebas estadÃ­sticas para {}.",
        "evaluation_complete_success": "ğŸ‰ EvaluaciÃ³n de modelos completada para todas las variables objetivo.",
        "download_reports_section": "ğŸ“„ Descargar Reportes PDF",
        "download_pdf_link": "ğŸ“¥ Descargar Reporte PDF para {}",
        "pdf_generation_error": "Error al generar o descargar el reporte PDF para {}: {}",
        "dataset_load_error": "No se pudo cargar el dataset. Verifica que el archivo 'datos_pacientes.csv' estÃ© en la carpeta correcta.",
        "training_linear_regression": "ğŸ”„ Entrenando RegresiÃ³n Lineal...",
        "training_random_forest": "ğŸ”„ Entrenando Random Forest...",
        "training_xgboost": "ğŸ”„ Entrenando XGBoost...",
        "processed_columns": "Columnas procesadas:",
        "residuals_histogram_title": "Histograma de Residuos para {}",
        "qq_plot_title": "GrÃ¡fico Q-Q de Residuos para {}",
        "residuals_vs_predictions_title": "Residuos vs. Predicciones para {}",
        "residuals_label": "Residuos",
        "frequency_label": "Frecuencia",
        "predicted_values_label": "Valores Predichos",
        "friedman_test_heading": "Prueba de Friedman",
        "friedman_result": "Resultado de la prueba de Friedman: Chi-cuadrado = {:.4f}, p-valor = {:.4f} ({})",
        "friedman_significant": "Significativo",
        "friedman_not_significant_interpret": "No Significativo",
        "friedman_not_enough_models": "Se requieren al menos 3 modelos para ejecutar la prueba de Friedman.",
        "friedman_data_error": "Error al preparar los datos para Friedman: {}",
        "friedman_error": "Error al ejecutar la prueba de Friedman: {}",
        "friedman_not_significant": "La prueba de Friedman no fue significativa, no se realizan pruebas post-hoc.",
        "posthoc_heading": "Pruebas Post-Hoc (Nemenyi)",
        "nemenyi_intro": "Resultados de la prueba post-hoc de Nemenyi (valores p):",
        "pdf_friedman_test_heading": "PRUEBA DE FRIEDMAN",
        "pdf_friedman_result": "EstadÃ­stico Chi-cuadrado = {:.4f}, p-valor = {:.4f} ({})",
        "pdf_posthoc_heading": "PRUEBAS POST-HOC (NEMENYI)",
        "pdf_nemenyi_intro": "Resultados de la prueba post-hoc de Nemenyi (valores p):",
        "pdf_no_friedman_results": "La prueba de Friedman no pudo ser ejecutada.",
        "pdf_no_posthoc_results": "No se encontraron resultados de pruebas post-hoc (Friedman no fue significativo o hubo un error).",

        # PDF Strings
        "pdf_report_title": "REPORTE DE EVALUACIÃ“N DE MODELOS ML - {}",
        "pdf_report_subtitle": "ValoraciÃ³n Nutricional AntropomÃ©trica",
        "pdf_equipment_heading": "CARACTERÃSTICAS DEL EQUIPO DE PROCESAMIENTO",
        "pdf_component_header": "Componente",
        "pdf_specification_header": "EspecificaciÃ³n",
        "pdf_processor": "Procesador",
        "pdf_ram": "RAM instalada",
        "pdf_storage": "Almacenamiento",
        "pdf_gpu": "Tarjeta grÃ¡fica",
        "pdf_dataset_info_heading": "INFORMACIÃ“N DEL DATASET",
        "pdf_num_records": "NÃºmero de registros: {}",
        "pdf_num_features": "NÃºmero de caracterÃ­sticas: {}",
        "pdf_train_percent": "Porcentaje de entrenamiento: {:.2f}%",
        "pdf_test_percent": "Porcentaje de prueba: {:.2f}%",
        "pdf_training_times_heading": "TIEMPOS DE ENTRENAMIENTO",
        "pdf_metrics_heading": "MÃ‰TRICAS DE RENDIMIENTO",
        "pdf_model_header": "Modelo",
        "pdf_time_seconds_header": "Tiempo (segundos)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "RÂ²",
        "pdf_statistical_tests_heading": "PRUEBAS ESTADÃSTICAS INFERENCIALES",
        "pdf_residuals_normality_heading": "Test de Normalidad de Residuos:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-value = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-value = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk no pudo ejecutarse: {}",
        "pdf_zero_std_note": "{}: Residuos con desviaciÃ³n estÃ¡ndar cero (todos los valores son iguales), no se puede realizar test de normalidad.",
        "pdf_no_stats_found": "No se encontraron resultados de pruebas estadÃ­sticas para {}.",
        "pdf_additional_visualizations": "VISUALIZACIONES ADICIONALES",
        "pdf_confusion_matrices": "Matrices de ConfusiÃ³n",
        "pdf_confusion_matrix_for": "Matriz de ConfusiÃ³n para {}:",
        "pdf_confusion_matrix_warning": "Advertencia: Matriz de ConfusiÃ³n para {} no encontrada en {}",
        "pdf_performance_graphs": "GrÃ¡ficos de Rendimiento por Modelo",
        "pdf_graphs_for_model": "GrÃ¡ficos para {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Advertencia: GrÃ¡fico '{}' para {} no encontrado en {}",
        "pdf_target_suffix_warning": "Advertencia: No se encontrÃ³ sufijo para el objetivo '{}'. No se agregarÃ¡n grÃ¡ficos especÃ­ficos.",
        "pdf_residuals_graphs_heading": "GRÃFICOS DE RESIDUOS"

    },
    "en": {
        "page_title": "ML Model Evaluation - Nutritional Assessment",
        "app_title": "ğŸ§¬ ML Model Evaluation for Anthropometric Nutritional Assessment",
        "app_description": "---",
        "sidebar_title": "âš™ï¸ Configuration",
        "select_language_label": "Select Language:",
        "data_load_section": "Data Loading",
        "data_loaded_success": "âœ… Data loaded successfully",
        "records_label": "ğŸ“Š Records:",
        "columns_label": "ğŸ“‹ Columns:",
        "file_not_found_error": "File 'datos_pacientes2.csv' not found in the current folder.",
        "file_load_error": "Error loading file: {}",
        "dataset_info_section": "ğŸ“‹ Dataset Information",
        "first_rows_label": "**First 5 Rows:**",
        "statistical_info_label": "**Statistical Information:**",
        "target_variables_section": "ğŸ¯ Target Variable Evaluation",
        "start_evaluation_button": "ğŸš€ Start Model Evaluation",
        "preprocessing_spinner": "Preprocessing data...",
        "column_not_found_error": "Column '{}' not found in processed data.",
        "data_split_section": "ğŸ—‚ï¸ Data Split for {}",
        "train_percent": "**Training data percentage:** {}%",
        "test_percent": "**Test data percentage:** {}%",
        "model_training_section": "ğŸ¤– Model Training for {}",
        "training_spinner": "Training models for {}...",
        "training_complete_success": "âœ… Models trained successfully for {}",
        "metrics_section": "ğŸ“Š Performance Metrics",
        "training_times_section": "â±ï¸ Training Times",
        "model_label": "Model",
        "time_seconds_label": "Time (seconds)",
        "statistical_tests_section": "ğŸ“ˆ Inferential Statistical Tests",
        "statistical_tests_spinner": "Performing statistical tests for {}...",
        "residuals_normality_test": "Residuals Normality Test:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-value = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-value = {:.4f} ({})",
        "normal_interpretation": "âœ… Normal",
        "not_normal_interpretation": "âŒ Not Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk could not be performed: {}",
        "zero_std_error": "{}: Residuals with zero standard deviation (all values are the same), normality test cannot be performed.",
        "no_statistical_results": "No statistical test results found for {}.",
        "evaluation_complete_success": "ğŸ‰ Model evaluation completed for all target variables.",
        "download_reports_section": "ğŸ“„ Download PDF Reports",
        "download_pdf_link": "ğŸ“¥ Download PDF Report for {}",
        "pdf_generation_error": "Error generating or downloading PDF report for {}: {}",
        "dataset_load_error": "Could not load the dataset. Please ensure 'datos_pacientes.csv' is in the correct folder.",
        "training_linear_regression": "ğŸ”„ Training Linear Regression...",
        "training_random_forest": "ğŸ”„ Training Random Forest...",
        "training_xgboost": "ğŸ”„ Training XGBoost...",
        "processed_columns": "Processed columns:",
        "residuals_histogram_title": "Residuals Histogram for {}",
        "qq_plot_title": "Residuals Q-Q Plot for {}",
        "residuals_vs_predictions_title": "Residuals vs. Predictions for {}",
        "residuals_label": "Residuals",
        "frequency_label": "Frequency",
        "predicted_values_label": "Predicted Values",
        "friedman_test_heading": "Friedman Test",
        "friedman_result": "Friedman test result: Chi-squared = {:.4f}, p-value = {:.4f} ({})",
        "friedman_significant": "Significant",
        "friedman_not_significant_interpret": "Not Significant",
        "friedman_not_enough_models": "At least 3 models are required to run the Friedman test.",
        "friedman_data_error": "Error preparing data for Friedman: {}",
        "friedman_error": "Error running Friedman test: {}",
        "friedman_not_significant": "Friedman test was not significant, no post-hoc tests performed.",
        "posthoc_heading": "Post-Hoc Tests (Nemenyi)",
        "nemenyi_intro": "Nemenyi post-hoc test results (p-values):",
        "pdf_friedman_test_heading": "FRIEDMAN TEST",
        "pdf_friedman_result": "Chi-squared Statistic = {:.4f}, p-value = {:.4f} ({})",
        "pdf_posthoc_heading": "POST-HOC TESTS (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi post-hoc test results (p-values):",
        "pdf_no_friedman_results": "Friedman test could not be executed.",
        "pdf_no_posthoc_results": "No post-hoc test results found (Friedman was not significant or an error occurred).",

        # PDF Strings
        "pdf_report_title": "ML MODEL EVALUATION REPORT - {}",
        "pdf_report_subtitle": "Anthropometric Nutritional Assessment",
        "pdf_equipment_heading": "PROCESSING EQUIPMENT CHARACTERISTICS",
        "pdf_component_header": "Component",
        "pdf_specification_header": "Specification",
        "pdf_processor": "Processor",
        "pdf_ram": "Installed RAM",
        "pdf_storage": "Storage",
        "pdf_gpu": "Graphics Card",
        "pdf_dataset_info_heading": "DATASET INFORMATION",
        "pdf_num_records": "Number of records: {}",
        "pdf_num_features": "Number of features: {}",
        "pdf_train_percent": "Training percentage: {:.2f}%",
        "pdf_test_percent": "Test percentage: {:.2f}%",
        "pdf_training_times_heading": "TRAINING TIMES",
        "pdf_metrics_heading": "PERFORMANCE METRICS",
        "pdf_model_header": "Model",
        "pdf_time_seconds_header": "Time (seconds)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "RÂ²",
        "pdf_statistical_tests_heading": "INFERENTIAL STATISTICAL TESTS",
        "pdf_residuals_normality_heading": "Residuals Normality Test:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-value = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-value = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk could not be performed: {}",
        "pdf_zero_std_note": "{}: Residuals with zero standard deviation (all values are the same), normality test cannot be performed.",
        "pdf_no_stats_found": "No statistical test results found for {}.",
        "pdf_additional_visualizations": "ADDITIONAL VISUALIZATIONS",
        "pdf_confusion_matrices": "Confusion Matrices",
        "pdf_confusion_matrix_for": "Confusion Matrix for {}:",
        "pdf_confusion_matrix_warning": "Warning: Confusion Matrix for {} not found at {}",
        "pdf_performance_graphs": "Model Performance Graphs",
        "pdf_graphs_for_model": "Graphs for {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Warning: Graph '{}' for {} not found at {}",
        "pdf_target_suffix_warning": "Warning: No suffix found for target '{}'. Specific graphs will not be added.",
        "pdf_residuals_graphs_heading": "RESIDUALS GRAPHS"

    },

    "zh": { # Chinese (Simplified)
        "page_title": "æœºå™¨å­¦ä¹ æ¨¡å‹è¯„ä¼° - è¥å…»è¯„ä¼°",
        "app_title": "ğŸ§¬ äººä½“æµ‹é‡è¥å…»è¯„ä¼°çš„æœºå™¨å­¦ä¹ æ¨¡å‹è¯„ä¼°",
        "app_description": "---",
        "sidebar_title": "âš™ï¸ é…ç½®",
        "select_language_label": "é€‰æ‹©è¯­è¨€:",
        "data_load_section": "æ•°æ®åŠ è½½",
        "data_loaded_success": "âœ… æ•°æ®åŠ è½½æˆåŠŸ",
        "records_label": "ğŸ“Š è®°å½•:",
        "columns_label": "ğŸ“‹ åˆ—:",
        "file_not_found_error": "åœ¨å½“å‰æ–‡ä»¶å¤¹ä¸­æ‰¾ä¸åˆ°æ–‡ä»¶ 'datos_pacientes2.csv'ã€‚",
        "file_load_error": "åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {}",
        "dataset_info_section": "ğŸ“‹ æ•°æ®é›†ä¿¡æ¯",
        "first_rows_label": "**å‰5è¡Œ:**",
        "statistical_info_label": "**ç»Ÿè®¡ä¿¡æ¯:**",
        "target_variables_section": "ğŸ¯ ç›®æ ‡å˜é‡è¯„ä¼°",
        "start_evaluation_button": "ğŸš€ å¼€å§‹æ¨¡å‹è¯„ä¼°",
        "preprocessing_spinner": "æ­£åœ¨é¢„å¤„ç†æ•°æ®...",
        "column_not_found_error": "åœ¨å·²å¤„ç†æ•°æ®ä¸­æ‰¾ä¸åˆ°åˆ— '{}'ã€‚",
        "data_split_section": "ğŸ—‚ï¸ {} çš„æ•°æ®åˆ†å‰²",
        "train_percent": "**è®­ç»ƒæ•°æ®ç™¾åˆ†æ¯”:** {}%",
        "test_percent": "**æµ‹è¯•æ•°æ®ç™¾åˆ†æ¯”:** {}%",
        "model_training_section": "ğŸ¤– {} çš„æ¨¡å‹è®­ç»ƒ",
        "training_spinner": "æ­£åœ¨ä¸º {} è®­ç»ƒæ¨¡å‹...",
        "training_complete_success": "âœ… å·²æˆåŠŸä¸º {} è®­ç»ƒæ¨¡å‹",
        "metrics_section": "ğŸ“Š æ€§èƒ½æŒ‡æ ‡",
        "training_times_section": "â±ï¸ è®­ç»ƒæ—¶é—´",
        "model_label": "æ¨¡å‹",
        "time_seconds_label": "æ—¶é—´ (ç§’)",
        "statistical_tests_section": "ğŸ“ˆ æ¨æ–­ç»Ÿè®¡æ£€éªŒ",
        "statistical_tests_spinner": "æ­£åœ¨ä¸º {} æ‰§è¡Œç»Ÿè®¡æ£€éªŒ...",
        "residuals_normality_test": "æ®‹å·®æ­£æ€æ€§æ£€éªŒ:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): på€¼ = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): på€¼ = {:.4f} ({})",
        "normal_interpretation": "âœ… æ­£å¸¸",
        "not_normal_interpretation": "âŒ ä¸æ­£å¸¸",
        "shapiro_wilk_error": "{}: Shapiro-Wilk æ— æ³•æ‰§è¡Œ: {}",
        "zero_std_error": "{}: æ®‹å·®æ ‡å‡†å·®ä¸ºé›¶ï¼ˆæ‰€æœ‰å€¼éƒ½ç›¸åŒï¼‰ï¼Œæ— æ³•æ‰§è¡Œæ­£æ€æ€§æ£€éªŒã€‚",
        "no_statistical_results": "æœªæ‰¾åˆ° {} çš„ç»Ÿè®¡æ£€éªŒç»“æœã€‚",
        "evaluation_complete_success": "ğŸ‰ æ‰€æœ‰ç›®æ ‡å˜é‡çš„æ¨¡å‹è¯„ä¼°å·²å®Œæˆã€‚",
        "download_reports_section": "ğŸ“„ ä¸‹è½½ PDF æŠ¥å‘Š",
        "download_pdf_link": "ğŸ“¥ ä¸‹è½½ {} çš„ PDF æŠ¥å‘Š",
        "pdf_generation_error": "ä¸º {} ç”Ÿæˆæˆ–ä¸‹è½½ PDF æŠ¥å‘Šæ—¶å‡ºé”™: {}",
        "dataset_load_error": "æ— æ³•åŠ è½½æ•°æ®é›†ã€‚è¯·ç¡®ä¿ 'datos_pacientes.csv' åœ¨æ­£ç¡®çš„æ–‡ä»¶å¤¹ä¸­ã€‚",
        "training_linear_regression": "ğŸ”„ æ­£åœ¨è®­ç»ƒçº¿æ€§å›å½’...",
        "training_random_forest": "ğŸ”„ æ­£åœ¨è®­ç»ƒéšæœºæ£®æ—...",
        "training_xgboost": "ğŸ”„ æ­£åœ¨è®­ç»ƒ XGBoost...",
        "processed_columns": "å·²å¤„ç†çš„åˆ—:",
        "residuals_histogram_title": "{} çš„æ®‹å·®ç›´æ–¹å›¾",
        "qq_plot_title": "{} çš„æ®‹å·® Q-Q å›¾",
        "residuals_vs_predictions_title": "{} çš„æ®‹å·®ä¸é¢„æµ‹å€¼",
        "residuals_label": "æ®‹å·®",
        "frequency_label": "é¢‘ç‡",
        "predicted_values_label": "é¢„æµ‹å€¼",
         "friedman_test_heading": "Friedman æ£€éªŒ",
        "friedman_result": "Friedman æ£€éªŒç»“æœ: å¡æ–¹ = {:.4f}, p å€¼ = {:.4f} ({})",
        "friedman_significant": "æ˜¾è‘—",
        "friedman_not_significant_interpret": "ä¸æ˜¾è‘—",
        "friedman_not_enough_models": "è¿è¡Œ Friedman æ£€éªŒè‡³å°‘éœ€è¦ 3 ä¸ªæ¨¡å‹ã€‚",
        "friedman_data_error": "å‡†å¤‡ Friedman æ•°æ®æ—¶å‡ºé”™: {}",
        "friedman_error": "è¿è¡Œ Friedman æ£€éªŒæ—¶å‡ºé”™: {}",
        "friedman_not_significant": "Friedman æ£€éªŒä¸æ˜¾è‘—ï¼Œæœªæ‰§è¡Œäº‹åæ£€éªŒã€‚",
        "posthoc_heading": "äº‹åæ£€éªŒ (Nemenyi)",
        "nemenyi_intro": "Nemenyi äº‹åæ£€éªŒç»“æœ (p å€¼):",
        "pdf_friedman_test_heading": "FRIEDMAN æ£€éªŒ",
        "pdf_friedman_result": "å¡æ–¹ç»Ÿè®¡é‡ = {:.4f}, p å€¼ = {:.4f} ({})",
        "pdf_posthoc_heading": "äº‹åæ£€éªŒ (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi äº‹åæ£€éªŒç»“æœ (p å€¼):",
        "pdf_no_friedman_results": "Friedman æ£€éªŒæ— æ³•æ‰§è¡Œã€‚",
        "pdf_no_posthoc_results": "æœªæ‰¾åˆ°äº‹åæ£€éªŒç»“æœï¼ˆFriedman ä¸æ˜¾è‘—æˆ–å‘ç”Ÿé”™è¯¯ï¼‰ã€‚",

        # PDF Strings
        "pdf_report_title": "ML æ¨¡å‹è¯„ä¼°æŠ¥å‘Š - {}",
        "pdf_report_subtitle": "äººä½“æµ‹é‡è¥å…»è¯„ä¼°",
        "pdf_equipment_heading": "å¤„ç†è®¾å¤‡ç‰¹æ€§",
        "pdf_component_header": "ç»„ä»¶",
        "pdf_specification_header": "è§„æ ¼",
        "pdf_processor": "å¤„ç†å™¨",
        "pdf_ram": "å·²å®‰è£…å†…å­˜",
        "pdf_storage": "å­˜å‚¨",
        "pdf_gpu": "æ˜¾å¡",
        "pdf_dataset_info_heading": "æ•°æ®é›†ä¿¡æ¯",
        "pdf_num_records": "è®°å½•æ•°: {}",
        "pdf_num_features": "ç‰¹å¾æ•°: {}",
        "pdf_train_percent": "è®­ç»ƒç™¾åˆ†æ¯”: {:.2f}%",
        "pdf_test_percent": "æµ‹è¯•ç™¾åˆ†æ¯”: {:.2f}%",
        "pdf_training_times_heading": "è®­ç»ƒæ—¶é—´",
        "pdf_metrics_heading": "æ€§èƒ½æŒ‡æ ‡",
        "pdf_model_header": "æ¨¡å‹",
        "pdf_time_seconds_header": "æ—¶é—´ (ç§’)",
        "pdf_mse": "å‡æ–¹è¯¯å·®",
        "pdf_rmse": "å‡æ–¹æ ¹è¯¯å·®",
        "pdf_mae": "å¹³å‡ç»å¯¹è¯¯å·®",
        "pdf_r2": "å†³å®šç³»æ•° (RÂ²)",
        "pdf_statistical_tests_heading": "æ¨æ–­ç»Ÿè®¡æ£€éªŒ",
        "pdf_residuals_normality_heading": "æ®‹å·®æ­£æ€æ€§æ£€éªŒ:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): på€¼ = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): på€¼ = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk æ— æ³•æ‰§è¡Œ: {}",
        "pdf_zero_std_note": "{}: æ®‹å·®æ ‡å‡†å·®ä¸ºé›¶ï¼ˆæ‰€æœ‰å€¼éƒ½ç›¸åŒï¼‰ï¼Œæ— æ³•æ‰§è¡Œæ­£æ€æ€§æ£€éªŒã€‚",
        "pdf_no_stats_found": "æœªæ‰¾åˆ° {} çš„ç»Ÿè®¡æ£€éªŒç»“æœã€‚",
        "pdf_additional_visualizations": "é™„åŠ å¯è§†åŒ–",
        "pdf_confusion_matrices": "æ··æ·†çŸ©é˜µ",
        "pdf_confusion_matrix_for": "{} çš„æ··æ·†çŸ©é˜µ:",
        "pdf_confusion_matrix_warning": "è­¦å‘Š: åœ¨ {} æœªæ‰¾åˆ° {} çš„æ··æ·†çŸ©é˜µ",
        "pdf_performance_graphs": "æ¨¡å‹æ€§èƒ½å›¾",
        "pdf_graphs_for_model": "{} ({}) çš„å›¾:",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "è­¦å‘Š: åœ¨ {} æœªæ‰¾åˆ° {} çš„å›¾ '{}'",
        "pdf_target_suffix_warning": "è­¦å‘Š: æœªæ‰¾åˆ°ç›®æ ‡ '{}' çš„åç¼€ã€‚å°†ä¸æ·»åŠ ç‰¹å®šå›¾ã€‚",
        "pdf_residuals_graphs_heading": "æ®‹å·®å›¾"
    },
    "de": { # German
        "page_title": "ML-Modellbewertung - ErnÃ¤hrungsanalyse",
        "app_title": "ğŸ§¬ ML-Modellbewertung fÃ¼r anthropometrische ErnÃ¤hrungsanalyse",
        "app_description": "---",
        "sidebar_title": "âš™ï¸ Konfiguration",
        "select_language_label": "Sprache auswÃ¤hlen:",
        "data_load_section": "Daten laden",
        "data_loaded_success": "âœ… Daten erfolgreich geladen",
        "records_label": "ğŸ“Š DatensÃ¤tze:",
        "columns_label": "ğŸ“‹ Spalten:",
        "file_not_found_error": "Datei 'datos_pacientes2.csv' im aktuellen Ordner nicht gefunden.",
        "file_load_error": "Fehler beim Laden der Datei: {}",
        "dataset_info_section": "ğŸ“‹ Datensatzinformationen",
        "first_rows_label": "**Erste 5 Zeilen:**",
        "statistical_info_label": "**Statistische Informationen:**",
        "target_variables_section": "ğŸ¯ Zielvariablenbewertung",
        "start_evaluation_button": "ğŸš€ Modellbewertung starten",
        "preprocessing_spinner": "Daten werden vorverarbeitet...",
        "column_not_found_error": "Spalte '{}' in den verarbeiteten Daten nicht gefunden.",
        "data_split_section": "ğŸ—‚ï¸ Datenteilung fÃ¼r {}",
        "train_percent": "**Prozentsatz der Trainingsdaten:** {}%",
        "test_percent": "**Prozentsatz der Testdaten:** {}%",
        "model_training_section": "ğŸ¤– Modelltraining fÃ¼r {}",
        "training_spinner": "Modelle werden fÃ¼r {} trainiert...",
        "training_complete_success": "âœ… Modelle erfolgreich fÃ¼r {} trainiert",
        "metrics_section": "ğŸ“Š Leistungsmetriken",
        "training_times_section": "â±ï¸ Trainingszeiten",
        "model_label": "Modell",
        "time_seconds_label": "Zeit (Sekunden)",
        "statistical_tests_section": "ğŸ“ˆ Inferenzstatistische Tests",
        "statistical_tests_spinner": "Statistische Tests fÃ¼r {} werden durchgefÃ¼hrt...",
        "residuals_normality_test": "NormalitÃ¤tstest der Residuen:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-Wert = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-Wert = {:.4f} ({})",
        "normal_interpretation": "âœ… Normal",
        "not_normal_interpretation": "âŒ Nicht Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk konnte nicht durchgefÃ¼hrt werden: {}",
        "zero_std_error": "{}: Residuen mit Standardabweichung Null (alle Werte sind gleich), NormalitÃ¤tstest kann nicht durchgefÃ¼hrt werden.",
        "no_statistical_results": "Keine statistischen Testergebnisse fÃ¼r {} gefunden.",
        "evaluation_complete_success": "ğŸ‰ Modellbewertung fÃ¼r alle Zielvariablen abgeschlossen.",
        "download_reports_section": "ğŸ“„ PDF-Berichte herunterladen",
        "download_pdf_link": "ğŸ“¥ PDF-Bericht fÃ¼r {} herunterladen",
        "pdf_generation_error": "Fehler beim Generieren oder Herunterladen des PDF-Berichts fÃ¼r {}: {}",
        "dataset_load_error": "Datensatz konnte nicht geladen werden. Stellen Sie sicher, dass 'datos_pacientes.csv' im richtigen Ordner ist.",
        "training_linear_regression": "ğŸ”„ Lineare Regression wird trainiert...",
        "training_random_forest": "ğŸ”„ Random Forest wird trainiert...",
        "training_xgboost": "ğŸ”„ XGBoost wird trainiert...",
        "processed_columns": "Verarbeitete Spalten:",
        "residuals_histogram_title": "Residuen-Histogramm fÃ¼r {}",
        "qq_plot_title": "Residuen-Q-Q-Diagramm fÃ¼r {}",
        "residuals_vs_predictions_title": "Residuen vs. Vorhersagen fÃ¼r {}",
        "residuals_label": "Residuen",
        "frequency_label": "HÃ¤ufigkeit",
        "predicted_values_label": "Vorhergesagte Werte",
        "friedman_test_heading": "Friedman-Test",
        "friedman_result": "Friedman-Testergebnis: Chi-Quadrat = {:.4f}, p-Wert = {:.4f} ({})",
        "friedman_significant": "Signifikant",
        "friedman_not_significant_interpret": "Nicht signifikant",
        "friedman_not_enough_models": "Es werden mindestens 3 Modelle fÃ¼r den Friedman-Test benÃ¶tigt.",
        "friedman_data_error": "Fehler beim Vorbereiten der Daten fÃ¼r Friedman: {}",
        "friedman_error": "Fehler beim AusfÃ¼hren des Friedman-Tests: {}",
        "friedman_not_significant": "Friedman-Test war nicht signifikant, keine Post-hoc-Tests durchgefÃ¼hrt.",
        "posthoc_heading": "Post-hoc-Tests (Nemenyi)",
        "nemenyi_intro": "Nemenyi Post-hoc-Testergebnisse (p-Werte):",
        "pdf_friedman_test_heading": "FRIEDMAN-TEST",
        "pdf_friedman_result": "Chi-Quadrat-Statistik = {:.4f}, p-Wert = {:.4f} ({})",
        "pdf_posthoc_heading": "POST-HOC-TESTS (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi Post-hoc-Testergebnisse (p-Werte):",
        "pdf_no_friedman_results": "Friedman-Test konnte nicht ausgefÃ¼hrt werden.",
        "pdf_no_posthoc_results": "Keine Post-hoc-Testergebnisse gefunden (Friedman war nicht signifikant oder es ist ein Fehler aufgetreten).",

        # PDF Strings
        "pdf_report_title": "ML-MODELLBEWERTUNGSBERICHT - {}",
        "pdf_report_subtitle": "Anthropometrische ErnÃ¤hrungsanalyse",
        "pdf_equipment_heading": "EIGENSCHAFTEN DER VERARBEITUNGSAUSRÃœSTUNG",
        "pdf_component_header": "Komponente",
        "pdf_specification_header": "Spezifikation",
        "pdf_processor": "Prozessor",
        "pdf_ram": "Installierter RAM",
        "pdf_storage": "Speicher",
        "pdf_gpu": "Grafikkarte",
        "pdf_dataset_info_heading": "DATENSATZINFORMATIONEN",
        "pdf_num_records": "Anzahl der DatensÃ¤tze: {}",
        "pdf_num_features": "Anzahl der Merkmale: {}",
        "pdf_train_percent": "Trainingsprozentsatz: {:.2f}%",
        "pdf_test_percent": "Testprozentsatz: {:.2f}%",
        "pdf_training_times_heading": "TRAININGSZEITEN",
        "pdf_metrics_heading": "LEISTUNGSMETRIKEN",
        "pdf_model_header": "Modell",
        "pdf_time_seconds_header": "Zeit (Sekunden)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "RÂ²",
        "pdf_statistical_tests_heading": "INFERENZSTATISTISCHE TESTS",
        "pdf_residuals_normality_heading": "NormalitÃ¤tstest der Residuen:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-Wert = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-Wert = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk konnte nicht durchgefÃ¼hrt werden: {}",
        "pdf_zero_std_note": "{}: Residuen mit Standardabweichung Null (alle Werte sind gleich), NormalitÃ¤tstest kann nicht durchgefÃ¼hrt werden.",
        "pdf_no_stats_found": "Keine statistischen Testergebnisse fÃ¼r {} gefunden.",
        "pdf_additional_visualizations": "ZUSÃ„TZLICHE VISUALISIERUNGEN",
        "pdf_confusion_matrices": "Konfusionsmatrizen",
        "pdf_confusion_matrix_for": "Konfusionsmatrix fÃ¼r {}:",
        "pdf_confusion_matrix_warning": "Warnung: Konfusionsmatrix fÃ¼r {} nicht gefunden unter {}",
        "pdf_performance_graphs": "Modellleistungsdiagramme",
        "pdf_graphs_for_model": "Diagramme fÃ¼r {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Warnung: Diagramm '{}' fÃ¼r {} nicht gefunden unter {}",
        "pdf_target_suffix_warning": "Warnung: Kein Suffix fÃ¼r Ziel '{}' gefunden. Spezifische Diagramme werden nicht hinzugefÃ¼gt.",
        "pdf_residuals_graphs_heading": "RESIDUEN-DIAGRAMME"
    },
    "ja": { # Japanese
        "page_title": "MLãƒ¢ãƒ‡ãƒ«è©•ä¾¡ - æ „é¤Šè©•ä¾¡",
        "app_title": "ğŸ§¬ äººä½“è¨ˆæ¸¬æ „é¤Šè©•ä¾¡ã®ãŸã‚ã®MLãƒ¢ãƒ‡ãƒ«è©•ä¾¡",
        "app_description": "---",
        "sidebar_title": "âš™ï¸ è¨­å®š",
        "select_language_label": "è¨€èªã‚’é¸æŠ:",
        "data_load_section": "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿",
        "data_loaded_success": "âœ… ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸ",
        "records_label": "ğŸ“Š ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°:",
        "columns_label": "ğŸ“‹ åˆ—æ•°:",
        "file_not_found_error": "ç¾åœ¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚¡ã‚¤ãƒ« 'datos_pacientes2.csv' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚",
        "file_load_error": "ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {}",
        "dataset_info_section": "ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±",
        "first_rows_label": "**æœ€åˆã®5è¡Œ:**",
        "statistical_info_label": "**çµ±è¨ˆæƒ…å ±:**",
        "target_variables_section": "ğŸ¯ ç›®æ¨™å¤‰æ•°è©•ä¾¡",
        "start_evaluation_button": "ğŸš€ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚’é–‹å§‹",
        "preprocessing_spinner": "ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ä¸­...",
        "column_not_found_error": "å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã«åˆ— '{}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚",
        "data_split_section": "ğŸ—‚ï¸ {} ã®ãƒ‡ãƒ¼ã‚¿åˆ†å‰²",
        "train_percent": "**ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å‰²åˆ:** {}%",
        "test_percent": "**ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‰²åˆ:** {}%",
        "model_training_section": "ğŸ¤– {} ã®ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
        "training_spinner": "{} ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...",
        "training_complete_success": "âœ… {} ã®ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¾ã—ãŸ",
        "metrics_section": "ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™",
        "training_times_section": "â±ï¸ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“",
        "model_label": "ãƒ¢ãƒ‡ãƒ«",
        "time_seconds_label": "æ™‚é–“ (ç§’)",
        "statistical_tests_section": "ğŸ“ˆ æ¨æ¸¬çµ±è¨ˆæ¤œå®š",
        "statistical_tests_spinner": "{} ã®çµ±è¨ˆæ¤œå®šã‚’å®Ÿè¡Œä¸­...",
        "residuals_normality_test": "æ®‹å·®ã®æ­£è¦æ€§æ¤œå®š:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): på€¤ = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): på€¤ = {:.4f} ({})",
        "normal_interpretation": "âœ… æ­£è¦",
        "not_normal_interpretation": "âŒ éæ­£è¦",
        "shapiro_wilk_error": "{}: Shapiro-Wilk ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {}",
        "zero_std_error": "{}: æ®‹å·®ã®æ¨™æº–åå·®ãŒã‚¼ãƒ­ï¼ˆã™ã¹ã¦ã®å€¤ãŒåŒã˜ï¼‰ã®ãŸã‚ã€æ­£è¦æ€§æ¤œå®šã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚",
        "no_statistical_results": "{} ã®çµ±è¨ˆæ¤œå®šçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚",
        "evaluation_complete_success": "ğŸ‰ ã™ã¹ã¦ã®ç›®æ¨™å¤‰æ•°ã®ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸã€‚",
        "download_reports_section": "ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        "download_pdf_link": "ğŸ“¥ {} ã®PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        "pdf_generation_error": "{} ã®PDFãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã¾ãŸã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
        "dataset_load_error": "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'datos_pacientes.csv' ãŒæ­£ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        "training_linear_regression": "ğŸ”„ ç·šå½¢å›å¸°ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...",
        "training_random_forest": "ğŸ”„ ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...",
        "training_xgboost": "ğŸ”„ XGBoostã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...",
        "processed_columns": "å‡¦ç†æ¸ˆã¿åˆ—:",
        "residuals_histogram_title": "{} ã®æ®‹å·®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ",
        "qq_plot_title": "{} ã®æ®‹å·® Q-Q ãƒ—ãƒ­ãƒƒãƒˆ",
        "residuals_vs_predictions_title": "{} ã®æ®‹å·® vs. äºˆæ¸¬",
        "residuals_label": "æ®‹å·®",
        "frequency_label": "é »åº¦",
        "predicted_values_label": "äºˆæ¸¬å€¤",
        "friedman_test_heading": "ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³æ¤œå®š",
        "friedman_result": "ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³æ¤œå®šçµæœ: ã‚«ã‚¤äºŒä¹— = {:.4f}, p å€¤ = {:.4f} ({})",
        "friedman_significant": "æœ‰æ„",
        "friedman_not_significant_interpret": "æœ‰æ„ã§ãªã„",
        "friedman_not_enough_models": "ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³æ¤œå®šã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€å°‘ãªãã¨ã‚‚3ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã§ã™ã€‚",
        "friedman_data_error": "ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
        "friedman_error": "ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³æ¤œå®šã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
        "friedman_not_significant": "ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³æ¤œå®šã¯æœ‰æ„ã§ã¯ãªã‹ã£ãŸãŸã‚ã€äº‹å¾Œæ¤œå®šã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚",
        "posthoc_heading": "äº‹å¾Œæ¤œå®š (Nemenyi)",
        "nemenyi_intro": "Nemenyi äº‹å¾Œæ¤œå®šçµæœ (p å€¤):",
        "pdf_friedman_test_heading": "ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³æ¤œå®š",
        "pdf_friedman_result": "ã‚«ã‚¤äºŒä¹—çµ±è¨ˆé‡ = {:.4f}, p å€¤ = {:.4f} ({})",
        "pdf_posthoc_heading": "äº‹å¾Œæ¤œå®š (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi äº‹å¾Œæ¤œå®šçµæœ (p å€¤):",
        "pdf_no_friedman_results": "ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³æ¤œå®šã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
        "pdf_no_posthoc_results": "äº‹å¾Œæ¤œå®šã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³ã¯æœ‰æ„ã§ã¯ãªã‹ã£ãŸã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ)ã€‚",

        # PDF Strings
        "pdf_report_title": "MLãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ - {}",
        "pdf_report_subtitle": "äººä½“è¨ˆæ¸¬æ „é¤Šè©•ä¾¡",
        "pdf_equipment_heading": "å‡¦ç†è£…ç½®ã®ç‰¹æ€§",
        "pdf_component_header": "ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ",
        "pdf_specification_header": "ä»•æ§˜",
        "pdf_processor": "ãƒ—ãƒ­ã‚»ãƒƒã‚µ",
        "pdf_ram": "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿RAM",
        "pdf_storage": "ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸",
        "pdf_gpu": "ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚«ãƒ¼ãƒ‰",
        "pdf_dataset_info_heading": "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±",
        "pdf_num_records": "ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {}",
        "pdf_num_features": "ç‰¹å¾´é‡æ•°: {}",
        "pdf_train_percent": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å‰²åˆ: {:.2f}%",
        "pdf_test_percent": "ãƒ†ã‚¹ãƒˆå‰²åˆ: {:.2f}%",
        "pdf_training_times_heading": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“",
        "pdf_metrics_heading": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™",
        "pdf_model_header": "ãƒ¢ãƒ‡ãƒ«",
        "pdf_time_seconds_header": "æ™‚é–“ (ç§’)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "RÂ²",
        "pdf_statistical_tests_heading": "æ¨æ¸¬çµ±è¨ˆæ¤œå®š",
        "pdf_residuals_normality_heading": "æ®‹å·®ã®æ­£è¦æ€§æ¤œå®š:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): på€¤ = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): på€¤ = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {}",
        "pdf_zero_std_note": "{}: æ®‹å·®ã®æ¨™æº–åå·®ãŒã‚¼ãƒ­ï¼ˆã™ã¹ã¦ã®å€¤ãŒåŒã˜ï¼‰ã®ãŸã‚ã€æ­£è¦æ€§æ¤œå®šã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚",
        "pdf_no_stats_found": "{} ã®çµ±è¨ˆæ¤œå®šçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚",
        "pdf_additional_visualizations": "è¿½åŠ ã®è¦–è¦šåŒ–",
        "pdf_confusion_matrices": "æ··åŒè¡Œåˆ—",
        "pdf_confusion_matrix_for": "{} ã®æ··åŒè¡Œåˆ—:",
        "pdf_confusion_matrix_warning": "è­¦å‘Š: {} ã®æ··åŒè¡Œåˆ—ãŒ {} ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
        "pdf_performance_graphs": "ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚°ãƒ©ãƒ•",
        "pdf_graphs_for_model": "{} ({}) ã®ã‚°ãƒ©ãƒ•:",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "è­¦å‘Š: {} ã®ã‚°ãƒ©ãƒ• '{}' ãŒ {} ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
        "pdf_target_suffix_warning": "è­¦å‘Š: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ '{}' ã®ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ç‰¹å®šã®ã‚°ãƒ©ãƒ•ã¯è¿½åŠ ã•ã‚Œã¾ã›ã‚“ã€‚",
        "pdf_residuals_graphs_heading": "æ®‹å·®ã‚°ãƒ©ãƒ•"
    },
    "fr": { # French
        "page_title": "Ã‰valuation de ModÃ¨les ML - Ã‰valuation Nutritionnelle",
        "app_title": "ğŸ§¬ Ã‰valuation de ModÃ¨les ML pour l'Ã‰valuation Nutritionnelle AnthropomÃ©trique",
        "app_description": "---",
        "sidebar_title": "âš™ï¸ Configuration",
        "select_language_label": "SÃ©lectionner la langue :",
        "data_load_section": "Chargement des DonnÃ©es",
        "data_loaded_success": "âœ… DonnÃ©es chargÃ©es avec succÃ¨s",
        "records_label": "ğŸ“Š Enregistrements :",
        "columns_label": "ğŸ“‹ Colonnes :",
        "file_not_found_error": "Fichier 'datos_pacientes2.csv' introuvable dans le dossier actuel.",
        "file_load_error": "Erreur lors du chargement du fichier : {}",
        "dataset_info_section": "ğŸ“‹ Informations sur l'Ensemble de DonnÃ©es",
        "first_rows_label": "**5 premiÃ¨res lignes :**",
        "statistical_info_label": "**Informations statistiques :**",
        "target_variables_section": "ğŸ¯ Ã‰valuation des Variables Cibles",
        "start_evaluation_button": "ğŸš€ DÃ©marrer l'Ã‰valuation des ModÃ¨les",
        "preprocessing_spinner": "PrÃ©traitement des donnÃ©es...",
        "column_not_found_error": "La colonne '{}' n'a pas Ã©tÃ© trouvÃ©e dans les donnÃ©es traitÃ©es.",
        "data_split_section": "ğŸ—‚ï¸ Division des DonnÃ©es pour {}",
        "train_percent": "**Pourcentage de donnÃ©es d'entraÃ®nement :** {}%",
        "test_percent": "**Pourcentage de donnÃ©es de test :** {}%",
        "model_training_section": "ğŸ¤– EntraÃ®nement des ModÃ¨les pour {}",
        "training_spinner": "EntraÃ®nement des modÃ¨les pour {}...",
        "training_complete_success": "âœ… ModÃ¨les entraÃ®nÃ©s avec succÃ¨s pour {}",
        "metrics_section": "ğŸ“Š MÃ©triques de Performance",
        "training_times_section": "â±ï¸ Temps d'EntraÃ®nement",
        "model_label": "ModÃ¨le",
        "time_seconds_label": "Temps (secondes)",
        "statistical_tests_section": "ğŸ“ˆ Tests Statistiques InfÃ©rentiels",
        "statistical_tests_spinner": "ExÃ©cution des tests statistiques pour {}...",
        "residuals_normality_test": "Test de NormalitÃ© des RÃ©sidus :",
        "shapiro_wilk_test": "{} (Shapiro-Wilk) : p-value = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov) : p-value = {:.4f} ({})",
        "normal_interpretation": "âœ… Normal",
        "not_normal_interpretation": "âŒ Non Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk n'a pas pu Ãªtre exÃ©cutÃ© : {}",
        "zero_std_error": "{}: RÃ©sidus avec Ã©cart type nul (toutes les valeurs sont identiques), le test de normalitÃ© ne peut pas Ãªtre effectuÃ©.",
        "no_statistical_results": "Aucun rÃ©sultat de test statistique trouvÃ© pour {}.",
        "evaluation_complete_success": "ğŸ‰ Ã‰valuation des modÃ¨les terminÃ©e pour toutes les variables cibles.",
        "download_reports_section": "ğŸ“„ TÃ©lÃ©charger les Rapports PDF",
        "download_pdf_link": "ğŸ“¥ TÃ©lÃ©charger le Rapport PDF pour {}",
        "pdf_generation_error": "Erreur lors de la gÃ©nÃ©ration ou du tÃ©lÃ©chargement du rapport PDF pour {} : {}",
        "dataset_load_error": "Impossible de charger l'ensemble de donnÃ©es. Veuillez vous assurer que 'datos_pacientes.csv' se trouve dans le bon dossier.",
        "training_linear_regression": "ğŸ”„ EntraÃ®nement de la RÃ©gression LinÃ©aire...",
        "training_random_forest": "ğŸ”„ EntraÃ®nement de Random Forest...",
        "training_xgboost": "ğŸ”„ EntraÃ®nement de XGBoost...",
        "processed_columns": "Colonnes traitÃ©es :",
        "residuals_histogram_title": "Histogramme des RÃ©sidus pour {}",
        "qq_plot_title": "Graphe Q-Q des RÃ©sidus pour {}",
        "residuals_vs_predictions_title": "RÃ©sidus vs. PrÃ©dictions pour {}",
        "residuals_label": "RÃ©sidus",
        "frequency_label": "FrÃ©quence",
        "predicted_values_label": "Valeurs PrÃ©dites",
        "friedman_test_heading": "Test de Friedman",
        "friedman_result": "RÃ©sultat du test de Friedman: Chi-deux = {:.4f}, p-valeur = {:.4f} ({})",
        "friedman_significant": "Significatif",
        "friedman_not_significant_interpret": "Non Significatif",
        "friedman_not_enough_models": "Au moins 3 modÃ¨les sont requis pour exÃ©cuter le test de Friedman.",
        "friedman_data_error": "Erreur lors de la prÃ©paration des donnÃ©es pour Friedman: {}",
        "friedman_error": "Erreur lors de l'exÃ©cution du test de Friedman: {}",
        "friedman_not_significant": "Le test de Friedman n'Ã©tait pas significatif, aucun test post-hoc effectuÃ©.",
        "posthoc_heading": "Tests Post-Hoc (Nemenyi)",
        "nemenyi_intro": "RÃ©sultats du test post-hoc de Nemenyi (valeurs p):",
        "pdf_friedman_test_heading": "TEST DE FRIEDMAN",
        "pdf_friedman_result": "Statistique du Chi-deux = {:.4f}, p-valeur = {:.4f} ({})",
        "pdf_posthoc_heading": "TESTS POST-HOC (NEMENYI)",
        "pdf_nemenyi_intro": "RÃ©sultats du test post-hoc de Nemenyi (valeurs p):",
        "pdf_no_friedman_results": "Le test de Friedman n'a pas pu Ãªtre exÃ©cutÃ©.",
        "pdf_no_posthoc_results": "Aucun rÃ©sultat de test post-hoc trouvÃ© (Friedman n'Ã©tait pas significatif ou une erreur s'est produite).",

        # PDF Strings
        "pdf_report_title": "RAPPORT D'Ã‰VALUATION DES MODÃˆLES ML - {}",
        "pdf_report_subtitle": "Ã‰valuation Nutritionnelle AnthropomÃ©trique",
        "pdf_equipment_heading": "CARACTÃ‰RISTIQUES DE L'Ã‰QUIPEMENT DE TRAITEMENT",
        "pdf_component_header": "Composant",
        "pdf_specification_header": "SpÃ©cification",
        "pdf_processor": "Processeur",
        "pdf_ram": "RAM installÃ©e",
        "pdf_storage": "Stockage",
        "pdf_gpu": "Carte graphique",
        "pdf_dataset_info_heading": "INFORMATIONS SUR L'ENSEMBLE DE DONNÃ‰ES",
        "pdf_num_records": "Nombre d'enregistrements : {}",
        "pdf_num_features": "Nombre de caractÃ©ristiques : {}",
        "pdf_train_percent": "Pourcentage d'entraÃ®nement : {:.2f}%",
        "pdf_test_percent": "Pourcentage de test : {:.2f}%",
        "pdf_training_times_heading": "TEMPS D'ENTRAÃNEMENT",
        "pdf_metrics_heading": "MÃ‰TRIQUES DE PERFORMANCE",
        "pdf_model_header": "ModÃ¨le",
        "pdf_time_seconds_header": "Temps (secondes)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "RÂ²",
        "pdf_statistical_tests_heading": "TESTS STATISTIQUES INFÃ‰RENTIELS",
        "pdf_residuals_normality_heading": "Test de NormalitÃ© des RÃ©sidus :",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk) : p-value = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov) : p-value = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk n'a pas pu Ãªtre exÃ©cutÃ© : {}",
        "pdf_zero_std_note": "{}: RÃ©sidus avec Ã©cart type nul (toutes les valeurs sont identiques), le test de normalitÃ© ne peut pas Ãªtre effectuÃ©.",
        "pdf_no_stats_found": "Aucun rÃ©sultat de test statistique trouvÃ© pour {}.",
        "pdf_additional_visualizations": "VISUALISATIONS SUPPLÃ‰MENTAIRES",
        "pdf_confusion_matrices": "Matrices de Confusion",
        "pdf_confusion_matrix_for": "Matrice de Confusion pour {} :",
        "pdf_confusion_matrix_warning": "Avertissement : Matrice de Confusion pour {} introuvable Ã  {}",
        "pdf_performance_graphs": "Graphiques de Performance du ModÃ¨le",
        "pdf_graphs_for_model": "Graphiques pour {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Avertissement : Graphique '{}' pour {} introuvable Ã  {}",
        "pdf_target_suffix_warning": "Avertissement : Aucun suffixe trouvÃ© pour la cible '{}'. Les graphiques spÃ©cifiques ne seront pas ajoutÃ©s.",
        "pdf_residuals_graphs_heading": "GRAPHIQUES DES RÃ‰SIDUS"
    },
    "pt": { # Portuguese (Brazil)
        "page_title": "AvaliaÃ§Ã£o de Modelos ML - AvaliaÃ§Ã£o Nutricional",
        "app_title": "ğŸ§¬ AvaliaÃ§Ã£o de Modelos ML para AvaliaÃ§Ã£o Nutricional AntropomÃ©trica",
        "app_description": "---",
        "sidebar_title": "âš™ï¸ ConfiguraÃ§Ã£o",
        "select_language_label": "Selecionar Idioma:",
        "data_load_section": "Carregamento de Dados",
        "data_loaded_success": "âœ… Dados carregados com sucesso",
        "records_label": "ğŸ“Š Registros:",
        "columns_label": "ğŸ“‹ Colunas:",
        "file_not_found_error": "Arquivo 'datos_pacientes2.csv' nÃ£o encontrado na pasta atual.",
        "file_load_error": "Erro ao carregar o arquivo: {}",
        "dataset_info_section": "ğŸ“‹ InformaÃ§Ãµes do Conjunto de Dados",
        "first_rows_label": "**Primeiras 5 linhas:**",
        "statistical_info_label": "**InformaÃ§Ãµes estatÃ­sticas:**",
        "target_variables_section": "ğŸ¯ AvaliaÃ§Ã£o de VariÃ¡veis Alvo",
        "start_evaluation_button": "ğŸš€ Iniciar AvaliaÃ§Ã£o de Modelos",
        "preprocessing_spinner": "PrÃ©-processando dados...",
        "column_not_found_error": "A coluna '{}' nÃ£o foi encontrada nos dados processados.",
        "data_split_section": "ğŸ—‚ï¸ DivisÃ£o de Dados para {}",
        "train_percent": "**Porcentagem de dados de treinamento:** {}%",
        "test_percent": "**Porcentagem de dados de teste:** {}%",
        "model_training_section": "ğŸ¤– Treinamento de Modelos para {}",
        "training_spinner": "Treinando modelos para {}...",
        "training_complete_success": "âœ… Modelos treinados com sucesso para {}",
        "metrics_section": "ğŸ“Š MÃ©tricas de Desempenho",
        "training_times_section": "â±ï¸ Tempos de Treinamento",
        "model_label": "Modelo",
        "time_seconds_label": "Tempo (segundos)",
        "statistical_tests_section": "ğŸ“ˆ Testes EstatÃ­sticos Inferenciais",
        "statistical_tests_spinner": "Realizando testes estatÃ­sticos para {}...",
        "residuals_normality_test": "Teste de Normalidade dos ResÃ­duos:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-valor = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-valor = {:.4f} ({})",
        "normal_interpretation": "âœ… Normal",
        "not_normal_interpretation": "âŒ NÃ£o Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk nÃ£o pÃ´de ser executado: {}",
        "zero_std_error": "{}: ResÃ­duos com desvio padrÃ£o zero (todos os valores sÃ£o iguais), o teste de normalidade nÃ£o pode ser realizado.",
        "no_statistical_results": "Nenhum resultado de teste estatÃ­stico encontrado para {}.",
        "evaluation_complete_success": "ğŸ‰ AvaliaÃ§Ã£o de modelos concluÃ­da para todas as variÃ¡veis alvo.",
        "download_reports_section": "ğŸ“„ Baixar RelatÃ³rios PDF",
        "download_pdf_link": "ğŸ“¥ Baixar RelatÃ³rio PDF para {}",
        "pdf_generation_error": "Erro ao gerar ou baixar o relatÃ³rio PDF para {}: {}",
        "dataset_load_error": "NÃ£o foi possÃ­vel carregar o conjunto de dados. Verifique se o arquivo 'datos_pacientes.csv' estÃ¡ na pasta correta.",
        "training_linear_regression": "ğŸ”„ Treinando RegressÃ£o Linear...",
        "training_random_forest": "ğŸ”„ Treinando Random Forest...",
        "training_xgboost": "ğŸ”„ Treinando XGBoost...",
        "processed_columns": "Colunas processadas:",
        "residuals_histogram_title": "Histograma de ResÃ­duos para {}",
        "qq_plot_title": "GrÃ¡fico Q-Q de ResÃ­duos para {}",
        "residuals_vs_predictions_title": "ResÃ­duos vs. PrevisÃµes para {}",
        "residuals_label": "ResÃ­duos",
        "frequency_label": "FrequÃªncia",
        "predicted_values_label": "Valores Previstos",
        "friedman_test_heading": "Teste de Friedman",
        "friedman_result": "Resultado do teste de Friedman: Qui-quadrado = {:.4f}, p-valor = {:.4f} ({})",
        "friedman_significant": "Significativo",
        "friedman_not_significant_interpret": "NÃ£o Significativo",
        "friedman_not_enough_models": "SÃ£o necessÃ¡rios pelo menos 3 modelos para executar o teste de Friedman.",
        "friedman_data_error": "Erro ao preparar os dados para Friedman: {}",
        "friedman_error": "Erro ao executar o teste de Friedman: {}",
        "friedman_not_significant": "O teste de Friedman nÃ£o foi significativo, nenhum teste post-hoc realizado.",
        "posthoc_heading": "Testes Post-Hoc (Nemenyi)",
        "nemenyi_intro": "Resultados do teste post-hoc de Nemenyi (valores p):",
        "pdf_friedman_test_heading": "TESTE DE FRIEDMAN",
        "pdf_friedman_result": "EstatÃ­stica Qui-quadrado = {:.4f}, p-valor = {:.4f} ({})",
        "pdf_posthoc_heading": "TESTES POST-HOC (NEMENYI)",
        "pdf_nemenyi_intro": "Resultados do teste post-hoc de Nemenyi (valores p):",
        "pdf_no_friedman_results": "O teste de Friedman nÃ£o pÃ´de ser executado.",
        "pdf_no_posthoc_results": "Nenhum resultado de teste post-hoc encontrado (Friedman nÃ£o foi significativo ou ocorreu um erro).",

        # PDF Strings
        "pdf_report_title": "RELATÃ“RIO DE AVALIAÃ‡ÃƒO DE MODELOS ML - {}",
        "pdf_report_subtitle": "AvaliaÃ§Ã£o Nutricional AntropomÃ©trica",
        "pdf_equipment_heading": "CARACTERÃSTICAS DO EQUIPAMENTO DE PROCESSAMENTO",
        "pdf_component_header": "Componente",
        "pdf_specification_header": "EspecificaÃ§Ã£o",
        "pdf_processor": "Processador",
        "pdf_ram": "RAM instalada",
        "pdf_storage": "Armazenamento",
        "pdf_gpu": "Placa grÃ¡fica",
        "pdf_dataset_info_heading": "INFORMAÃ‡Ã•ES DO CONJUNTO DE DADOS",
        "pdf_num_records": "NÃºmero de registros: {}",
        "pdf_num_features": "NÃºmero de caracterÃ­sticas: {}",
        "pdf_train_percent": "Porcentagem de treinamento: {:.2f}%",
        "pdf_test_percent": "Porcentagem de teste: {:.2f}%",
        "pdf_training_times_heading": "TEMPOS DE TREINAMENTO",
        "pdf_metrics_heading": "MÃ‰TRICAS DE DESEMPENHO",
        "pdf_model_header": "Modelo",
        "pdf_time_seconds_header": "Tempo (segundos)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "RÂ²",
        "pdf_statistical_tests_heading": "TESTES ESTATÃSTICOS INFERENCIAIS",
        "pdf_residuals_normality_heading": "Teste de Normalidade dos ResÃ­duos:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-valor = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-valor = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk nÃ£o pÃ´de ser executado: {}",
        "pdf_zero_std_note": "{}: ResÃ­duos com desvio padrÃ£o zero (todos os valores sÃ£o iguais), o teste de normalidade nÃ£o pode ser realizado.",
        "pdf_no_stats_found": "Nenhum resultado de teste estatÃ­stico encontrado para {}.",
        "pdf_additional_visualizations": "VISUALIZAÃ‡Ã•ES ADICIONAIS",
        "pdf_confusion_matrices": "Matrizes de ConfusÃ£o",
        "pdf_confusion_matrix_for": "Matriz de ConfusÃ£o para {}:",
        "pdf_confusion_matrix_warning": "Aviso: Matriz de ConfusÃ£o para {} nÃ£o encontrada em {}",
        "pdf_performance_graphs": "GrÃ¡ficos de Desempenho do Modelo",
        "pdf_graphs_for_model": "GrÃ¡ficos para {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Aviso: GrÃ¡fico '{}' para {} nÃ£o encontrado em {}",
        "pdf_target_suffix_warning": "Aviso: Nenhum sufixo encontrado para o alvo '{}'. GrÃ¡ficos especÃ­ficos nÃ£o serÃ£o adicionados.",
        "pdf_residuals_graphs_heading": "GRÃFICOS DE RESÃDUOS"
    },
    "ko": { # Korean
        "page_title": "ML ëª¨ë¸ í‰ê°€ - ì˜ì–‘ í‰ê°€",
        "app_title": "ğŸ§¬ ì¸ì²´ ì¸¡ì • ì˜ì–‘ í‰ê°€ë¥¼ ìœ„í•œ ML ëª¨ë¸ í‰ê°€",
        "app_description": "---",
        "sidebar_title": "âš™ï¸ ì„¤ì •",
        "select_language_label": "ì–¸ì–´ ì„ íƒ:",
        "data_load_section": "ë°ì´í„° ë¡œë“œ",
        "data_loaded_success": "âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ",
        "records_label": "ğŸ“Š ê¸°ë¡:",
        "columns_label": "ğŸ“‹ ì—´:",
        "file_not_found_error": "í˜„ì¬ í´ë”ì—ì„œ 'datos_pacientes2.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "file_load_error": "íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {}",
        "dataset_info_section": "ğŸ“‹ ë°ì´í„°ì…‹ ì •ë³´",
        "first_rows_label": "**ì²« 5í–‰:**",
        "statistical_info_label": "**í†µê³„ ì •ë³´:**",
        "target_variables_section": "ğŸ¯ ëŒ€ìƒ ë³€ìˆ˜ í‰ê°€",
        "start_evaluation_button": "ğŸš€ ëª¨ë¸ í‰ê°€ ì‹œì‘",
        "preprocessing_spinner": "ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...",
        "column_not_found_error": "ì²˜ë¦¬ëœ ë°ì´í„°ì—ì„œ ì—´ '{}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "data_split_section": "ğŸ—‚ï¸ {} ì— ëŒ€í•œ ë°ì´í„° ë¶„í• ",
        "train_percent": "**í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨:** {}%",
        "test_percent": "**í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨:** {}%",
        "model_training_section": "ğŸ¤– {} ì— ëŒ€í•œ ëª¨ë¸ í›ˆë ¨",
        "training_spinner": "{} ì— ëŒ€í•œ ëª¨ë¸ í›ˆë ¨ ì¤‘...",
        "training_complete_success": "âœ… {} ì— ëŒ€í•œ ëª¨ë¸ í›ˆë ¨ ì„±ê³µ",
        "metrics_section": "ğŸ“Š ì„±ëŠ¥ ì§€í‘œ",
        "training_times_section": "â±ï¸ í›ˆë ¨ ì‹œê°„",
        "model_label": "ëª¨ë¸",
        "time_seconds_label": "ì‹œê°„ (ì´ˆ)",
        "statistical_tests_section": "ğŸ“ˆ ì¶”ë¡  í†µê³„ í…ŒìŠ¤íŠ¸",
        "statistical_tests_spinner": "{} ì— ëŒ€í•œ í†µê³„ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ ì¤‘...",
        "residuals_normality_test": "ì”ì°¨ ì •ê·œì„± í…ŒìŠ¤íŠ¸:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-ê°’ = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-ê°’ = {:.4f} ({})",
        "normal_interpretation": "âœ… ì •ìƒ",
        "not_normal_interpretation": "âŒ ë¹„ì •ìƒ",
        "shapiro_wilk_error": "{}: Shapiro-Wilk ì„(ë¥¼) ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}",
        "zero_std_error": "{}: ì”ì°¨ì˜ í‘œì¤€ í¸ì°¨ê°€ 0ì…ë‹ˆë‹¤ (ëª¨ë“  ê°’ì´ ë™ì¼í•¨). ì •ê·œì„± í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "no_statistical_results": "{} ì— ëŒ€í•œ í†µê³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "evaluation_complete_success": "ğŸ‰ ëª¨ë“  ëŒ€ìƒ ë³€ìˆ˜ì— ëŒ€í•œ ëª¨ë¸ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
        "download_reports_section": "ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
        "download_pdf_link": "ğŸ“¥ {} ì— ëŒ€í•œ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
        "pdf_generation_error": "{} ì— ëŒ€í•œ PDF ë³´ê³ ì„œ ìƒì„± ë˜ëŠ” ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {}",
        "dataset_load_error": "ë°ì´í„°ì…‹ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'datos_pacientes.csv' íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.",
        "training_linear_regression": "ğŸ”„ ì„ í˜• íšŒê·€ í›ˆë ¨ ì¤‘...",
        "training_random_forest": "ğŸ”„ ëœë¤ í¬ë ˆìŠ¤íŠ¸ í›ˆë ¨ ì¤‘...",
        "training_xgboost": "ğŸ”„ XGBoost í›ˆë ¨ ì¤‘...",
        "processed_columns": "ì²˜ë¦¬ëœ ì—´:",
        "residuals_histogram_title": "{} ì— ëŒ€í•œ ì”ì°¨ íˆìŠ¤í† ê·¸ë¨",
        "qq_plot_title": "{} ì— ëŒ€í•œ ì”ì°¨ Q-Q í”Œë¡¯",
        "residuals_vs_predictions_title": "{} ì— ëŒ€í•œ ì”ì°¨ ëŒ€ ì˜ˆì¸¡",
        "residuals_label": "ì”ì°¨",
        "frequency_label": "ë¹ˆë„",
        "predicted_values_label": "ì˜ˆì¸¡ ê°’",
        "friedman_test_heading": "í”„ë¦¬ë“œë§Œ í…ŒìŠ¤íŠ¸",
        "friedman_result": "í”„ë¦¬ë“œë§Œ í…ŒìŠ¤íŠ¸ ê²°ê³¼: ì¹´ì´ì œê³± = {:.4f}, p-ê°’ = {:.4f} ({})",
        "friedman_significant": "ìœ ì˜ë¯¸",
        "friedman_not_significant_interpret": "ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ",
        "friedman_not_enough_models": "í”„ë¦¬ë“œë§Œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ìµœì†Œ 3ê°œì˜ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "friedman_data_error": "í”„ë¦¬ë“œë§Œ ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {}",
        "friedman_error": "í”„ë¦¬ë“œë§Œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {}",
        "friedman_not_significant": "í”„ë¦¬ë“œë§Œ í…ŒìŠ¤íŠ¸ê°€ ìœ ì˜ë¯¸í•˜ì§€ ì•Šì•„ ì‚¬í›„ í…ŒìŠ¤íŠ¸ê°€ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
        "posthoc_heading": "ì‚¬í›„ í…ŒìŠ¤íŠ¸ (Nemenyi)",
        "nemenyi_intro": "Nemenyi ì‚¬í›„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (p-ê°’):",
        "pdf_friedman_test_heading": "í”„ë¦¬ë“œë§Œ í…ŒìŠ¤íŠ¸",
        "pdf_friedman_result": "ì¹´ì´ì œê³± í†µê³„ëŸ‰ = {:.4f}, p-ê°’ = {:.4f} ({})",
        "pdf_posthoc_heading": "ì‚¬í›„ í…ŒìŠ¤íŠ¸ (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi ì‚¬í›„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (p-ê°’):",
        "pdf_no_friedman_results": "í”„ë¦¬ë“œë§Œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.",
        "pdf_no_posthoc_results": "ì‚¬í›„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (í”„ë¦¬ë“œë§Œ í…ŒìŠ¤íŠ¸ê°€ ìœ ì˜ë¯¸í•˜ì§€ ì•Šê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤).",

        # PDF Strings
        "pdf_report_title": "ML ëª¨ë¸ í‰ê°€ ë³´ê³ ì„œ - {}",
        "pdf_report_subtitle": "ì¸ì²´ ì¸¡ì • ì˜ì–‘ í‰ê°€",
        "pdf_equipment_heading": "ì²˜ë¦¬ ì¥ë¹„ íŠ¹ì„±",
        "pdf_component_header": "êµ¬ì„± ìš”ì†Œ",
        "pdf_specification_header": "ì‚¬ì–‘",
        "pdf_processor": "í”„ë¡œì„¸ì„œ",
        "pdf_ram": "ì„¤ì¹˜ëœ RAM",
        "pdf_storage": "ì €ì¥ ê³µê°„",
        "pdf_gpu": "ê·¸ë˜í”½ ì¹´ë“œ",
        "pdf_dataset_info_heading": "ë°ì´í„°ì…‹ ì •ë³´",
        "pdf_num_records": "ê¸°ë¡ ìˆ˜: {}",
        "pdf_num_features": "íŠ¹ì§• ìˆ˜: {}",
        "pdf_train_percent": "í›ˆë ¨ ë¹„ìœ¨: {:.2f}%",
        "pdf_test_percent": "í…ŒìŠ¤íŠ¸ ë¹„ìœ¨: {:.2f}%",
        "pdf_training_times_heading": "í›ˆë ¨ ì‹œê°„",
        "pdf_metrics_heading": "ì„±ëŠ¥ ì§€í‘œ",
        "pdf_model_header": "ëª¨ë¸",
        "pdf_time_seconds_header": "ì‹œê°„ (ì´ˆ)",
        "pdf_mse": "í‰ê·  ì œê³± ì˜¤ì°¨ (MSE)",
        "pdf_rmse": "í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE)",
        "pdf_mae": "í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE)",
        "pdf_r2": "ê²°ì • ê³„ìˆ˜ (RÂ²)",
        "pdf_statistical_tests_heading": "ì¶”ë¡  í†µê³„ í…ŒìŠ¤íŠ¸",
        "pdf_residuals_normality_heading": "ì”ì°¨ ì •ê·œì„± í…ŒìŠ¤íŠ¸:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-ê°’ = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-ê°’ = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk ì„(ë¥¼) ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}",
        "pdf_zero_std_note": "{}: ì”ì°¨ì˜ í‘œì¤€ í¸ì°¨ê°€ 0ì…ë‹ˆë‹¤ (ëª¨ë“  ê°’ì´ ë™ì¼í•¨). ì •ê·œì„± í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "pdf_no_stats_found": "{} ì— ëŒ€í•œ í†µê³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "pdf_additional_visualizations": "ì¶”ê°€ ì‹œê°í™”",
        "pdf_confusion_matrices": "í˜¼ë™ í–‰ë ¬",
        "pdf_confusion_matrix_for": "{} ì— ëŒ€í•œ í˜¼ë™ í–‰ë ¬:",
        "pdf_confusion_matrix_warning": "ê²½ê³ : {} ì—ì„œ {} ì— ëŒ€í•œ í˜¼ë™ í–‰ë ¬ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "pdf_performance_graphs": "ëª¨ë¸ ì„±ëŠ¥ ê·¸ë˜í”„",
        "pdf_graphs_for_model": "{} ({}) ì— ëŒ€í•œ ê·¸ë˜í”„:",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "ê²½ê³ : {} ì—ì„œ {} ì— ëŒ€í•œ '{}' ê·¸ë˜í”„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "pdf_target_suffix_warning": "ê²½ê³ : ëŒ€ìƒ '{}' ì— ëŒ€í•œ ì ‘ë¯¸ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŠ¹ì • ê·¸ë˜í”„ëŠ” ì¶”ê°€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "pdf_residuals_graphs_heading": "ì”ì°¨ ê·¸ë˜í”„"
    }
}

# --- Initialize session state for language if not already set ---
if 'lang' not in st.session_state:
    st.session_state.lang = "es" # Default to Spanish

current_lang = LANGUAGES[st.session_state.lang]

# ConfiguraciÃ³n de la pÃ¡gina (needs to be here to use current_lang)
st.set_page_config(
    page_title=current_lang["page_title"],
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# TÃ­tulo principal
st.title(current_lang["app_title"])
st.markdown(current_lang["app_description"])

# --- Funciones auxiliares ---
@st.cache_data
def load_data(current_lang):
    """Cargar datos del CSV"""
    try:
        df = pd.read_csv('datos_pacientes2.csv')
        return df
    except FileNotFoundError:
        st.error(current_lang["file_not_found_error"])
        return None
    except Exception as e:
        st.error(current_lang["file_load_error"].format(str(e)))
        return None

def preprocess_data(df, current_lang):
    """Preprocesamiento de datos"""
    df_processed = df.copy()

    # Codificar variables categÃ³ricas
    label_encoders = {}
    for column in df_processed.columns:
        if df_processed[column].dtype == 'object':
            le = LabelEncoder()
            df_processed[column] = le.fit_transform(df_processed[column].astype(str))
            label_encoders[column] = le

    # Manejar valores nulos
    df_processed = df_processed.fillna(df_processed.mean(numeric_only=True))
    
    st.write(current_lang["processed_columns"], df_processed.columns.tolist())
    
    return df_processed, label_encoders

def train_models(X_train, X_test, y_train, y_test, current_lang):
    """Entrenar los modelos y medir tiempos"""
    models = {}
    training_times = {}
    predictions = {}
    metrics = {}
    
    # RegresiÃ³n Lineal
    st.write(current_lang["training_linear_regression"])
    start_time = time.time()
    lr_model = LinearRegression()
    lr_model.fit(X_train, y_train)
    training_times['RegresiÃ³n Lineal'] = time.time() - start_time
    
    lr_pred = lr_model.predict(X_test)
    models['RegresiÃ³n Lineal'] = lr_model
    predictions['RegresiÃ³n Lineal'] = lr_pred
    
    # Random Forest
    st.write(current_lang["training_random_forest"])
    start_time = time.time()
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)
    training_times['Random Forest'] = time.time() - start_time
    
    rf_pred = rf_model.predict(X_test)
    models['Random Forest'] = rf_model
    predictions['Random Forest'] = rf_pred
    
    # XGBoost
    st.write(current_lang["training_xgboost"])
    start_time = time.time()
    xgb_model = XGBRegressor(random_state=42)
    xgb_model.fit(X_train, y_train)
    training_times['XGBoost'] = time.time() - start_time
    
    xgb_pred = xgb_model.predict(X_test)
    models['XGBoost'] = xgb_model
    predictions['XGBoost'] = xgb_pred
    
    # Calcular mÃ©tricas
    for name, pred in predictions.items():
        mse = mean_squared_error(y_test, pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, pred)
        r2 = r2_score(y_test, pred)
        
        metrics[name] = {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'RÂ²': r2
        }
    
    return models, predictions, metrics, training_times

def statistical_tests(predictions, y_test, current_lang):
    """Realizar pruebas estadÃ­sticas inferenciales, incluyendo Friedman y post-hoc."""
    results = {}
    
    st.write(current_lang["statistical_tests_spinner"].format("")) # General message for tests
    
    # --- Pruebas de normalidad de residuos (ya existentes) ---
    for name, pred in predictions.items():
        residuals = y_test - pred
        
        if len(residuals) <= 5000 and len(residuals) > 3:
            try:
                shapiro_stat, shapiro_p = stats.shapiro(residuals)
                results[name] = {
                    'shapiro_stat': shapiro_stat,
                    'shapiro_p': shapiro_p,
                    'test': 'Shapiro-Wilk'
                }
            except Exception as e:
                results[name] = {
                    'note': current_lang["shapiro_wilk_error"].format(name, str(e)),
                    'test': 'N/A'
                }
        else: # Para N > 5000, usamos Kolmogorov-Smirnov
            if residuals.std() > 0:
                ks_stat, ks_p = stats.kstest(residuals, 'norm', args=(residuals.mean(), residuals.std()))
                results[name] = {
                    'ks_stat': ks_stat,
                    'ks_p': ks_p,
                    'test': 'Kolmogorov-Smirnov'
                }
            else:
                results[name] = {
                    'note': current_lang["zero_std_error"].format(name),
                    'test': 'N/A'
                }
    
    # --- Prueba de Friedman y Post-Hoc ---
    model_names = list(predictions.keys())
    
    if len(model_names) >= 3: # Friedman requiere al menos 3 grupos
        try:
            # Step 1: Collect absolute errors for each model, ensuring they align by index
            # This is the correct way to build the DataFrame for scikit-posthocs
            df_errors_for_friedman = pd.DataFrame({
                name: np.abs(y_test - predictions[name]) for name in model_names
            })
            
            # Check if all columns have the same number of rows as y_test
            if not df_errors_for_friedman.empty and df_errors_for_friedman.shape[0] == len(y_test):
                # The data for scipy.stats.friedmanchisquare should be unpacked as separate arrays
                # You can get this by converting the DataFrame to a list of its column arrays
                data_for_scipy_friedman = [df_errors_for_friedman[col].values for col in df_errors_for_friedman.columns]

                friedman_stat, friedman_p = stats.friedmanchisquare(*data_for_scipy_friedman) # Unpack the list of arrays
                
                results['Friedman'] = {
                    'stat': friedman_stat,
                    'p_value': friedman_p,
                    'model_names': model_names # Guardar nombres para referencia
                }

                # If Friedman is significant, execute post-hoc tests (Nemenyi)
                if friedman_p < 0.05:
                    # sp.posthoc_nemenyi_friedman works directly with the DataFrame of errors
                    # Rows are observations, columns are groups (models)
                    posthoc_df = sp.posthoc_nemenyi_friedman(df_errors_for_friedman)
                    
                    posthoc_df.columns = model_names
                    posthoc_df.index = model_names
                    results['Nemenyi_posthoc'] = posthoc_df.to_string() # Guardar como string para el PDF
                else:
                    results['Nemenyi_posthoc'] = current_lang["friedman_not_significant"]

            else:
                results['Friedman'] = {
                    'note': current_lang["friedman_data_error"].format("longitudes de datos diferentes o DataFrame vacÃ­o")
                }

        except Exception as e:
            results['Friedman'] = {'note': current_lang["friedman_error"].format(str(e))}
    else:
        results['Friedman'] = {'note': current_lang["friedman_not_enough_models"]}

    return results


def add_images_to_pdf(story, styles, target_name, current_lang):
    """Agrega imÃ¡genes al PDF desde las rutas especificadas."""
    story.append(Spacer(1, 24))
    story.append(Paragraph(current_lang["pdf_additional_visualizations"], styles['Heading2']))
    
    model_folder_map = {
        'RegresiÃ³n Lineal': 'RegresionLinealMulti',
        'Random Forest': 'RandomForest',
        'XGBoost': 'XGBoost'
    }

    target_suffix_map = {
        'Valoracion_Talla_Edad': 'talla_edad',
        'Valoracion_IMC_Talla': 'imc_talla'
    }
    
    current_target_suffix = target_suffix_map.get(target_name, '').lower()

    # --- Matrices de ConfusiÃ³n ---
    story.append(Spacer(1, 12))
    story.append(Paragraph(current_lang["pdf_confusion_matrices"], styles['Heading3']))
    
    confusion_matrix_files = {
        'RegresiÃ³n Lineal': 'confusion_regresion.png',
        'Random Forest': 'confusion_randomforest.png',
        'XGBoost': 'confusion_xgboost.png'
    }

    for model_name, filename in confusion_matrix_files.items():
        filepath = os.path.join('confusion_matrices', filename)
        if os.path.exists(filepath):
            story.append(Paragraph(current_lang["pdf_confusion_matrix_for"].format(model_name), styles['Normal']))
            img = Image(filepath, width=3.5 * inch, height=3.0 * inch)
            story.append(img)
            story.append(Spacer(1, 6))
        else:
            story.append(Paragraph(current_lang["pdf_confusion_matrix_warning"].format(model_name, filepath), styles['Normal']))
            story.append(Spacer(1, 6))

    # --- GrÃ¡ficos de Rendimiento EspecÃ­ficos por Modelo ---
    story.append(Spacer(1, 18))
    story.append(Paragraph(current_lang["pdf_performance_graphs"], styles['Heading3']))

    for model_name, folder_name in model_folder_map.items():
        if current_target_suffix:
            story.append(Spacer(1, 12))
            story.append(Paragraph(current_lang["pdf_graphs_for_model"].format(model_name, target_name.replace('_', ' ')), styles['Heading4']))
            
            plot_types = [
                f'Curvas_precision_recall_multiclase_modelo_{current_target_suffix}.png',
                f'Curvas_roc_multiclase_modelo_{current_target_suffix}.png',
                f'Graficos_calibracion_{current_target_suffix}.png'
            ]

            for plot_file in plot_types:
                filepath = os.path.join('Graficas', folder_name, plot_file)
                if os.path.exists(filepath):
                    friendly_title = plot_file.replace('_', ' ').replace('.png', '').replace(f'modelo {current_target_suffix}', '').strip()
                    story.append(Paragraph(current_lang["pdf_graph_title_prefix"].format(friendly_title), styles['Normal']))
                    img = Image(filepath, width=5.0 * inch, height=3.5 * inch)
                    story.append(img)
                    story.append(Spacer(1, 6))
                else:
                    story.append(Paragraph(current_lang["pdf_graph_warning"].format(plot_file, model_name, filepath), styles['Normal']))
                    story.append(Spacer(1, 6))
        else:
            story.append(Paragraph(current_lang["pdf_target_suffix_warning"].format(target_name), styles['Normal']))
            story.append(Spacer(1, 6))
    
    # --- NUEVO: GrÃ¡ficos de Residuos ---
    story.append(Spacer(1, 18))
    story.append(Paragraph(current_lang["pdf_residuals_graphs_heading"], styles['Heading3']))

    # Mapeo de nombres de modelo a nombres de archivo para los nuevos grÃ¡ficos de residuos
    # AsegÃºrate de que estos nombres de archivo coincidan con los generados en generate_residual_plots
    residual_plot_types = {
        'histograma_residuos': current_lang["residuals_histogram_title"].format(""),
        'qq_plot_residuos': current_lang["qq_plot_title"].format(""),
        'residuos_vs_predicciones': current_lang["residuals_vs_predictions_title"].format("")
    }

    if current_target_suffix: # Asegura que tenemos un sufijo de objetivo vÃ¡lido
        for model_name_raw, folder_name in model_folder_map.items():
            model_name_safe = model_name_raw.replace(" ", "_").lower()
            story.append(Spacer(1, 12))
            story.append(Paragraph(current_lang["pdf_graphs_for_model"].format(model_name_raw, target_name.replace('_', ' ')), styles['Heading4']))

            for plot_file_prefix, plot_title_template in residual_plot_types.items():
                filepath = os.path.join('Graficas', f'Residuals_{current_target_suffix}', folder_name, 
                                        f'{plot_file_prefix}_{model_name_safe}_{current_target_suffix}.png')
                
                if os.path.exists(filepath):
                    # Solo necesitas el nombre del modelo aquÃ­ para el tÃ­tulo
                    friendly_title = plot_title_template.replace("{}", model_name_raw) 
                    story.append(Paragraph(current_lang["pdf_graph_title_prefix"].format(friendly_title), styles['Normal']))
                    img = Image(filepath, width=5.0 * inch, height=3.5 * inch)
                    story.append(img)
                    story.append(Spacer(1, 6))
                else:
                    story.append(Paragraph(current_lang["pdf_graph_warning"].format(f"{plot_file_prefix}_{model_name_safe}_{current_target_suffix}.png", model_name_raw, filepath), styles['Normal']))
                    story.append(Spacer(1, 6))
    else:
        story.append(Paragraph(current_lang["pdf_target_suffix_warning"].format(target_name), styles['Normal']))
        story.append(Spacer(1, 6))
    # --- FIN NUEVO ---

def generate_residual_plots(predictions, y_test, target_name, current_lang):
    """
    Genera histogramas, Q-Q plots y grÃ¡ficos de residuos vs. predicciones
    para cada modelo y guarda las imÃ¡genes en la carpeta Graficas.
    """
    plots_saved_paths = []
    
    # Mapeo de nombres de modelo a nombres de carpeta
    model_folder_map = {
        'RegresiÃ³n Lineal': 'RegresionLinealMulti',
        'Random Forest': 'RandomForest',
        'XGBoost': 'XGBoost'
    }

    # Definir sufijo para las carpetas dentro de Graficas
    target_suffix = {
        'Valoracion_Talla_Edad': 'talla_edad',
        'Valoracion_IMC_Talla': 'imc_talla'
    }.get(target_name, target_name.lower().replace('_', ''))

    base_dir = os.path.join('Graficas', f'Residuals_{target_suffix}')
    os.makedirs(base_dir, exist_ok=True) # Asegurarse de que la carpeta base exista

    for model_name, pred in predictions.items():
        residuals = y_test - pred
        
        # Obtener la carpeta especÃ­fica del modelo dentro de 'Graficas'
        model_sub_folder = model_folder_map.get(model_name, model_name.replace(' ', ''))
        save_dir = os.path.join(base_dir, model_sub_folder)
        os.makedirs(save_dir, exist_ok=True) # Crear subcarpeta para cada modelo

        # 1. Histograma de Residuos
        plt.figure(figsize=(8, 6))
        sns.histplot(residuals, kde=True)
        plt.title(f'{current_lang["pdf_report_title"].format(target_name.replace("_", " "))}\n{current_lang["residuals_histogram_title"].format(model_name)}')
        plt.xlabel(current_lang["residuals_label"])
        plt.ylabel(current_lang["frequency_label"])
        hist_path = os.path.join(save_dir, f'histograma_residuos_{model_name.replace(" ", "_").lower()}_{target_suffix}.png')
        plt.savefig(hist_path)
        plt.close()
        plots_saved_paths.append(hist_path)

        # 2. GrÃ¡fico Q-Q
        plt.figure(figsize=(8, 6))
        sm.qqplot(residuals, line='s', fit=True)
        plt.title(f'{current_lang["pdf_report_title"].format(target_name.replace("_", " "))}\n{current_lang["qq_plot_title"].format(model_name)}')
        qq_path = os.path.join(save_dir, f'qq_plot_residuos_{model_name.replace(" ", "_").lower()}_{target_suffix}.png')
        plt.savefig(qq_path)
        plt.close()
        plots_saved_paths.append(qq_path)

        # 3. GrÃ¡fico de Residuos vs. Predicciones
        plt.figure(figsize=(8, 6))
        plt.scatter(pred, residuals, alpha=0.5)
        plt.axhline(0, color='red', linestyle='--', linewidth=2)
        plt.title(f'{current_lang["pdf_report_title"].format(target_name.replace("_", " "))}\n{current_lang["residuals_vs_predictions_title"].format(model_name)}')
        plt.xlabel(current_lang["predicted_values_label"])
        plt.ylabel(current_lang["residuals_label"])
        plt.grid(True)
        residuals_vs_pred_path = os.path.join(save_dir, f'residuos_vs_predicciones_{model_name.replace(" ", "_").lower()}_{target_suffix}.png')
        plt.savefig(residuals_vs_pred_path)
        plt.close()
        plots_saved_paths.append(residuals_vs_pred_path)
        
    return plots_saved_paths

def create_pdf_report(metrics, training_times, statistical_results, df_info, target_name, train_size_percent, test_size_percent, current_lang):
    """Crear reporte PDF, incluyendo Friedman y post-hoc."""
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []
    
    # TÃ­tulo (sin cambios)
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=16,
        spaceAfter=30,
        alignment=1
    )
    
    story.append(Paragraph(current_lang["pdf_report_title"].format(target_name.replace('_', ' ').upper()), title_style))
    story.append(Paragraph(current_lang["pdf_report_subtitle"], styles['Heading2']))
    story.append(Spacer(1, 12))
    
    # InformaciÃ³n del equipo (sin cambios)
    story.append(Paragraph(current_lang["pdf_equipment_heading"], styles['Heading2']))
    equipment_data = [
        [current_lang["pdf_component_header"], current_lang["pdf_specification_header"]],
        [current_lang["pdf_processor"], 'Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz'],
        [current_lang["pdf_ram"], '8,00 GB (7,83 GB usable)'],
        [current_lang["pdf_storage"], '932 GB HDD, 238 GB SSD NVMe'],
        [current_lang["pdf_gpu"], 'NVIDIA GeForce GTX 1650 (4 GB)']
    ]
    
    equipment_table = Table(equipment_data, colWidths=[2*inch, 4*inch])
    equipment_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(equipment_table)
    story.append(Spacer(1, 12))
    
    # InformaciÃ³n del dataset (sin cambios)
    story.append(Paragraph(current_lang["pdf_dataset_info_heading"], styles['Heading2']))
    story.append(Paragraph(current_lang["pdf_num_records"].format(df_info['rows']), styles['Normal']))
    story.append(Paragraph(current_lang["pdf_num_features"].format(df_info['columns']), styles['Normal']))
    story.append(Paragraph(current_lang["pdf_train_percent"].format(train_size_percent), styles['Normal']))
    story.append(Paragraph(current_lang["pdf_test_percent"].format(test_size_percent), styles['Normal']))
    story.append(Spacer(1, 12))
    
    # Tiempos de entrenamiento (sin cambios)
    story.append(Paragraph(current_lang["pdf_training_times_heading"], styles['Heading2']))
    time_data = [[current_lang["pdf_model_header"], current_lang["pdf_time_seconds_header"]]]
    for model, time_val in training_times.items():
        time_data.append([model, f"{time_val:.4f}"])
    
    time_table = Table(time_data, colWidths=[3*inch, 2*inch])
    time_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(time_table)
    story.append(Spacer(1, 12))
    
    # MÃ©tricas de rendimiento (sin cambios)
    story.append(Paragraph(current_lang["pdf_metrics_heading"], styles['Heading2']))
    metrics_data = [[current_lang["pdf_model_header"], current_lang["pdf_mse"], current_lang["pdf_rmse"], current_lang["pdf_mae"], current_lang["pdf_r2"]]]
    for model, metric in metrics.items():
        metrics_data.append([
            model,
            f"{metric['MSE']:.4f}",
            f"{metric['RMSE']:.4f}",
            f"{metric['MAE']:.4f}",
            f"{metric['RÂ²']:.4f}"
        ])
    
    metrics_table = Table(metrics_data, colWidths=[1.5*inch, 1*inch, 1*inch, 1*inch, 1*inch])
    metrics_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 9),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(metrics_table)
    story.append(Spacer(1, 12))
    
    # Pruebas estadÃ­sticas (modificado para Friedman)
    story.append(Paragraph(current_lang["pdf_statistical_tests_heading"], styles['Heading2']))
    
    story.append(Paragraph(current_lang["pdf_residuals_normality_heading"], styles['Heading3']))
    for model_name_for_stats in metrics.keys(): # Iterar sobre los modelos para la secciÃ³n de normalidad
        if model_name_for_stats in statistical_results:
            if 'note' in statistical_results[model_name_for_stats]:
                story.append(Paragraph(statistical_results[model_name_for_stats]['note'], styles['Normal']))
            elif statistical_results[model_name_for_stats]['test'] == 'Shapiro-Wilk':
                p_val = statistical_results[model_name_for_stats]['shapiro_p']
                interpretation = current_lang["normal_interpretation"] if p_val > 0.05 else current_lang["not_normal_interpretation"]
                story.append(Paragraph(current_lang["pdf_shapiro_wilk_result"].format(model_name_for_stats, p_val, interpretation), styles['Normal']))
            else: # Kolmogorov-Smirnov
                p_val = statistical_results[model_name_for_stats]['ks_p']
                interpretation = current_lang["normal_interpretation"] if p_val > 0.05 else current_lang["not_normal_interpretation"]
                story.append(Paragraph(current_lang["pdf_kolmogorov_smirnov_result"].format(model_name_for_stats, p_val, interpretation), styles['Normal']))
        else:
            story.append(Paragraph(current_lang["pdf_no_stats_found"].format(model_name_for_stats), styles['Normal']))
    story.append(Spacer(1, 12))

    # --- NUEVA SECCIÃ“N: Prueba de Friedman y Post-Hoc ---
    story.append(Paragraph(current_lang["pdf_friedman_test_heading"], styles['Heading3']))
    if 'Friedman' in statistical_results:
        friedman_res = statistical_results['Friedman']
        if 'note' in friedman_res:
            story.append(Paragraph(friedman_res['note'], styles['Normal']))
        else:
            story.append(Paragraph(current_lang["pdf_friedman_result"].format(
                friedman_res['stat'], friedman_res['p_value'], # Pass the values directly
                current_lang["friedman_significant"] if friedman_res['p_value'] < 0.05 else current_lang["friedman_not_significant_interpret"]
            ), styles['Normal']))
            
            story.append(Spacer(1, 6))
            story.append(Paragraph(current_lang["pdf_posthoc_heading"], styles['Heading4']))
            if 'Nemenyi_posthoc' in statistical_results:
                story.append(Paragraph(current_lang["pdf_nemenyi_intro"], styles['Normal']))
                # Use Preformatted to keep the table-like structure of the string
                story.append(Preformatted(statistical_results['Nemenyi_posthoc'], styles['Code']))
            else:
                story.append(Paragraph(current_lang["pdf_no_posthoc_results"], styles['Normal']))
    else:
        story.append(Paragraph(current_lang["pdf_no_friedman_results"], styles['Normal']))
    story.append(Spacer(1, 12))
    # --- FIN NUEVA SECCIÃ“N ---

    # --- AGREGAR IMÃGENES AL PDF (sin cambios) ---
    add_images_to_pdf(story, styles, target_name, current_lang) # Pass current_lang to image function

    doc.build(story)
    buffer.seek(0)
    return buffer

# Interfaz principal
def main():
    # Update current_lang at the beginning of main to reflect any language changes from sidebar
    global current_lang
    # Ensure 'lang' is initialized in session_state, defaulting to 'es' if not set
    if 'lang' not in st.session_state:
        st.session_state.lang = "es"
        
    current_lang = LANGUAGES[st.session_state.lang]

    st.sidebar.title(current_lang["sidebar_title"])
    
    # Define the language options to be displayed and their corresponding internal keys
    language_options_display = {
        "EspaÃ±ol": "es",
        "English": "en",
        "ä¸­æ–‡ (Chino)": "zh",
        "Deutsch (AlemÃ¡n)": "de",
        "æ—¥æœ¬èª (JaponÃ©s)": "ja",
        "FranÃ§ais (FrancÃ©s)": "fr",
        "PortuguÃªs (PortuguÃ©s)": "pt",
        "í•œêµ­ì–´ (Coreano)": "ko"
    }

    # Get the display name for the current language key in session state
    current_lang_display = next(
        (display_name for display_name, lang_key in language_options_display.items()
         if lang_key == st.session_state.lang),
        "EspaÃ±ol" # Default to 'EspaÃ±ol' if the current lang key isn't found in display options
    )

    # Language selection selectbox
    language_selection_display = st.sidebar.selectbox(
        current_lang["select_language_label"], # This label should be defined in your LANGUAGES dict
        options=list(language_options_display.keys()),
        index=list(language_options_display.keys()).index(current_lang_display),
        key="language_selection"
    )

    # Get the internal language key based on the user's selection
    selected_lang_key = language_options_display[language_selection_display]

    # If the selected language is different from the current one, update and rerun
    if selected_lang_key != st.session_state.lang:
        st.session_state.lang = selected_lang_key
        st.rerun() # Rerun to update all texts
            
    # Re-fetch current_lang after potential rerun (ensures current_lang is correct after a language change)
    current_lang = LANGUAGES[st.session_state.lang]

    # Cargar datos
    st.subheader(current_lang["data_load_section"])
    df = load_data(current_lang)
    
    if df is not None:
        st.sidebar.success(current_lang["data_loaded_success"])
        st.sidebar.write(current_lang["records_label"].format(df.shape[0]))
        st.sidebar.write(current_lang["columns_label"].format(df.shape[1]))
        
        # Mostrar informaciÃ³n del dataset
        st.subheader(current_lang["dataset_info_section"])
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(current_lang["first_rows_label"])
            st.dataframe(df.head())
        
        with col2:
            st.write(current_lang["statistical_info_label"])
            st.dataframe(df.describe())
        
        # SelecciÃ³n de variables objetivo
        st.subheader(current_lang["target_variables_section"])
        target_columns = ['Valoracion_Talla_Edad', 'Valoracion_IMC_Talla']

        if "evaluated_data" not in st.session_state:
            st.session_state.evaluated_data = {}

        if st.button(current_lang["start_evaluation_button"], type="primary"):
            st.session_state.evaluated_data = {} # Reset previous data
            # Preprocesar datos
            with st.spinner(current_lang["preprocessing_spinner"]):
                df_processed, label_encoders = preprocess_data(df, current_lang)
                
                # Verificar si las columnas objetivo estÃ¡n en el DataFrame procesado
                for target_column in target_columns:
                    if target_column not in df_processed.columns:
                        st.error(current_lang["column_not_found_error"].format(target_column))
                        return # Exit if column not found

                    # Separar caracterÃ­sticas y variable objetivo
                    X = df_processed.drop(columns=[target_column])
                    y = df_processed[target_column]
                    
                    # DivisiÃ³n train/test
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=0.2, random_state=42
                    )
                    
                    # Calculate and display train/test percentages
                    train_size_percent = (len(X_train) / len(df_processed)) * 100
                    test_size_percent = (len(X_test) / len(df_processed)) * 100
                    
                    st.write(f"---")
                    st.subheader(current_lang["data_split_section"].format(target_column))
                    st.write(current_lang["train_percent"].format(train_size_percent))
                    st.write(current_lang["test_percent"].format(test_size_percent))
                    st.write(f"---")

                    # Entrenar modelos
                    st.subheader(current_lang["model_training_section"].format(target_column))
                    with st.spinner(current_lang["training_spinner"].format(target_column)):
                        models, predictions, metrics, training_times = train_models(
                            X_train, X_test, y_train, y_test, current_lang
                        )
                    
                    st.success(current_lang["training_complete_success"].format(target_column))
                    
                    # Store results in session state
                    st.session_state.evaluated_data[target_column] = {
                        'metrics': metrics,
                        'training_times': training_times,
                        'predictions': predictions,
                        'y_test': y_test, # Store y_test for statistical tests later
                        'train_size_percent': train_size_percent,
                        'test_size_percent': test_size_percent
                    }
                    
                    # Display metrics immediately after training for visual feedback
                    st.subheader(current_lang["metrics_section"])
                    metrics_df = pd.DataFrame(metrics).T
                    st.dataframe(metrics_df.style.highlight_min(axis=0, subset=['MSE', 'RMSE', 'MAE']).highlight_max(axis=0, subset=['RÂ²']))
                    
                    # Tiempos de entrenamiento
                    st.subheader(current_lang["training_times_section"])
                    time_df = pd.DataFrame(list(training_times.items()), columns=[current_lang["model_label"], current_lang["time_seconds_label"]])
                    st.dataframe(time_df)
                    
                    # Pruebas estadÃ­sticas
                    st.subheader(current_lang["statistical_tests_section"])
                    with st.spinner(current_lang["statistical_tests_spinner"].format(target_column)):
                        statistical_results = statistical_tests(predictions, y_test, current_lang)
                    
                    # Display statistical results
                    st.session_state.evaluated_data[target_column]['statistical_results'] = statistical_results
                    for model in models.keys():
                        if model in statistical_results:
                            if 'note' in statistical_results[model]:
                                st.write(f"- {statistical_results[model]['note']}")
                            elif statistical_results[model]['test'] == 'Shapiro-Wilk':
                                p_val = statistical_results[model]['shapiro_p']
                                interpretation = current_lang["normal_interpretation"] if p_val > 0.05 else current_lang["not_normal_interpretation"]
                                st.write(current_lang["shapiro_wilk_test"].format(model, p_val, interpretation))
                            else:
                                p_val = statistical_results[model]['ks_p']
                                interpretation = current_lang["normal_interpretation"] if p_val > 0.05 else current_lang["not_normal_interpretation"]
                                st.write(current_lang["kolmogorov_smirnov_test"].format(model, p_val, interpretation))
                        else:
                            st.write(current_lang["no_statistical_results"].format(model))
                    # --- NUEVO: Generar y guardar grÃ¡ficos de residuos ---
                    # Guardamos las rutas de los grÃ¡ficos generados para cada objetivo
                    st.session_state.evaluated_data[target_column]['residual_plots_paths'] = generate_residual_plots(
                        predictions, y_test, target_column, current_lang
                    )
            st.success(current_lang["evaluation_complete_success"])
            st.markdown("---") # Separator after all training is done

        # Display download buttons after all evaluations are done and stored in session_state
        if st.session_state.evaluated_data:
            st.subheader(current_lang["download_reports_section"])
            df_info = {'rows': df.shape[0], 'columns': df.shape[1]}
            for target_column, data in st.session_state.evaluated_data.items():
                metrics = data['metrics']
                training_times = data['training_times']
                statistical_results = data['statistical_results'] # Retrieved from session state
                train_size_percent = data['train_size_percent']
                test_size_percent = data['test_size_percent']

                try:
                    pdf_buffer = create_pdf_report(metrics, training_times, statistical_results, df_info, target_column, train_size_percent, test_size_percent, current_lang)
                    pdf_bytes = pdf_buffer.getvalue()
                    b64 = base64.b64encode(pdf_bytes).decode()
                    href = f'<a href="data:application/pdf;base64,{b64}" download="reporte_evaluacion_modelos_{target_column}.pdf">{current_lang["download_pdf_link"].format(target_column.replace("_", " "))}</a>'
                    st.markdown(href, unsafe_allow_html=True)
                except Exception as e:
                    st.error(current_lang["pdf_generation_error"].format(target_column, str(e)))

    else:
        st.error(current_lang["dataset_load_error"])

if __name__ == "__main__":
    main()