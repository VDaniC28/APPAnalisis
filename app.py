import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm # Necesario para el Q-Q plot
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler, LabelEncoder
import time
import warnings
from scipy import stats

from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image, Preformatted
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from reportlab.lib.units import inch

import scikit_posthocs as sp # Nueva importaci√≥n

import io
import base64
import os

warnings.filterwarnings('ignore')


# --- Language Configuration ---
LANGUAGES = {
    "es": {
        "page_title": "Evaluaci√≥n de Modelos ML - Valoraci√≥n Nutricional",
        "app_title": "üß¨ Evaluaci√≥n de Modelos ML para Valoraci√≥n Nutricional Antropom√©trica",
        "app_description": "---",
        "sidebar_title": "‚öôÔ∏è Configuraci√≥n",
        "select_language_label": "Selecciona Idioma:",
        "data_load_section": "Carga de Datos",
        "data_loaded_success": "‚úÖ Datos cargados correctamente",
        "records_label": "üìä Registros:",
        "columns_label": "üìã Columnas:",
        "file_not_found_error": "No se encontr√≥ el archivo 'datos_pacientes2.csv' en la carpeta actual.",
        "file_load_error": "Error al cargar el archivo: {}",
        "dataset_info_section": "üìã Informaci√≥n del Dataset",
        "first_rows_label": "**Primeras 5 filas:**",
        "statistical_info_label": "**Informaci√≥n estad√≠stica:**",
        "target_variables_section": "üéØ Evaluaci√≥n de Variables Objetivo",
        "start_evaluation_button": "üöÄ Iniciar Evaluaci√≥n de Modelos",
        "preprocessing_spinner": "Preprocesando datos...",
        "column_not_found_error": "La columna '{}' no se encontr√≥ en los datos procesados.",
        "data_split_section": "üóÇÔ∏è Divisi√≥n de Datos para {}",
        "train_percent": "**Porcentaje de datos de entrenamiento:** {}%",
        "test_percent": "**Porcentaje de datos de prueba:** {}%",
        "model_training_section": "ü§ñ Entrenamiento de Modelos para {}",
        "training_spinner": "Entrenando modelos para {}...",
        "training_complete_success": "‚úÖ Modelos entrenados exitosamente para {}",
        "metrics_section": "üìä M√©tricas de Rendimiento",
        "training_times_section": "‚è±Ô∏è Tiempos de Entrenamiento",
        "model_label": "Modelo",
        "time_seconds_label": "Tiempo (segundos)",
        "statistical_tests_section": "üìà Pruebas Estad√≠sticas Inferenciales",
        "statistical_tests_spinner": "Realizando pruebas estad√≠sticas para {}...",
        "residuals_normality_test": "Test de Normalidad de Residuos:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-value = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-value = {:.4f} ({})",
        "normal_interpretation": "‚úÖ Normal",
        "not_normal_interpretation": "‚ùå No Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk no pudo ejecutarse: {}",
        "zero_std_error": "{}: Residuos con desviaci√≥n est√°ndar cero (todos los valores son iguales), no se puede realizar test de normalidad.",
        "no_statistical_results": "No se encontraron resultados de pruebas estad√≠sticas para {}.",
        "evaluation_complete_success": "üéâ Evaluaci√≥n de modelos completada para todas las variables objetivo.",
        "download_reports_section": "üìÑ Descargar Reportes PDF",
        "download_pdf_link": "üì• Descargar Reporte PDF para {}",
        "pdf_generation_error": "Error al generar o descargar el reporte PDF para {}: {}",
        "dataset_load_error": "No se pudo cargar el dataset. Verifica que el archivo 'datos_pacientes.csv' est√© en la carpeta correcta.",
        "training_linear_regression": "üîÑ Entrenando Regresi√≥n Lineal...",
        "training_random_forest": "üîÑ Entrenando Random Forest...",
        "training_xgboost": "üîÑ Entrenando XGBoost...",
        "processed_columns": "Columnas procesadas:",
        "residuals_histogram_title": "Histograma de Residuos para {}",
        "qq_plot_title": "Gr√°fico Q-Q de Residuos para {}",
        "residuals_vs_predictions_title": "Residuos vs. Predicciones para {}",
        "residuals_label": "Residuos",
        "frequency_label": "Frecuencia",
        "predicted_values_label": "Valores Predichos",
        "friedman_test_heading": "Prueba de Friedman",
        "friedman_result": "Resultado de la prueba de Friedman: Chi-cuadrado = {:.4f}, p-valor = {:.4f} ({})",
        "friedman_significant": "Significativo",
        "friedman_not_significant_interpret": "No Significativo",
        "friedman_not_enough_models": "Se requieren al menos 3 modelos para ejecutar la prueba de Friedman.",
        "friedman_data_error": "Error al preparar los datos para Friedman: {}",
        "friedman_error": "Error al ejecutar la prueba de Friedman: {}",
        "friedman_not_significant": "La prueba de Friedman no fue significativa, no se realizan pruebas post-hoc.",
        "posthoc_heading": "Pruebas Post-Hoc (Nemenyi)",
        "nemenyi_intro": "Resultados de la prueba post-hoc de Nemenyi (valores p):",
        "pdf_friedman_test_heading": "PRUEBA DE FRIEDMAN",
        "pdf_friedman_result": "Estad√≠stico Chi-cuadrado = {:.4f}, p-valor = {:.4f} ({})",
        "pdf_posthoc_heading": "PRUEBAS POST-HOC (NEMENYI)",
        "pdf_nemenyi_intro": "Resultados de la prueba post-hoc de Nemenyi (valores p):",
        "pdf_no_friedman_results": "La prueba de Friedman no pudo ser ejecutada.",
        "pdf_no_posthoc_results": "No se encontraron resultados de pruebas post-hoc (Friedman no fue significativo o hubo un error).",

        # PDF Strings
        "pdf_report_title": "REPORTE DE EVALUACI√ìN DE MODELOS ML - {}",
        "pdf_report_subtitle": "Valoraci√≥n Nutricional Antropom√©trica",
        "pdf_equipment_heading": "CARACTER√çSTICAS DEL EQUIPO DE PROCESAMIENTO",
        "pdf_component_header": "Componente",
        "pdf_specification_header": "Especificaci√≥n",
        "pdf_processor": "Procesador",
        "pdf_ram": "RAM instalada",
        "pdf_storage": "Almacenamiento",
        "pdf_gpu": "Tarjeta gr√°fica",
        "pdf_dataset_info_heading": "INFORMACI√ìN DEL DATASET",
        "pdf_num_records": "N√∫mero de registros: {}",
        "pdf_num_features": "N√∫mero de caracter√≠sticas: {}",
        "pdf_train_percent": "Porcentaje de entrenamiento: {:.2f}%",
        "pdf_test_percent": "Porcentaje de prueba: {:.2f}%",
        "pdf_training_times_heading": "TIEMPOS DE ENTRENAMIENTO",
        "pdf_metrics_heading": "M√âTRICAS DE RENDIMIENTO",
        "pdf_model_header": "Modelo",
        "pdf_time_seconds_header": "Tiempo (segundos)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "R¬≤",
        "pdf_statistical_tests_heading": "PRUEBAS ESTAD√çSTICAS INFERENCIALES",
        "pdf_residuals_normality_heading": "Test de Normalidad de Residuos:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-value = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-value = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk no pudo ejecutarse: {}",
        "pdf_zero_std_note": "{}: Residuos con desviaci√≥n est√°ndar cero (todos los valores son iguales), no se puede realizar test de normalidad.",
        "pdf_no_stats_found": "No se encontraron resultados de pruebas estad√≠sticas para {}.",
        "pdf_additional_visualizations": "VISUALIZACIONES ADICIONALES",
        "pdf_confusion_matrices": "Matrices de Confusi√≥n",
        "pdf_confusion_matrix_for": "Matriz de Confusi√≥n para {}:",
        "pdf_confusion_matrix_warning": "Advertencia: Matriz de Confusi√≥n para {} no encontrada en {}",
        "pdf_performance_graphs": "Gr√°ficos de Rendimiento por Modelo",
        "pdf_graphs_for_model": "Gr√°ficos para {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Advertencia: Gr√°fico '{}' para {} no encontrado en {}",
        "pdf_target_suffix_warning": "Advertencia: No se encontr√≥ sufijo para el objetivo '{}'. No se agregar√°n gr√°ficos espec√≠ficos.",
        "pdf_residuals_graphs_heading": "GR√ÅFICOS DE RESIDUOS"

    },
    "en": {
        "page_title": "ML Model Evaluation - Nutritional Assessment",
        "app_title": "üß¨ ML Model Evaluation for Anthropometric Nutritional Assessment",
        "app_description": "---",
        "sidebar_title": "‚öôÔ∏è Configuration",
        "select_language_label": "Select Language:",
        "data_load_section": "Data Loading",
        "data_loaded_success": "‚úÖ Data loaded successfully",
        "records_label": "üìä Records:",
        "columns_label": "üìã Columns:",
        "file_not_found_error": "File 'datos_pacientes2.csv' not found in the current folder.",
        "file_load_error": "Error loading file: {}",
        "dataset_info_section": "üìã Dataset Information",
        "first_rows_label": "**First 5 Rows:**",
        "statistical_info_label": "**Statistical Information:**",
        "target_variables_section": "üéØ Target Variable Evaluation",
        "start_evaluation_button": "üöÄ Start Model Evaluation",
        "preprocessing_spinner": "Preprocessing data...",
        "column_not_found_error": "Column '{}' not found in processed data.",
        "data_split_section": "üóÇÔ∏è Data Split for {}",
        "train_percent": "**Training data percentage:** {}%",
        "test_percent": "**Test data percentage:** {}%",
        "model_training_section": "ü§ñ Model Training for {}",
        "training_spinner": "Training models for {}...",
        "training_complete_success": "‚úÖ Models trained successfully for {}",
        "metrics_section": "üìä Performance Metrics",
        "training_times_section": "‚è±Ô∏è Training Times",
        "model_label": "Model",
        "time_seconds_label": "Time (seconds)",
        "statistical_tests_section": "üìà Inferential Statistical Tests",
        "statistical_tests_spinner": "Performing statistical tests for {}...",
        "residuals_normality_test": "Residuals Normality Test:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-value = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-value = {:.4f} ({})",
        "normal_interpretation": "‚úÖ Normal",
        "not_normal_interpretation": "‚ùå Not Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk could not be performed: {}",
        "zero_std_error": "{}: Residuals with zero standard deviation (all values are the same), normality test cannot be performed.",
        "no_statistical_results": "No statistical test results found for {}.",
        "evaluation_complete_success": "üéâ Model evaluation completed for all target variables.",
        "download_reports_section": "üìÑ Download PDF Reports",
        "download_pdf_link": "üì• Download PDF Report for {}",
        "pdf_generation_error": "Error generating or downloading PDF report for {}: {}",
        "dataset_load_error": "Could not load the dataset. Please ensure 'datos_pacientes.csv' is in the correct folder.",
        "training_linear_regression": "üîÑ Training Linear Regression...",
        "training_random_forest": "üîÑ Training Random Forest...",
        "training_xgboost": "üîÑ Training XGBoost...",
        "processed_columns": "Processed columns:",
        "residuals_histogram_title": "Residuals Histogram for {}",
        "qq_plot_title": "Residuals Q-Q Plot for {}",
        "residuals_vs_predictions_title": "Residuals vs. Predictions for {}",
        "residuals_label": "Residuals",
        "frequency_label": "Frequency",
        "predicted_values_label": "Predicted Values",
        "friedman_test_heading": "Friedman Test",
        "friedman_result": "Friedman test result: Chi-squared = {:.4f}, p-value = {:.4f} ({})",
        "friedman_significant": "Significant",
        "friedman_not_significant_interpret": "Not Significant",
        "friedman_not_enough_models": "At least 3 models are required to run the Friedman test.",
        "friedman_data_error": "Error preparing data for Friedman: {}",
        "friedman_error": "Error running Friedman test: {}",
        "friedman_not_significant": "Friedman test was not significant, no post-hoc tests performed.",
        "posthoc_heading": "Post-Hoc Tests (Nemenyi)",
        "nemenyi_intro": "Nemenyi post-hoc test results (p-values):",
        "pdf_friedman_test_heading": "FRIEDMAN TEST",
        "pdf_friedman_result": "Chi-squared Statistic = {:.4f}, p-value = {:.4f} ({})",
        "pdf_posthoc_heading": "POST-HOC TESTS (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi post-hoc test results (p-values):",
        "pdf_no_friedman_results": "Friedman test could not be executed.",
        "pdf_no_posthoc_results": "No post-hoc test results found (Friedman was not significant or an error occurred).",

        # PDF Strings
        "pdf_report_title": "ML MODEL EVALUATION REPORT - {}",
        "pdf_report_subtitle": "Anthropometric Nutritional Assessment",
        "pdf_equipment_heading": "PROCESSING EQUIPMENT CHARACTERISTICS",
        "pdf_component_header": "Component",
        "pdf_specification_header": "Specification",
        "pdf_processor": "Processor",
        "pdf_ram": "Installed RAM",
        "pdf_storage": "Storage",
        "pdf_gpu": "Graphics Card",
        "pdf_dataset_info_heading": "DATASET INFORMATION",
        "pdf_num_records": "Number of records: {}",
        "pdf_num_features": "Number of features: {}",
        "pdf_train_percent": "Training percentage: {:.2f}%",
        "pdf_test_percent": "Test percentage: {:.2f}%",
        "pdf_training_times_heading": "TRAINING TIMES",
        "pdf_metrics_heading": "PERFORMANCE METRICS",
        "pdf_model_header": "Model",
        "pdf_time_seconds_header": "Time (seconds)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "R¬≤",
        "pdf_statistical_tests_heading": "INFERENTIAL STATISTICAL TESTS",
        "pdf_residuals_normality_heading": "Residuals Normality Test:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-value = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-value = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk could not be performed: {}",
        "pdf_zero_std_note": "{}: Residuals with zero standard deviation (all values are the same), normality test cannot be performed.",
        "pdf_no_stats_found": "No statistical test results found for {}.",
        "pdf_additional_visualizations": "ADDITIONAL VISUALIZATIONS",
        "pdf_confusion_matrices": "Confusion Matrices",
        "pdf_confusion_matrix_for": "Confusion Matrix for {}:",
        "pdf_confusion_matrix_warning": "Warning: Confusion Matrix for {} not found at {}",
        "pdf_performance_graphs": "Model Performance Graphs",
        "pdf_graphs_for_model": "Graphs for {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Warning: Graph '{}' for {} not found at {}",
        "pdf_target_suffix_warning": "Warning: No suffix found for target '{}'. Specific graphs will not be added.",
        "pdf_residuals_graphs_heading": "RESIDUALS GRAPHS"

    },

    "zh": { # Chinese (Simplified)
        "page_title": "Êú∫Âô®Â≠¶‰π†Ê®°ÂûãËØÑ‰º∞ - Ëê•ÂÖªËØÑ‰º∞",
        "app_title": "üß¨ ‰∫∫‰ΩìÊµãÈáèËê•ÂÖªËØÑ‰º∞ÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãËØÑ‰º∞",
        "app_description": "---",
        "sidebar_title": "‚öôÔ∏è ÈÖçÁΩÆ",
        "select_language_label": "ÈÄâÊã©ËØ≠Ë®Ä:",
        "data_load_section": "Êï∞ÊçÆÂä†ËΩΩ",
        "data_loaded_success": "‚úÖ Êï∞ÊçÆÂä†ËΩΩÊàêÂäü",
        "records_label": "üìä ËÆ∞ÂΩï:",
        "columns_label": "üìã Âàó:",
        "file_not_found_error": "Âú®ÂΩìÂâçÊñá‰ª∂Â§π‰∏≠Êâæ‰∏çÂà∞Êñá‰ª∂ 'datos_pacientes2.csv'„ÄÇ",
        "file_load_error": "Âä†ËΩΩÊñá‰ª∂Êó∂Âá∫Èîô: {}",
        "dataset_info_section": "üìã Êï∞ÊçÆÈõÜ‰ø°ÊÅØ",
        "first_rows_label": "**Ââç5Ë°å:**",
        "statistical_info_label": "**ÁªüËÆ°‰ø°ÊÅØ:**",
        "target_variables_section": "üéØ ÁõÆÊ†áÂèòÈáèËØÑ‰º∞",
        "start_evaluation_button": "üöÄ ÂºÄÂßãÊ®°ÂûãËØÑ‰º∞",
        "preprocessing_spinner": "Ê≠£Âú®È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ...",
        "column_not_found_error": "Âú®Â∑≤Â§ÑÁêÜÊï∞ÊçÆ‰∏≠Êâæ‰∏çÂà∞Âàó '{}'„ÄÇ",
        "data_split_section": "üóÇÔ∏è {} ÁöÑÊï∞ÊçÆÂàÜÂâ≤",
        "train_percent": "**ËÆ≠ÁªÉÊï∞ÊçÆÁôæÂàÜÊØî:** {}%",
        "test_percent": "**ÊµãËØïÊï∞ÊçÆÁôæÂàÜÊØî:** {}%",
        "model_training_section": "ü§ñ {} ÁöÑÊ®°ÂûãËÆ≠ÁªÉ",
        "training_spinner": "Ê≠£Âú®‰∏∫ {} ËÆ≠ÁªÉÊ®°Âûã...",
        "training_complete_success": "‚úÖ Â∑≤ÊàêÂäü‰∏∫ {} ËÆ≠ÁªÉÊ®°Âûã",
        "metrics_section": "üìä ÊÄßËÉΩÊåáÊ†á",
        "training_times_section": "‚è±Ô∏è ËÆ≠ÁªÉÊó∂Èó¥",
        "model_label": "Ê®°Âûã",
        "time_seconds_label": "Êó∂Èó¥ (Áßí)",
        "statistical_tests_section": "üìà Êé®Êñ≠ÁªüËÆ°Ê£ÄÈ™å",
        "statistical_tests_spinner": "Ê≠£Âú®‰∏∫ {} ÊâßË°åÁªüËÆ°Ê£ÄÈ™å...",
        "residuals_normality_test": "ÊÆãÂ∑ÆÊ≠£ÊÄÅÊÄßÊ£ÄÈ™å:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): pÂÄº = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): pÂÄº = {:.4f} ({})",
        "normal_interpretation": "‚úÖ Ê≠£Â∏∏",
        "not_normal_interpretation": "‚ùå ‰∏çÊ≠£Â∏∏",
        "shapiro_wilk_error": "{}: Shapiro-Wilk Êó†Ê≥ïÊâßË°å: {}",
        "zero_std_error": "{}: ÊÆãÂ∑ÆÊ†áÂáÜÂ∑Æ‰∏∫Èõ∂ÔºàÊâÄÊúâÂÄºÈÉΩÁõ∏ÂêåÔºâÔºåÊó†Ê≥ïÊâßË°åÊ≠£ÊÄÅÊÄßÊ£ÄÈ™å„ÄÇ",
        "no_statistical_results": "Êú™ÊâæÂà∞ {} ÁöÑÁªüËÆ°Ê£ÄÈ™åÁªìÊûú„ÄÇ",
        "evaluation_complete_success": "üéâ ÊâÄÊúâÁõÆÊ†áÂèòÈáèÁöÑÊ®°ÂûãËØÑ‰º∞Â∑≤ÂÆåÊàê„ÄÇ",
        "download_reports_section": "üìÑ ‰∏ãËΩΩ PDF Êä•Âëä",
        "download_pdf_link": "üì• ‰∏ãËΩΩ {} ÁöÑ PDF Êä•Âëä",
        "pdf_generation_error": "‰∏∫ {} ÁîüÊàêÊàñ‰∏ãËΩΩ PDF Êä•ÂëäÊó∂Âá∫Èîô: {}",
        "dataset_load_error": "Êó†Ê≥ïÂä†ËΩΩÊï∞ÊçÆÈõÜ„ÄÇËØ∑Á°Æ‰øù 'datos_pacientes.csv' Âú®Ê≠£Á°ÆÁöÑÊñá‰ª∂Â§π‰∏≠„ÄÇ",
        "training_linear_regression": "üîÑ Ê≠£Âú®ËÆ≠ÁªÉÁ∫øÊÄßÂõûÂΩí...",
        "training_random_forest": "üîÑ Ê≠£Âú®ËÆ≠ÁªÉÈöèÊú∫Ê£ÆÊûó...",
        "training_xgboost": "üîÑ Ê≠£Âú®ËÆ≠ÁªÉ XGBoost...",
        "processed_columns": "Â∑≤Â§ÑÁêÜÁöÑÂàó:",
        "residuals_histogram_title": "{} ÁöÑÊÆãÂ∑ÆÁõ¥ÊñπÂõæ",
        "qq_plot_title": "{} ÁöÑÊÆãÂ∑Æ Q-Q Âõæ",
        "residuals_vs_predictions_title": "{} ÁöÑÊÆãÂ∑Æ‰∏éÈ¢ÑÊµãÂÄº",
        "residuals_label": "ÊÆãÂ∑Æ",
        "frequency_label": "È¢ëÁéá",
        "predicted_values_label": "È¢ÑÊµãÂÄº",
         "friedman_test_heading": "Friedman Ê£ÄÈ™å",
        "friedman_result": "Friedman Ê£ÄÈ™åÁªìÊûú: Âç°Êñπ = {:.4f}, p ÂÄº = {:.4f} ({})",
        "friedman_significant": "ÊòæËëó",
        "friedman_not_significant_interpret": "‰∏çÊòæËëó",
        "friedman_not_enough_models": "ËøêË°å Friedman Ê£ÄÈ™åËá≥Â∞ëÈúÄË¶Å 3 ‰∏™Ê®°Âûã„ÄÇ",
        "friedman_data_error": "ÂáÜÂ§á Friedman Êï∞ÊçÆÊó∂Âá∫Èîô: {}",
        "friedman_error": "ËøêË°å Friedman Ê£ÄÈ™åÊó∂Âá∫Èîô: {}",
        "friedman_not_significant": "Friedman Ê£ÄÈ™å‰∏çÊòæËëóÔºåÊú™ÊâßË°å‰∫ãÂêéÊ£ÄÈ™å„ÄÇ",
        "posthoc_heading": "‰∫ãÂêéÊ£ÄÈ™å (Nemenyi)",
        "nemenyi_intro": "Nemenyi ‰∫ãÂêéÊ£ÄÈ™åÁªìÊûú (p ÂÄº):",
        "pdf_friedman_test_heading": "FRIEDMAN Ê£ÄÈ™å",
        "pdf_friedman_result": "Âç°ÊñπÁªüËÆ°Èáè = {:.4f}, p ÂÄº = {:.4f} ({})",
        "pdf_posthoc_heading": "‰∫ãÂêéÊ£ÄÈ™å (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi ‰∫ãÂêéÊ£ÄÈ™åÁªìÊûú (p ÂÄº):",
        "pdf_no_friedman_results": "Friedman Ê£ÄÈ™åÊó†Ê≥ïÊâßË°å„ÄÇ",
        "pdf_no_posthoc_results": "Êú™ÊâæÂà∞‰∫ãÂêéÊ£ÄÈ™åÁªìÊûúÔºàFriedman ‰∏çÊòæËëóÊàñÂèëÁîüÈîôËØØÔºâ„ÄÇ",

        # PDF Strings
        "pdf_report_title": "ML Ê®°ÂûãËØÑ‰º∞Êä•Âëä - {}",
        "pdf_report_subtitle": "‰∫∫‰ΩìÊµãÈáèËê•ÂÖªËØÑ‰º∞",
        "pdf_equipment_heading": "Â§ÑÁêÜËÆæÂ§áÁâπÊÄß",
        "pdf_component_header": "ÁªÑ‰ª∂",
        "pdf_specification_header": "ËßÑÊ†º",
        "pdf_processor": "Â§ÑÁêÜÂô®",
        "pdf_ram": "Â∑≤ÂÆâË£ÖÂÜÖÂ≠ò",
        "pdf_storage": "Â≠òÂÇ®",
        "pdf_gpu": "ÊòæÂç°",
        "pdf_dataset_info_heading": "Êï∞ÊçÆÈõÜ‰ø°ÊÅØ",
        "pdf_num_records": "ËÆ∞ÂΩïÊï∞: {}",
        "pdf_num_features": "ÁâπÂæÅÊï∞: {}",
        "pdf_train_percent": "ËÆ≠ÁªÉÁôæÂàÜÊØî: {:.2f}%",
        "pdf_test_percent": "ÊµãËØïÁôæÂàÜÊØî: {:.2f}%",
        "pdf_training_times_heading": "ËÆ≠ÁªÉÊó∂Èó¥",
        "pdf_metrics_heading": "ÊÄßËÉΩÊåáÊ†á",
        "pdf_model_header": "Ê®°Âûã",
        "pdf_time_seconds_header": "Êó∂Èó¥ (Áßí)",
        "pdf_mse": "ÂùáÊñπËØØÂ∑Æ",
        "pdf_rmse": "ÂùáÊñπÊ†πËØØÂ∑Æ",
        "pdf_mae": "Âπ≥ÂùáÁªùÂØπËØØÂ∑Æ",
        "pdf_r2": "ÂÜ≥ÂÆöÁ≥ªÊï∞ (R¬≤)",
        "pdf_statistical_tests_heading": "Êé®Êñ≠ÁªüËÆ°Ê£ÄÈ™å",
        "pdf_residuals_normality_heading": "ÊÆãÂ∑ÆÊ≠£ÊÄÅÊÄßÊ£ÄÈ™å:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): pÂÄº = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): pÂÄº = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk Êó†Ê≥ïÊâßË°å: {}",
        "pdf_zero_std_note": "{}: ÊÆãÂ∑ÆÊ†áÂáÜÂ∑Æ‰∏∫Èõ∂ÔºàÊâÄÊúâÂÄºÈÉΩÁõ∏ÂêåÔºâÔºåÊó†Ê≥ïÊâßË°åÊ≠£ÊÄÅÊÄßÊ£ÄÈ™å„ÄÇ",
        "pdf_no_stats_found": "Êú™ÊâæÂà∞ {} ÁöÑÁªüËÆ°Ê£ÄÈ™åÁªìÊûú„ÄÇ",
        "pdf_additional_visualizations": "ÈôÑÂä†ÂèØËßÜÂåñ",
        "pdf_confusion_matrices": "Ê∑∑Ê∑ÜÁü©Èòµ",
        "pdf_confusion_matrix_for": "{} ÁöÑÊ∑∑Ê∑ÜÁü©Èòµ:",
        "pdf_confusion_matrix_warning": "Ë≠¶Âëä: Âú® {} Êú™ÊâæÂà∞ {} ÁöÑÊ∑∑Ê∑ÜÁü©Èòµ",
        "pdf_performance_graphs": "Ê®°ÂûãÊÄßËÉΩÂõæ",
        "pdf_graphs_for_model": "{} ({}) ÁöÑÂõæ:",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Ë≠¶Âëä: Âú® {} Êú™ÊâæÂà∞ {} ÁöÑÂõæ '{}'",
        "pdf_target_suffix_warning": "Ë≠¶Âëä: Êú™ÊâæÂà∞ÁõÆÊ†á '{}' ÁöÑÂêéÁºÄ„ÄÇÂ∞Ü‰∏çÊ∑ªÂä†ÁâπÂÆöÂõæ„ÄÇ",
        "pdf_residuals_graphs_heading": "ÊÆãÂ∑ÆÂõæ"
    },
    "de": { # German
        "page_title": "ML-Modellbewertung - Ern√§hrungsanalyse",
        "app_title": "üß¨ ML-Modellbewertung f√ºr anthropometrische Ern√§hrungsanalyse",
        "app_description": "---",
        "sidebar_title": "‚öôÔ∏è Konfiguration",
        "select_language_label": "Sprache ausw√§hlen:",
        "data_load_section": "Daten laden",
        "data_loaded_success": "‚úÖ Daten erfolgreich geladen",
        "records_label": "üìä Datens√§tze:",
        "columns_label": "üìã Spalten:",
        "file_not_found_error": "Datei 'datos_pacientes2.csv' im aktuellen Ordner nicht gefunden.",
        "file_load_error": "Fehler beim Laden der Datei: {}",
        "dataset_info_section": "üìã Datensatzinformationen",
        "first_rows_label": "**Erste 5 Zeilen:**",
        "statistical_info_label": "**Statistische Informationen:**",
        "target_variables_section": "üéØ Zielvariablenbewertung",
        "start_evaluation_button": "üöÄ Modellbewertung starten",
        "preprocessing_spinner": "Daten werden vorverarbeitet...",
        "column_not_found_error": "Spalte '{}' in den verarbeiteten Daten nicht gefunden.",
        "data_split_section": "üóÇÔ∏è Datenteilung f√ºr {}",
        "train_percent": "**Prozentsatz der Trainingsdaten:** {}%",
        "test_percent": "**Prozentsatz der Testdaten:** {}%",
        "model_training_section": "ü§ñ Modelltraining f√ºr {}",
        "training_spinner": "Modelle werden f√ºr {} trainiert...",
        "training_complete_success": "‚úÖ Modelle erfolgreich f√ºr {} trainiert",
        "metrics_section": "üìä Leistungsmetriken",
        "training_times_section": "‚è±Ô∏è Trainingszeiten",
        "model_label": "Modell",
        "time_seconds_label": "Zeit (Sekunden)",
        "statistical_tests_section": "üìà Inferenzstatistische Tests",
        "statistical_tests_spinner": "Statistische Tests f√ºr {} werden durchgef√ºhrt...",
        "residuals_normality_test": "Normalit√§tstest der Residuen:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-Wert = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-Wert = {:.4f} ({})",
        "normal_interpretation": "‚úÖ Normal",
        "not_normal_interpretation": "‚ùå Nicht Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk konnte nicht durchgef√ºhrt werden: {}",
        "zero_std_error": "{}: Residuen mit Standardabweichung Null (alle Werte sind gleich), Normalit√§tstest kann nicht durchgef√ºhrt werden.",
        "no_statistical_results": "Keine statistischen Testergebnisse f√ºr {} gefunden.",
        "evaluation_complete_success": "üéâ Modellbewertung f√ºr alle Zielvariablen abgeschlossen.",
        "download_reports_section": "üìÑ PDF-Berichte herunterladen",
        "download_pdf_link": "üì• PDF-Bericht f√ºr {} herunterladen",
        "pdf_generation_error": "Fehler beim Generieren oder Herunterladen des PDF-Berichts f√ºr {}: {}",
        "dataset_load_error": "Datensatz konnte nicht geladen werden. Stellen Sie sicher, dass 'datos_pacientes.csv' im richtigen Ordner ist.",
        "training_linear_regression": "üîÑ Lineare Regression wird trainiert...",
        "training_random_forest": "üîÑ Random Forest wird trainiert...",
        "training_xgboost": "üîÑ XGBoost wird trainiert...",
        "processed_columns": "Verarbeitete Spalten:",
        "residuals_histogram_title": "Residuen-Histogramm f√ºr {}",
        "qq_plot_title": "Residuen-Q-Q-Diagramm f√ºr {}",
        "residuals_vs_predictions_title": "Residuen vs. Vorhersagen f√ºr {}",
        "residuals_label": "Residuen",
        "frequency_label": "H√§ufigkeit",
        "predicted_values_label": "Vorhergesagte Werte",
        "friedman_test_heading": "Friedman-Test",
        "friedman_result": "Friedman-Testergebnis: Chi-Quadrat = {:.4f}, p-Wert = {:.4f} ({})",
        "friedman_significant": "Signifikant",
        "friedman_not_significant_interpret": "Nicht signifikant",
        "friedman_not_enough_models": "Es werden mindestens 3 Modelle f√ºr den Friedman-Test ben√∂tigt.",
        "friedman_data_error": "Fehler beim Vorbereiten der Daten f√ºr Friedman: {}",
        "friedman_error": "Fehler beim Ausf√ºhren des Friedman-Tests: {}",
        "friedman_not_significant": "Friedman-Test war nicht signifikant, keine Post-hoc-Tests durchgef√ºhrt.",
        "posthoc_heading": "Post-hoc-Tests (Nemenyi)",
        "nemenyi_intro": "Nemenyi Post-hoc-Testergebnisse (p-Werte):",
        "pdf_friedman_test_heading": "FRIEDMAN-TEST",
        "pdf_friedman_result": "Chi-Quadrat-Statistik = {:.4f}, p-Wert = {:.4f} ({})",
        "pdf_posthoc_heading": "POST-HOC-TESTS (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi Post-hoc-Testergebnisse (p-Werte):",
        "pdf_no_friedman_results": "Friedman-Test konnte nicht ausgef√ºhrt werden.",
        "pdf_no_posthoc_results": "Keine Post-hoc-Testergebnisse gefunden (Friedman war nicht signifikant oder es ist ein Fehler aufgetreten).",

        # PDF Strings
        "pdf_report_title": "ML-MODELLBEWERTUNGSBERICHT - {}",
        "pdf_report_subtitle": "Anthropometrische Ern√§hrungsanalyse",
        "pdf_equipment_heading": "EIGENSCHAFTEN DER VERARBEITUNGSAUSR√úSTUNG",
        "pdf_component_header": "Komponente",
        "pdf_specification_header": "Spezifikation",
        "pdf_processor": "Prozessor",
        "pdf_ram": "Installierter RAM",
        "pdf_storage": "Speicher",
        "pdf_gpu": "Grafikkarte",
        "pdf_dataset_info_heading": "DATENSATZINFORMATIONEN",
        "pdf_num_records": "Anzahl der Datens√§tze: {}",
        "pdf_num_features": "Anzahl der Merkmale: {}",
        "pdf_train_percent": "Trainingsprozentsatz: {:.2f}%",
        "pdf_test_percent": "Testprozentsatz: {:.2f}%",
        "pdf_training_times_heading": "TRAININGSZEITEN",
        "pdf_metrics_heading": "LEISTUNGSMETRIKEN",
        "pdf_model_header": "Modell",
        "pdf_time_seconds_header": "Zeit (Sekunden)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "R¬≤",
        "pdf_statistical_tests_heading": "INFERENZSTATISTISCHE TESTS",
        "pdf_residuals_normality_heading": "Normalit√§tstest der Residuen:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-Wert = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-Wert = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk konnte nicht durchgef√ºhrt werden: {}",
        "pdf_zero_std_note": "{}: Residuen mit Standardabweichung Null (alle Werte sind gleich), Normalit√§tstest kann nicht durchgef√ºhrt werden.",
        "pdf_no_stats_found": "Keine statistischen Testergebnisse f√ºr {} gefunden.",
        "pdf_additional_visualizations": "ZUS√ÑTZLICHE VISUALISIERUNGEN",
        "pdf_confusion_matrices": "Konfusionsmatrizen",
        "pdf_confusion_matrix_for": "Konfusionsmatrix f√ºr {}:",
        "pdf_confusion_matrix_warning": "Warnung: Konfusionsmatrix f√ºr {} nicht gefunden unter {}",
        "pdf_performance_graphs": "Modellleistungsdiagramme",
        "pdf_graphs_for_model": "Diagramme f√ºr {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Warnung: Diagramm '{}' f√ºr {} nicht gefunden unter {}",
        "pdf_target_suffix_warning": "Warnung: Kein Suffix f√ºr Ziel '{}' gefunden. Spezifische Diagramme werden nicht hinzugef√ºgt.",
        "pdf_residuals_graphs_heading": "RESIDUEN-DIAGRAMME"
    },
    "ja": { # Japanese
        "page_title": "ML„É¢„Éá„É´Ë©ï‰æ° - Ê†ÑÈ§äË©ï‰æ°",
        "app_title": "üß¨ ‰∫∫‰ΩìË®àÊ∏¨Ê†ÑÈ§äË©ï‰æ°„ÅÆ„Åü„ÇÅ„ÅÆML„É¢„Éá„É´Ë©ï‰æ°",
        "app_description": "---",
        "sidebar_title": "‚öôÔ∏è Ë®≠ÂÆö",
        "select_language_label": "Ë®ÄË™û„ÇíÈÅ∏Êäû:",
        "data_load_section": "„Éá„Éº„ÇøË™≠„ÅøËæº„Åø",
        "data_loaded_success": "‚úÖ „Éá„Éº„Çø„ÅÆË™≠„ÅøËæº„Åø„Å´ÊàêÂäü„Åó„Åæ„Åó„Åü",
        "records_label": "üìä „É¨„Ç≥„Éº„ÉâÊï∞:",
        "columns_label": "üìã ÂàóÊï∞:",
        "file_not_found_error": "ÁèæÂú®„ÅÆ„Éï„Ç©„É´„ÉÄ„Å´„Éï„Ç°„Ç§„É´ 'datos_pacientes2.csv' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ",
        "file_load_error": "„Éï„Ç°„Ç§„É´„ÅÆË™≠„ÅøËæº„Åø„Ç®„É©„Éº: {}",
        "dataset_info_section": "üìã „Éá„Éº„Çø„Çª„ÉÉ„ÉàÊÉÖÂ†±",
        "first_rows_label": "**ÊúÄÂàù„ÅÆ5Ë°å:**",
        "statistical_info_label": "**Áµ±Ë®àÊÉÖÂ†±:**",
        "target_variables_section": "üéØ ÁõÆÊ®ôÂ§âÊï∞Ë©ï‰æ°",
        "start_evaluation_button": "üöÄ „É¢„Éá„É´Ë©ï‰æ°„ÇíÈñãÂßã",
        "preprocessing_spinner": "„Éá„Éº„Çø„ÇíÂâçÂá¶ÁêÜ‰∏≠...",
        "column_not_found_error": "Âá¶ÁêÜÊ∏à„Åø„Éá„Éº„Çø„Å´Âàó '{}' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ",
        "data_split_section": "üóÇÔ∏è {} „ÅÆ„Éá„Éº„ÇøÂàÜÂâ≤",
        "train_percent": "**„Éà„É¨„Éº„Éã„É≥„Ç∞„Éá„Éº„ÇøÂâ≤Âêà:** {}%",
        "test_percent": "**„ÉÜ„Çπ„Éà„Éá„Éº„ÇøÂâ≤Âêà:** {}%",
        "model_training_section": "ü§ñ {} „ÅÆ„É¢„Éá„É´„Éà„É¨„Éº„Éã„É≥„Ç∞",
        "training_spinner": "{} „ÅÆ„É¢„Éá„É´„Çí„Éà„É¨„Éº„Éã„É≥„Ç∞‰∏≠...",
        "training_complete_success": "‚úÖ {} „ÅÆ„É¢„Éá„É´„ÅåÊ≠£Â∏∏„Å´„Éà„É¨„Éº„Éã„É≥„Ç∞„Åï„Çå„Åæ„Åó„Åü",
        "metrics_section": "üìä „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊåáÊ®ô",
        "training_times_section": "‚è±Ô∏è „Éà„É¨„Éº„Éã„É≥„Ç∞ÊôÇÈñì",
        "model_label": "„É¢„Éá„É´",
        "time_seconds_label": "ÊôÇÈñì (Áßí)",
        "statistical_tests_section": "üìà Êé®Ê∏¨Áµ±Ë®àÊ§úÂÆö",
        "statistical_tests_spinner": "{} „ÅÆÁµ±Ë®àÊ§úÂÆö„ÇíÂÆüË°å‰∏≠...",
        "residuals_normality_test": "ÊÆãÂ∑Æ„ÅÆÊ≠£Ë¶èÊÄßÊ§úÂÆö:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): pÂÄ§ = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): pÂÄ§ = {:.4f} ({})",
        "normal_interpretation": "‚úÖ Ê≠£Ë¶è",
        "not_normal_interpretation": "‚ùå ÈùûÊ≠£Ë¶è",
        "shapiro_wilk_error": "{}: Shapiro-Wilk „ÇíÂÆüË°å„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü: {}",
        "zero_std_error": "{}: ÊÆãÂ∑Æ„ÅÆÊ®ôÊ∫ñÂÅèÂ∑Æ„Åå„Çº„É≠Ôºà„Åô„Åπ„Å¶„ÅÆÂÄ§„ÅåÂêå„ÅòÔºâ„ÅÆ„Åü„ÇÅ„ÄÅÊ≠£Ë¶èÊÄßÊ§úÂÆö„ÅØÂÆüË°å„Åß„Åç„Åæ„Åõ„Çì„ÄÇ",
        "no_statistical_results": "{} „ÅÆÁµ±Ë®àÊ§úÂÆöÁµêÊûú„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ",
        "evaluation_complete_success": "üéâ „Åô„Åπ„Å¶„ÅÆÁõÆÊ®ôÂ§âÊï∞„ÅÆ„É¢„Éá„É´Ë©ï‰æ°„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ",
        "download_reports_section": "üìÑ PDF„É¨„Éù„Éº„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
        "download_pdf_link": "üì• {} „ÅÆPDF„É¨„Éù„Éº„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
        "pdf_generation_error": "{} „ÅÆPDF„É¨„Éù„Éº„Éà„ÅÆÁîüÊàê„Åæ„Åü„ÅØ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {}",
        "dataset_load_error": "„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„É≠„Éº„Éâ„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ'datos_pacientes.csv' „ÅåÊ≠£„Åó„ÅÑ„Éï„Ç©„É´„ÉÄ„Å´„ÅÇ„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "training_linear_regression": "üîÑ Á∑öÂΩ¢ÂõûÂ∏∞„Çí„Éà„É¨„Éº„Éã„É≥„Ç∞‰∏≠...",
        "training_random_forest": "üîÑ „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„Çí„Éà„É¨„Éº„Éã„É≥„Ç∞‰∏≠...",
        "training_xgboost": "üîÑ XGBoost„Çí„Éà„É¨„Éº„Éã„É≥„Ç∞‰∏≠...",
        "processed_columns": "Âá¶ÁêÜÊ∏à„ÅøÂàó:",
        "residuals_histogram_title": "{} „ÅÆÊÆãÂ∑Æ„Éí„Çπ„Éà„Ç∞„É©„É†",
        "qq_plot_title": "{} „ÅÆÊÆãÂ∑Æ Q-Q „Éó„É≠„ÉÉ„Éà",
        "residuals_vs_predictions_title": "{} „ÅÆÊÆãÂ∑Æ vs. ‰∫àÊ∏¨",
        "residuals_label": "ÊÆãÂ∑Æ",
        "frequency_label": "È†ªÂ∫¶",
        "predicted_values_label": "‰∫àÊ∏¨ÂÄ§",
        "friedman_test_heading": "„Éï„É™„Éº„Éâ„Éû„É≥Ê§úÂÆö",
        "friedman_result": "„Éï„É™„Éº„Éâ„Éû„É≥Ê§úÂÆöÁµêÊûú: „Ç´„Ç§‰∫å‰πó = {:.4f}, p ÂÄ§ = {:.4f} ({})",
        "friedman_significant": "ÊúâÊÑè",
        "friedman_not_significant_interpret": "ÊúâÊÑè„Åß„Å™„ÅÑ",
        "friedman_not_enough_models": "„Éï„É™„Éº„Éâ„Éû„É≥Ê§úÂÆö„ÇíÂÆüË°å„Åô„Çã„Å´„ÅØ„ÄÅÂ∞ë„Å™„Åè„Å®„ÇÇ3„Å§„ÅÆ„É¢„Éá„É´„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ",
        "friedman_data_error": "„Éï„É™„Éº„Éâ„Éû„É≥„ÅÆ„Éá„Éº„Çø„ÇíÊ∫ñÂÇô‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {}",
        "friedman_error": "„Éï„É™„Éº„Éâ„Éû„É≥Ê§úÂÆö„ÅÆÂÆüË°å‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {}",
        "friedman_not_significant": "„Éï„É™„Éº„Éâ„Éû„É≥Ê§úÂÆö„ÅØÊúâÊÑè„Åß„ÅØ„Å™„Åã„Å£„Åü„Åü„ÇÅ„ÄÅ‰∫ãÂæåÊ§úÂÆö„ÅØÂÆüË°å„Åï„Çå„Åæ„Åõ„Çì„ÄÇ",
        "posthoc_heading": "‰∫ãÂæåÊ§úÂÆö (Nemenyi)",
        "nemenyi_intro": "Nemenyi ‰∫ãÂæåÊ§úÂÆöÁµêÊûú (p ÂÄ§):",
        "pdf_friedman_test_heading": "„Éï„É™„Éº„Éâ„Éû„É≥Ê§úÂÆö",
        "pdf_friedman_result": "„Ç´„Ç§‰∫å‰πóÁµ±Ë®àÈáè = {:.4f}, p ÂÄ§ = {:.4f} ({})",
        "pdf_posthoc_heading": "‰∫ãÂæåÊ§úÂÆö (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi ‰∫ãÂæåÊ§úÂÆöÁµêÊûú (p ÂÄ§):",
        "pdf_no_friedman_results": "„Éï„É™„Éº„Éâ„Éû„É≥Ê§úÂÆö„ÇíÂÆüË°å„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ",
        "pdf_no_posthoc_results": "‰∫ãÂæåÊ§úÂÆö„ÅÆÁµêÊûú„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü („Éï„É™„Éº„Éâ„Éû„É≥„ÅØÊúâÊÑè„Åß„ÅØ„Å™„Åã„Å£„Åü„Åã„ÄÅ„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü)„ÄÇ",

        # PDF Strings
        "pdf_report_title": "ML„É¢„Éá„É´Ë©ï‰æ°„É¨„Éù„Éº„Éà - {}",
        "pdf_report_subtitle": "‰∫∫‰ΩìË®àÊ∏¨Ê†ÑÈ§äË©ï‰æ°",
        "pdf_equipment_heading": "Âá¶ÁêÜË£ÖÁΩÆ„ÅÆÁâπÊÄß",
        "pdf_component_header": "„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà",
        "pdf_specification_header": "‰ªïÊßò",
        "pdf_processor": "„Éó„É≠„Çª„ÉÉ„Çµ",
        "pdf_ram": "„Ç§„É≥„Çπ„Éà„Éº„É´Ê∏à„ÅøRAM",
        "pdf_storage": "„Çπ„Éà„É¨„Éº„Ç∏",
        "pdf_gpu": "„Ç∞„É©„Éï„Ç£„ÉÉ„ÇØ„Ç´„Éº„Éâ",
        "pdf_dataset_info_heading": "„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊÉÖÂ†±",
        "pdf_num_records": "„É¨„Ç≥„Éº„ÉâÊï∞: {}",
        "pdf_num_features": "ÁâπÂæ¥ÈáèÊï∞: {}",
        "pdf_train_percent": "„Éà„É¨„Éº„Éã„É≥„Ç∞Ââ≤Âêà: {:.2f}%",
        "pdf_test_percent": "„ÉÜ„Çπ„ÉàÂâ≤Âêà: {:.2f}%",
        "pdf_training_times_heading": "„Éà„É¨„Éº„Éã„É≥„Ç∞ÊôÇÈñì",
        "pdf_metrics_heading": "„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊåáÊ®ô",
        "pdf_model_header": "„É¢„Éá„É´",
        "pdf_time_seconds_header": "ÊôÇÈñì (Áßí)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "R¬≤",
        "pdf_statistical_tests_heading": "Êé®Ê∏¨Áµ±Ë®àÊ§úÂÆö",
        "pdf_residuals_normality_heading": "ÊÆãÂ∑Æ„ÅÆÊ≠£Ë¶èÊÄßÊ§úÂÆö:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): pÂÄ§ = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): pÂÄ§ = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk „ÇíÂÆüË°å„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü: {}",
        "pdf_zero_std_note": "{}: ÊÆãÂ∑Æ„ÅÆÊ®ôÊ∫ñÂÅèÂ∑Æ„Åå„Çº„É≠Ôºà„Åô„Åπ„Å¶„ÅÆÂÄ§„ÅåÂêå„ÅòÔºâ„ÅÆ„Åü„ÇÅ„ÄÅÊ≠£Ë¶èÊÄßÊ§úÂÆö„ÅØÂÆüË°å„Åß„Åç„Åæ„Åõ„Çì„ÄÇ",
        "pdf_no_stats_found": "{} „ÅÆÁµ±Ë®àÊ§úÂÆöÁµêÊûú„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ",
        "pdf_additional_visualizations": "ËøΩÂä†„ÅÆË¶ñË¶öÂåñ",
        "pdf_confusion_matrices": "Ê∑∑ÂêåË°åÂàó",
        "pdf_confusion_matrix_for": "{} „ÅÆÊ∑∑ÂêåË°åÂàó:",
        "pdf_confusion_matrix_warning": "Ë≠¶Âëä: {} „ÅÆÊ∑∑ÂêåË°åÂàó„Åå {} „Å´Ë¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü",
        "pdf_performance_graphs": "„É¢„Éá„É´ÊÄßËÉΩ„Ç∞„É©„Éï",
        "pdf_graphs_for_model": "{} ({}) „ÅÆ„Ç∞„É©„Éï:",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Ë≠¶Âëä: {} „ÅÆ„Ç∞„É©„Éï '{}' „Åå {} „Å´Ë¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü",
        "pdf_target_suffix_warning": "Ë≠¶Âëä: „Çø„Éº„Ç≤„ÉÉ„Éà '{}' „ÅÆ„Çµ„Éï„Ç£„ÉÉ„ÇØ„Çπ„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇÁâπÂÆö„ÅÆ„Ç∞„É©„Éï„ÅØËøΩÂä†„Åï„Çå„Åæ„Åõ„Çì„ÄÇ",
        "pdf_residuals_graphs_heading": "ÊÆãÂ∑Æ„Ç∞„É©„Éï"
    },
    "fr": { # French
        "page_title": "√âvaluation de Mod√®les ML - √âvaluation Nutritionnelle",
        "app_title": "üß¨ √âvaluation de Mod√®les ML pour l'√âvaluation Nutritionnelle Anthropom√©trique",
        "app_description": "---",
        "sidebar_title": "‚öôÔ∏è Configuration",
        "select_language_label": "S√©lectionner la langue :",
        "data_load_section": "Chargement des Donn√©es",
        "data_loaded_success": "‚úÖ Donn√©es charg√©es avec succ√®s",
        "records_label": "üìä Enregistrements :",
        "columns_label": "üìã Colonnes :",
        "file_not_found_error": "Fichier 'datos_pacientes2.csv' introuvable dans le dossier actuel.",
        "file_load_error": "Erreur lors du chargement du fichier : {}",
        "dataset_info_section": "üìã Informations sur l'Ensemble de Donn√©es",
        "first_rows_label": "**5 premi√®res lignes :**",
        "statistical_info_label": "**Informations statistiques :**",
        "target_variables_section": "üéØ √âvaluation des Variables Cibles",
        "start_evaluation_button": "üöÄ D√©marrer l'√âvaluation des Mod√®les",
        "preprocessing_spinner": "Pr√©traitement des donn√©es...",
        "column_not_found_error": "La colonne '{}' n'a pas √©t√© trouv√©e dans les donn√©es trait√©es.",
        "data_split_section": "üóÇÔ∏è Division des Donn√©es pour {}",
        "train_percent": "**Pourcentage de donn√©es d'entra√Ænement :** {}%",
        "test_percent": "**Pourcentage de donn√©es de test :** {}%",
        "model_training_section": "ü§ñ Entra√Ænement des Mod√®les pour {}",
        "training_spinner": "Entra√Ænement des mod√®les pour {}...",
        "training_complete_success": "‚úÖ Mod√®les entra√Æn√©s avec succ√®s pour {}",
        "metrics_section": "üìä M√©triques de Performance",
        "training_times_section": "‚è±Ô∏è Temps d'Entra√Ænement",
        "model_label": "Mod√®le",
        "time_seconds_label": "Temps (secondes)",
        "statistical_tests_section": "üìà Tests Statistiques Inf√©rentiels",
        "statistical_tests_spinner": "Ex√©cution des tests statistiques pour {}...",
        "residuals_normality_test": "Test de Normalit√© des R√©sidus :",
        "shapiro_wilk_test": "{} (Shapiro-Wilk) : p-value = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov) : p-value = {:.4f} ({})",
        "normal_interpretation": "‚úÖ Normal",
        "not_normal_interpretation": "‚ùå Non Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk n'a pas pu √™tre ex√©cut√© : {}",
        "zero_std_error": "{}: R√©sidus avec √©cart type nul (toutes les valeurs sont identiques), le test de normalit√© ne peut pas √™tre effectu√©.",
        "no_statistical_results": "Aucun r√©sultat de test statistique trouv√© pour {}.",
        "evaluation_complete_success": "üéâ √âvaluation des mod√®les termin√©e pour toutes les variables cibles.",
        "download_reports_section": "üìÑ T√©l√©charger les Rapports PDF",
        "download_pdf_link": "üì• T√©l√©charger le Rapport PDF pour {}",
        "pdf_generation_error": "Erreur lors de la g√©n√©ration ou du t√©l√©chargement du rapport PDF pour {} : {}",
        "dataset_load_error": "Impossible de charger l'ensemble de donn√©es. Veuillez vous assurer que 'datos_pacientes.csv' se trouve dans le bon dossier.",
        "training_linear_regression": "üîÑ Entra√Ænement de la R√©gression Lin√©aire...",
        "training_random_forest": "üîÑ Entra√Ænement de Random Forest...",
        "training_xgboost": "üîÑ Entra√Ænement de XGBoost...",
        "processed_columns": "Colonnes trait√©es :",
        "residuals_histogram_title": "Histogramme des R√©sidus pour {}",
        "qq_plot_title": "Graphe Q-Q des R√©sidus pour {}",
        "residuals_vs_predictions_title": "R√©sidus vs. Pr√©dictions pour {}",
        "residuals_label": "R√©sidus",
        "frequency_label": "Fr√©quence",
        "predicted_values_label": "Valeurs Pr√©dites",
        "friedman_test_heading": "Test de Friedman",
        "friedman_result": "R√©sultat du test de Friedman: Chi-deux = {:.4f}, p-valeur = {:.4f} ({})",
        "friedman_significant": "Significatif",
        "friedman_not_significant_interpret": "Non Significatif",
        "friedman_not_enough_models": "Au moins 3 mod√®les sont requis pour ex√©cuter le test de Friedman.",
        "friedman_data_error": "Erreur lors de la pr√©paration des donn√©es pour Friedman: {}",
        "friedman_error": "Erreur lors de l'ex√©cution du test de Friedman: {}",
        "friedman_not_significant": "Le test de Friedman n'√©tait pas significatif, aucun test post-hoc effectu√©.",
        "posthoc_heading": "Tests Post-Hoc (Nemenyi)",
        "nemenyi_intro": "R√©sultats du test post-hoc de Nemenyi (valeurs p):",
        "pdf_friedman_test_heading": "TEST DE FRIEDMAN",
        "pdf_friedman_result": "Statistique du Chi-deux = {:.4f}, p-valeur = {:.4f} ({})",
        "pdf_posthoc_heading": "TESTS POST-HOC (NEMENYI)",
        "pdf_nemenyi_intro": "R√©sultats du test post-hoc de Nemenyi (valeurs p):",
        "pdf_no_friedman_results": "Le test de Friedman n'a pas pu √™tre ex√©cut√©.",
        "pdf_no_posthoc_results": "Aucun r√©sultat de test post-hoc trouv√© (Friedman n'√©tait pas significatif ou une erreur s'est produite).",

        # PDF Strings
        "pdf_report_title": "RAPPORT D'√âVALUATION DES MOD√àLES ML - {}",
        "pdf_report_subtitle": "√âvaluation Nutritionnelle Anthropom√©trique",
        "pdf_equipment_heading": "CARACT√âRISTIQUES DE L'√âQUIPEMENT DE TRAITEMENT",
        "pdf_component_header": "Composant",
        "pdf_specification_header": "Sp√©cification",
        "pdf_processor": "Processeur",
        "pdf_ram": "RAM install√©e",
        "pdf_storage": "Stockage",
        "pdf_gpu": "Carte graphique",
        "pdf_dataset_info_heading": "INFORMATIONS SUR L'ENSEMBLE DE DONN√âES",
        "pdf_num_records": "Nombre d'enregistrements : {}",
        "pdf_num_features": "Nombre de caract√©ristiques : {}",
        "pdf_train_percent": "Pourcentage d'entra√Ænement : {:.2f}%",
        "pdf_test_percent": "Pourcentage de test : {:.2f}%",
        "pdf_training_times_heading": "TEMPS D'ENTRA√éNEMENT",
        "pdf_metrics_heading": "M√âTRIQUES DE PERFORMANCE",
        "pdf_model_header": "Mod√®le",
        "pdf_time_seconds_header": "Temps (secondes)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "R¬≤",
        "pdf_statistical_tests_heading": "TESTS STATISTIQUES INF√âRENTIELS",
        "pdf_residuals_normality_heading": "Test de Normalit√© des R√©sidus :",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk) : p-value = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov) : p-value = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk n'a pas pu √™tre ex√©cut√© : {}",
        "pdf_zero_std_note": "{}: R√©sidus avec √©cart type nul (toutes les valeurs sont identiques), le test de normalit√© ne peut pas √™tre effectu√©.",
        "pdf_no_stats_found": "Aucun r√©sultat de test statistique trouv√© pour {}.",
        "pdf_additional_visualizations": "VISUALISATIONS SUPPL√âMENTAIRES",
        "pdf_confusion_matrices": "Matrices de Confusion",
        "pdf_confusion_matrix_for": "Matrice de Confusion pour {} :",
        "pdf_confusion_matrix_warning": "Avertissement : Matrice de Confusion pour {} introuvable √† {}",
        "pdf_performance_graphs": "Graphiques de Performance du Mod√®le",
        "pdf_graphs_for_model": "Graphiques pour {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Avertissement : Graphique '{}' pour {} introuvable √† {}",
        "pdf_target_suffix_warning": "Avertissement : Aucun suffixe trouv√© pour la cible '{}'. Les graphiques sp√©cifiques ne seront pas ajout√©s.",
        "pdf_residuals_graphs_heading": "GRAPHIQUES DES R√âSIDUS"
    },
    "pt": { # Portuguese (Brazil)
        "page_title": "Avalia√ß√£o de Modelos ML - Avalia√ß√£o Nutricional",
        "app_title": "üß¨ Avalia√ß√£o de Modelos ML para Avalia√ß√£o Nutricional Antropom√©trica",
        "app_description": "---",
        "sidebar_title": "‚öôÔ∏è Configura√ß√£o",
        "select_language_label": "Selecionar Idioma:",
        "data_load_section": "Carregamento de Dados",
        "data_loaded_success": "‚úÖ Dados carregados com sucesso",
        "records_label": "üìä Registros:",
        "columns_label": "üìã Colunas:",
        "file_not_found_error": "Arquivo 'datos_pacientes2.csv' n√£o encontrado na pasta atual.",
        "file_load_error": "Erro ao carregar o arquivo: {}",
        "dataset_info_section": "üìã Informa√ß√µes do Conjunto de Dados",
        "first_rows_label": "**Primeiras 5 linhas:**",
        "statistical_info_label": "**Informa√ß√µes estat√≠sticas:**",
        "target_variables_section": "üéØ Avalia√ß√£o de Vari√°veis Alvo",
        "start_evaluation_button": "üöÄ Iniciar Avalia√ß√£o de Modelos",
        "preprocessing_spinner": "Pr√©-processando dados...",
        "column_not_found_error": "A coluna '{}' n√£o foi encontrada nos dados processados.",
        "data_split_section": "üóÇÔ∏è Divis√£o de Dados para {}",
        "train_percent": "**Porcentagem de dados de treinamento:** {}%",
        "test_percent": "**Porcentagem de dados de teste:** {}%",
        "model_training_section": "ü§ñ Treinamento de Modelos para {}",
        "training_spinner": "Treinando modelos para {}...",
        "training_complete_success": "‚úÖ Modelos treinados com sucesso para {}",
        "metrics_section": "üìä M√©tricas de Desempenho",
        "training_times_section": "‚è±Ô∏è Tempos de Treinamento",
        "model_label": "Modelo",
        "time_seconds_label": "Tempo (segundos)",
        "statistical_tests_section": "üìà Testes Estat√≠sticos Inferenciais",
        "statistical_tests_spinner": "Realizando testes estat√≠sticos para {}...",
        "residuals_normality_test": "Teste de Normalidade dos Res√≠duos:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-valor = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-valor = {:.4f} ({})",
        "normal_interpretation": "‚úÖ Normal",
        "not_normal_interpretation": "‚ùå N√£o Normal",
        "shapiro_wilk_error": "{}: Shapiro-Wilk n√£o p√¥de ser executado: {}",
        "zero_std_error": "{}: Res√≠duos com desvio padr√£o zero (todos os valores s√£o iguais), o teste de normalidade n√£o pode ser realizado.",
        "no_statistical_results": "Nenhum resultado de teste estat√≠stico encontrado para {}.",
        "evaluation_complete_success": "üéâ Avalia√ß√£o de modelos conclu√≠da para todas as vari√°veis alvo.",
        "download_reports_section": "üìÑ Baixar Relat√≥rios PDF",
        "download_pdf_link": "üì• Baixar Relat√≥rio PDF para {}",
        "pdf_generation_error": "Erro ao gerar ou baixar o relat√≥rio PDF para {}: {}",
        "dataset_load_error": "N√£o foi poss√≠vel carregar o conjunto de dados. Verifique se o arquivo 'datos_pacientes.csv' est√° na pasta correta.",
        "training_linear_regression": "üîÑ Treinando Regress√£o Linear...",
        "training_random_forest": "üîÑ Treinando Random Forest...",
        "training_xgboost": "üîÑ Treinando XGBoost...",
        "processed_columns": "Colunas processadas:",
        "residuals_histogram_title": "Histograma de Res√≠duos para {}",
        "qq_plot_title": "Gr√°fico Q-Q de Res√≠duos para {}",
        "residuals_vs_predictions_title": "Res√≠duos vs. Previs√µes para {}",
        "residuals_label": "Res√≠duos",
        "frequency_label": "Frequ√™ncia",
        "predicted_values_label": "Valores Previstos",
        "friedman_test_heading": "Teste de Friedman",
        "friedman_result": "Resultado do teste de Friedman: Qui-quadrado = {:.4f}, p-valor = {:.4f} ({})",
        "friedman_significant": "Significativo",
        "friedman_not_significant_interpret": "N√£o Significativo",
        "friedman_not_enough_models": "S√£o necess√°rios pelo menos 3 modelos para executar o teste de Friedman.",
        "friedman_data_error": "Erro ao preparar os dados para Friedman: {}",
        "friedman_error": "Erro ao executar o teste de Friedman: {}",
        "friedman_not_significant": "O teste de Friedman n√£o foi significativo, nenhum teste post-hoc realizado.",
        "posthoc_heading": "Testes Post-Hoc (Nemenyi)",
        "nemenyi_intro": "Resultados do teste post-hoc de Nemenyi (valores p):",
        "pdf_friedman_test_heading": "TESTE DE FRIEDMAN",
        "pdf_friedman_result": "Estat√≠stica Qui-quadrado = {:.4f}, p-valor = {:.4f} ({})",
        "pdf_posthoc_heading": "TESTES POST-HOC (NEMENYI)",
        "pdf_nemenyi_intro": "Resultados do teste post-hoc de Nemenyi (valores p):",
        "pdf_no_friedman_results": "O teste de Friedman n√£o p√¥de ser executado.",
        "pdf_no_posthoc_results": "Nenhum resultado de teste post-hoc encontrado (Friedman n√£o foi significativo ou ocorreu um erro).",

        # PDF Strings
        "pdf_report_title": "RELAT√ìRIO DE AVALIA√á√ÉO DE MODELOS ML - {}",
        "pdf_report_subtitle": "Avalia√ß√£o Nutricional Antropom√©trica",
        "pdf_equipment_heading": "CARACTER√çSTICAS DO EQUIPAMENTO DE PROCESSAMENTO",
        "pdf_component_header": "Componente",
        "pdf_specification_header": "Especifica√ß√£o",
        "pdf_processor": "Processador",
        "pdf_ram": "RAM instalada",
        "pdf_storage": "Armazenamento",
        "pdf_gpu": "Placa gr√°fica",
        "pdf_dataset_info_heading": "INFORMA√á√ïES DO CONJUNTO DE DADOS",
        "pdf_num_records": "N√∫mero de registros: {}",
        "pdf_num_features": "N√∫mero de caracter√≠sticas: {}",
        "pdf_train_percent": "Porcentagem de treinamento: {:.2f}%",
        "pdf_test_percent": "Porcentagem de teste: {:.2f}%",
        "pdf_training_times_heading": "TEMPOS DE TREINAMENTO",
        "pdf_metrics_heading": "M√âTRICAS DE DESEMPENHO",
        "pdf_model_header": "Modelo",
        "pdf_time_seconds_header": "Tempo (segundos)",
        "pdf_mse": "MSE",
        "pdf_rmse": "RMSE",
        "pdf_mae": "MAE",
        "pdf_r2": "R¬≤",
        "pdf_statistical_tests_heading": "TESTES ESTAT√çSTICOS INFERENCIAIS",
        "pdf_residuals_normality_heading": "Teste de Normalidade dos Res√≠duos:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-valor = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-valor = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk n√£o p√¥de ser executado: {}",
        "pdf_zero_std_note": "{}: Res√≠duos com desvio padr√£o zero (todos os valores s√£o iguais), o teste de normalidade n√£o pode ser realizado.",
        "pdf_no_stats_found": "Nenhum resultado de teste estat√≠stico encontrado para {}.",
        "pdf_additional_visualizations": "VISUALIZA√á√ïES ADICIONAIS",
        "pdf_confusion_matrices": "Matrizes de Confus√£o",
        "pdf_confusion_matrix_for": "Matriz de Confus√£o para {}:",
        "pdf_confusion_matrix_warning": "Aviso: Matriz de Confus√£o para {} n√£o encontrada em {}",
        "pdf_performance_graphs": "Gr√°ficos de Desempenho do Modelo",
        "pdf_graphs_for_model": "Gr√°ficos para {} ({}):",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Aviso: Gr√°fico '{}' para {} n√£o encontrado em {}",
        "pdf_target_suffix_warning": "Aviso: Nenhum sufixo encontrado para o alvo '{}'. Gr√°ficos espec√≠ficos n√£o ser√£o adicionados.",
        "pdf_residuals_graphs_heading": "GR√ÅFICOS DE RES√çDUOS"
    },
    "ko": { # Korean
        "page_title": "ML Î™®Îç∏ ÌèâÍ∞Ä - ÏòÅÏñë ÌèâÍ∞Ä",
        "app_title": "üß¨ Ïù∏Ï≤¥ Ï∏°Ï†ï ÏòÅÏñë ÌèâÍ∞ÄÎ•º ÏúÑÌïú ML Î™®Îç∏ ÌèâÍ∞Ä",
        "app_description": "---",
        "sidebar_title": "‚öôÔ∏è ÏÑ§Ï†ï",
        "select_language_label": "Ïñ∏Ïñ¥ ÏÑ†ÌÉù:",
        "data_load_section": "Îç∞Ïù¥ÌÑ∞ Î°úÎìú",
        "data_loaded_success": "‚úÖ Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏÑ±Í≥µ",
        "records_label": "üìä Í∏∞Î°ù:",
        "columns_label": "üìã Ïó¥:",
        "file_not_found_error": "ÌòÑÏû¨ Ìè¥ÎçîÏóêÏÑú 'datos_pacientes2.csv' ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.",
        "file_load_error": "ÌååÏùº Î°úÎìú Ïò§Î•ò: {}",
        "dataset_info_section": "üìã Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ïÎ≥¥",
        "first_rows_label": "**Ï≤´ 5Ìñâ:**",
        "statistical_info_label": "**ÌÜµÍ≥Ñ Ï†ïÎ≥¥:**",
        "target_variables_section": "üéØ ÎåÄÏÉÅ Î≥ÄÏàò ÌèâÍ∞Ä",
        "start_evaluation_button": "üöÄ Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë",
        "preprocessing_spinner": "Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ Ï§ë...",
        "column_not_found_error": "Ï≤òÎ¶¨Îêú Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ïó¥ '{}'ÏùÑ(Î•º) Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.",
        "data_split_section": "üóÇÔ∏è {} Ïóê ÎåÄÌïú Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†",
        "train_percent": "**ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ ÎπÑÏú®:** {}%",
        "test_percent": "**ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÎπÑÏú®:** {}%",
        "model_training_section": "ü§ñ {} Ïóê ÎåÄÌïú Î™®Îç∏ ÌõàÎ†®",
        "training_spinner": "{} Ïóê ÎåÄÌïú Î™®Îç∏ ÌõàÎ†® Ï§ë...",
        "training_complete_success": "‚úÖ {} Ïóê ÎåÄÌïú Î™®Îç∏ ÌõàÎ†® ÏÑ±Í≥µ",
        "metrics_section": "üìä ÏÑ±Îä• ÏßÄÌëú",
        "training_times_section": "‚è±Ô∏è ÌõàÎ†® ÏãúÍ∞Ñ",
        "model_label": "Î™®Îç∏",
        "time_seconds_label": "ÏãúÍ∞Ñ (Ï¥à)",
        "statistical_tests_section": "üìà Ï∂îÎ°† ÌÜµÍ≥Ñ ÌÖåÏä§Ìä∏",
        "statistical_tests_spinner": "{} Ïóê ÎåÄÌïú ÌÜµÍ≥Ñ ÌÖåÏä§Ìä∏ ÏàòÌñâ Ï§ë...",
        "residuals_normality_test": "ÏûîÏ∞® Ï†ïÍ∑úÏÑ± ÌÖåÏä§Ìä∏:",
        "shapiro_wilk_test": "{} (Shapiro-Wilk): p-Í∞í = {:.4f} ({})",
        "kolmogorov_smirnov_test": "{} (Kolmogorov-Smirnov): p-Í∞í = {:.4f} ({})",
        "normal_interpretation": "‚úÖ Ï†ïÏÉÅ",
        "not_normal_interpretation": "‚ùå ÎπÑÏ†ïÏÉÅ",
        "shapiro_wilk_error": "{}: Shapiro-Wilk ÏùÑ(Î•º) ÏàòÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§: {}",
        "zero_std_error": "{}: ÏûîÏ∞®Ïùò ÌëúÏ§Ä Ìé∏Ï∞®Í∞Ä 0ÏûÖÎãàÎã§ (Î™®Îì† Í∞íÏù¥ ÎèôÏùºÌï®). Ï†ïÍ∑úÏÑ± ÌÖåÏä§Ìä∏Î•º ÏàòÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§.",
        "no_statistical_results": "{} Ïóê ÎåÄÌïú ÌÜµÍ≥Ñ ÌÖåÏä§Ìä∏ Í≤∞Í≥ºÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.",
        "evaluation_complete_success": "üéâ Î™®Îì† ÎåÄÏÉÅ Î≥ÄÏàòÏóê ÎåÄÌïú Î™®Îç∏ ÌèâÍ∞ÄÍ∞Ä ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.",
        "download_reports_section": "üìÑ PDF Î≥¥Í≥†ÏÑú Îã§Ïö¥Î°úÎìú",
        "download_pdf_link": "üì• {} Ïóê ÎåÄÌïú PDF Î≥¥Í≥†ÏÑú Îã§Ïö¥Î°úÎìú",
        "pdf_generation_error": "{} Ïóê ÎåÄÌïú PDF Î≥¥Í≥†ÏÑú ÏÉùÏÑ± ÎòêÎäî Îã§Ïö¥Î°úÎìú Ïò§Î•ò: {}",
        "dataset_load_error": "Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§. 'datos_pacientes.csv' ÌååÏùºÏù¥ Ïò¨Î∞îÎ•∏ Ìè¥ÎçîÏóê ÏûàÎäîÏßÄ ÌôïÏù∏ÌïòÏã≠ÏãúÏò§.",
        "training_linear_regression": "üîÑ ÏÑ†Ìòï ÌöåÍ∑Ä ÌõàÎ†® Ï§ë...",
        "training_random_forest": "üîÑ ÎûúÎç§ Ìè¨Î†àÏä§Ìä∏ ÌõàÎ†® Ï§ë...",
        "training_xgboost": "üîÑ XGBoost ÌõàÎ†® Ï§ë...",
        "processed_columns": "Ï≤òÎ¶¨Îêú Ïó¥:",
        "residuals_histogram_title": "{} Ïóê ÎåÄÌïú ÏûîÏ∞® ÌûàÏä§ÌÜ†Í∑∏Îû®",
        "qq_plot_title": "{} Ïóê ÎåÄÌïú ÏûîÏ∞® Q-Q ÌîåÎ°Ø",
        "residuals_vs_predictions_title": "{} Ïóê ÎåÄÌïú ÏûîÏ∞® ÎåÄ ÏòàÏ∏°",
        "residuals_label": "ÏûîÏ∞®",
        "frequency_label": "ÎπàÎèÑ",
        "predicted_values_label": "ÏòàÏ∏° Í∞í",
        "friedman_test_heading": "ÌîÑÎ¶¨ÎìúÎßå ÌÖåÏä§Ìä∏",
        "friedman_result": "ÌîÑÎ¶¨ÎìúÎßå ÌÖåÏä§Ìä∏ Í≤∞Í≥º: Ïπ¥Ïù¥Ï†úÍ≥± = {:.4f}, p-Í∞í = {:.4f} ({})",
        "friedman_significant": "Ïú†ÏùòÎØ∏",
        "friedman_not_significant_interpret": "Ïú†ÏùòÎØ∏ÌïòÏßÄ ÏïäÏùå",
        "friedman_not_enough_models": "ÌîÑÎ¶¨ÎìúÎßå ÌÖåÏä§Ìä∏Î•º Ïã§ÌñâÌïòÎ†§Î©¥ ÏµúÏÜå 3Í∞úÏùò Î™®Îç∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.",
        "friedman_data_error": "ÌîÑÎ¶¨ÎìúÎßå Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ Ï§ë Ïò§Î•ò: {}",
        "friedman_error": "ÌîÑÎ¶¨ÎìúÎßå ÌÖåÏä§Ìä∏ Ïã§Ìñâ Ï§ë Ïò§Î•ò: {}",
        "friedman_not_significant": "ÌîÑÎ¶¨ÎìúÎßå ÌÖåÏä§Ìä∏Í∞Ä Ïú†ÏùòÎØ∏ÌïòÏßÄ ÏïäÏïÑ ÏÇ¨ÌõÑ ÌÖåÏä§Ìä∏Í∞Ä ÏàòÌñâÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.",
        "posthoc_heading": "ÏÇ¨ÌõÑ ÌÖåÏä§Ìä∏ (Nemenyi)",
        "nemenyi_intro": "Nemenyi ÏÇ¨ÌõÑ ÌÖåÏä§Ìä∏ Í≤∞Í≥º (p-Í∞í):",
        "pdf_friedman_test_heading": "ÌîÑÎ¶¨ÎìúÎßå ÌÖåÏä§Ìä∏",
        "pdf_friedman_result": "Ïπ¥Ïù¥Ï†úÍ≥± ÌÜµÍ≥ÑÎüâ = {:.4f}, p-Í∞í = {:.4f} ({})",
        "pdf_posthoc_heading": "ÏÇ¨ÌõÑ ÌÖåÏä§Ìä∏ (NEMENYI)",
        "pdf_nemenyi_intro": "Nemenyi ÏÇ¨ÌõÑ ÌÖåÏä§Ìä∏ Í≤∞Í≥º (p-Í∞í):",
        "pdf_no_friedman_results": "ÌîÑÎ¶¨ÎìúÎßå ÌÖåÏä§Ìä∏Î•º Ïã§ÌñâÌï† Ïàò ÏóÜÏóàÏäµÎãàÎã§.",
        "pdf_no_posthoc_results": "ÏÇ¨ÌõÑ ÌÖåÏä§Ìä∏ Í≤∞Í≥ºÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ (ÌîÑÎ¶¨ÎìúÎßå ÌÖåÏä§Ìä∏Í∞Ä Ïú†ÏùòÎØ∏ÌïòÏßÄ ÏïäÍ±∞ÎÇò Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§).",

        # PDF Strings
        "pdf_report_title": "ML Î™®Îç∏ ÌèâÍ∞Ä Î≥¥Í≥†ÏÑú - {}",
        "pdf_report_subtitle": "Ïù∏Ï≤¥ Ï∏°Ï†ï ÏòÅÏñë ÌèâÍ∞Ä",
        "pdf_equipment_heading": "Ï≤òÎ¶¨ Ïû•ÎπÑ ÌäπÏÑ±",
        "pdf_component_header": "Íµ¨ÏÑ± ÏöîÏÜå",
        "pdf_specification_header": "ÏÇ¨Ïñë",
        "pdf_processor": "ÌîÑÎ°úÏÑ∏ÏÑú",
        "pdf_ram": "ÏÑ§ÏπòÎêú RAM",
        "pdf_storage": "Ï†ÄÏû• Í≥µÍ∞Ñ",
        "pdf_gpu": "Í∑∏ÎûòÌîΩ Ïπ¥Îìú",
        "pdf_dataset_info_heading": "Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ïÎ≥¥",
        "pdf_num_records": "Í∏∞Î°ù Ïàò: {}",
        "pdf_num_features": "ÌäπÏßï Ïàò: {}",
        "pdf_train_percent": "ÌõàÎ†® ÎπÑÏú®: {:.2f}%",
        "pdf_test_percent": "ÌÖåÏä§Ìä∏ ÎπÑÏú®: {:.2f}%",
        "pdf_training_times_heading": "ÌõàÎ†® ÏãúÍ∞Ñ",
        "pdf_metrics_heading": "ÏÑ±Îä• ÏßÄÌëú",
        "pdf_model_header": "Î™®Îç∏",
        "pdf_time_seconds_header": "ÏãúÍ∞Ñ (Ï¥à)",
        "pdf_mse": "ÌèâÍ∑† Ï†úÍ≥± Ïò§Ï∞® (MSE)",
        "pdf_rmse": "ÌèâÍ∑† Ï†úÍ≥±Í∑º Ïò§Ï∞® (RMSE)",
        "pdf_mae": "ÌèâÍ∑† Ï†àÎåÄ Ïò§Ï∞® (MAE)",
        "pdf_r2": "Í≤∞Ï†ï Í≥ÑÏàò (R¬≤)",
        "pdf_statistical_tests_heading": "Ï∂îÎ°† ÌÜµÍ≥Ñ ÌÖåÏä§Ìä∏",
        "pdf_residuals_normality_heading": "ÏûîÏ∞® Ï†ïÍ∑úÏÑ± ÌÖåÏä§Ìä∏:",
        "pdf_shapiro_wilk_result": "{} (Shapiro-Wilk): p-Í∞í = {:.4f} ({})",
        "pdf_kolmogorov_smirnov_result": "{} (Kolmogorov-Smirnov): p-Í∞í = {:.4f} ({})",
        "pdf_shapiro_wilk_note": "{}: Shapiro-Wilk ÏùÑ(Î•º) ÏàòÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§: {}",
        "pdf_zero_std_note": "{}: ÏûîÏ∞®Ïùò ÌëúÏ§Ä Ìé∏Ï∞®Í∞Ä 0ÏûÖÎãàÎã§ (Î™®Îì† Í∞íÏù¥ ÎèôÏùºÌï®). Ï†ïÍ∑úÏÑ± ÌÖåÏä§Ìä∏Î•º ÏàòÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§.",
        "pdf_no_stats_found": "{} Ïóê ÎåÄÌïú ÌÜµÍ≥Ñ ÌÖåÏä§Ìä∏ Í≤∞Í≥ºÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.",
        "pdf_additional_visualizations": "Ï∂îÍ∞Ä ÏãúÍ∞ÅÌôî",
        "pdf_confusion_matrices": "ÌòºÎèô ÌñâÎ†¨",
        "pdf_confusion_matrix_for": "{} Ïóê ÎåÄÌïú ÌòºÎèô ÌñâÎ†¨:",
        "pdf_confusion_matrix_warning": "Í≤ΩÍ≥†: {} ÏóêÏÑú {} Ïóê ÎåÄÌïú ÌòºÎèô ÌñâÎ†¨ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§",
        "pdf_performance_graphs": "Î™®Îç∏ ÏÑ±Îä• Í∑∏ÎûòÌîÑ",
        "pdf_graphs_for_model": "{} ({}) Ïóê ÎåÄÌïú Í∑∏ÎûòÌîÑ:",
        "pdf_graph_title_prefix": "- {}:",
        "pdf_graph_warning": "Í≤ΩÍ≥†: {} ÏóêÏÑú {} Ïóê ÎåÄÌïú '{}' Í∑∏ÎûòÌîÑÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§",
        "pdf_target_suffix_warning": "Í≤ΩÍ≥†: ÎåÄÏÉÅ '{}' Ïóê ÎåÄÌïú Ï†ëÎØ∏ÏÇ¨Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. ÌäπÏ†ï Í∑∏ÎûòÌîÑÎäî Ï∂îÍ∞ÄÎêòÏßÄ ÏïäÏäµÎãàÎã§.",
        "pdf_residuals_graphs_heading": "ÏûîÏ∞® Í∑∏ÎûòÌîÑ"
    }
}

# --- Initialize session state for language if not already set ---
if 'lang' not in st.session_state:
    st.session_state.lang = "es" # Default to Spanish

current_lang = LANGUAGES[st.session_state.lang]

# Configuraci√≥n de la p√°gina (needs to be here to use current_lang)
st.set_page_config(
    page_title=current_lang["page_title"],
    page_icon="üß¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title(current_lang["app_title"])
st.markdown(current_lang["app_description"])

# --- Funciones auxiliares ---
@st.cache_data
def load_data(current_lang):
    """Cargar datos del CSV"""
    try:
        df = pd.read_csv('datos_pacientes2.csv')
        return df
    except FileNotFoundError:
        st.error(current_lang["file_not_found_error"])
        return None
    except Exception as e:
        st.error(current_lang["file_load_error"].format(str(e)))
        return None

def preprocess_data(df, current_lang):
    """Preprocesamiento de datos"""
    df_processed = df.copy()

    # Codificar variables categ√≥ricas
    label_encoders = {}
    for column in df_processed.columns:
        if df_processed[column].dtype == 'object':
            le = LabelEncoder()
            df_processed[column] = le.fit_transform(df_processed[column].astype(str))
            label_encoders[column] = le

    # Manejar valores nulos
    df_processed = df_processed.fillna(df_processed.mean(numeric_only=True))
    
    st.write(current_lang["processed_columns"], df_processed.columns.tolist())
    
    return df_processed, label_encoders

def train_models(X_train, X_test, y_train, y_test, current_lang):
    """Entrenar los modelos y medir tiempos"""
    models = {}
    training_times = {}
    predictions = {}
    metrics = {}
    
    # Regresi√≥n Lineal
    st.write(current_lang["training_linear_regression"])
    start_time = time.time()
    lr_model = LinearRegression()
    lr_model.fit(X_train, y_train)
    training_times['Regresi√≥n Lineal'] = time.time() - start_time
    
    lr_pred = lr_model.predict(X_test)
    models['Regresi√≥n Lineal'] = lr_model
    predictions['Regresi√≥n Lineal'] = lr_pred
    
    # Random Forest
    st.write(current_lang["training_random_forest"])
    start_time = time.time()
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)
    training_times['Random Forest'] = time.time() - start_time
    
    rf_pred = rf_model.predict(X_test)
    models['Random Forest'] = rf_model
    predictions['Random Forest'] = rf_pred
    
    # XGBoost
    st.write(current_lang["training_xgboost"])
    start_time = time.time()
    xgb_model = XGBRegressor(random_state=42)
    xgb_model.fit(X_train, y_train)
    training_times['XGBoost'] = time.time() - start_time
    
    xgb_pred = xgb_model.predict(X_test)
    models['XGBoost'] = xgb_model
    predictions['XGBoost'] = xgb_pred
    
    # Calcular m√©tricas
    for name, pred in predictions.items():
        mse = mean_squared_error(y_test, pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, pred)
        r2 = r2_score(y_test, pred)
        
        metrics[name] = {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'R¬≤': r2
        }
    
    return models, predictions, metrics, training_times

def statistical_tests(predictions, y_test, current_lang):
    """Realizar pruebas estad√≠sticas inferenciales, incluyendo Friedman y post-hoc."""
    results = {}
    
    st.write(current_lang["statistical_tests_spinner"].format("")) # General message for tests
    
    # --- Pruebas de normalidad de residuos (ya existentes) ---
    for name, pred in predictions.items():
        residuals = y_test - pred
        
        if len(residuals) <= 5000 and len(residuals) > 3:
            try:
                shapiro_stat, shapiro_p = stats.shapiro(residuals)
                results[name] = {
                    'shapiro_stat': shapiro_stat,
                    'shapiro_p': shapiro_p,
                    'test': 'Shapiro-Wilk'
                }
            except Exception as e:
                results[name] = {
                    'note': current_lang["shapiro_wilk_error"].format(name, str(e)),
                    'test': 'N/A'
                }
        else: # Para N > 5000, usamos Kolmogorov-Smirnov
            if residuals.std() > 0:
                ks_stat, ks_p = stats.kstest(residuals, 'norm', args=(residuals.mean(), residuals.std()))
                results[name] = {
                    'ks_stat': ks_stat,
                    'ks_p': ks_p,
                    'test': 'Kolmogorov-Smirnov'
                }
            else:
                results[name] = {
                    'note': current_lang["zero_std_error"].format(name),
                    'test': 'N/A'
                }
    
    # --- Prueba de Friedman y Post-Hoc ---
    model_names = list(predictions.keys())
    
    if len(model_names) >= 3: # Friedman requiere al menos 3 grupos
        try:
            # Step 1: Collect absolute errors for each model, ensuring they align by index
            # This is the correct way to build the DataFrame for scikit-posthocs
            df_errors_for_friedman = pd.DataFrame({
                name: np.abs(y_test - predictions[name]) for name in model_names
            })
            
            # Check if all columns have the same number of rows as y_test
            if not df_errors_for_friedman.empty and df_errors_for_friedman.shape[0] == len(y_test):
                # The data for scipy.stats.friedmanchisquare should be unpacked as separate arrays
                # You can get this by converting the DataFrame to a list of its column arrays
                data_for_scipy_friedman = [df_errors_for_friedman[col].values for col in df_errors_for_friedman.columns]

                friedman_stat, friedman_p = stats.friedmanchisquare(*data_for_scipy_friedman) # Unpack the list of arrays
                
                results['Friedman'] = {
                    'stat': friedman_stat,
                    'p_value': friedman_p,
                    'model_names': model_names # Guardar nombres para referencia
                }

                # If Friedman is significant, execute post-hoc tests (Nemenyi)
                if friedman_p < 0.05:
                    # sp.posthoc_nemenyi_friedman works directly with the DataFrame of errors
                    # Rows are observations, columns are groups (models)
                    posthoc_df = sp.posthoc_nemenyi_friedman(df_errors_for_friedman)
                    
                    posthoc_df.columns = model_names
                    posthoc_df.index = model_names
                    results['Nemenyi_posthoc'] = posthoc_df.to_string() # Guardar como string para el PDF
                else:
                    results['Nemenyi_posthoc'] = current_lang["friedman_not_significant"]

            else:
                results['Friedman'] = {
                    'note': current_lang["friedman_data_error"].format("longitudes de datos diferentes o DataFrame vac√≠o")
                }

        except Exception as e:
            results['Friedman'] = {'note': current_lang["friedman_error"].format(str(e))}
    else:
        results['Friedman'] = {'note': current_lang["friedman_not_enough_models"]}

    return results


def add_images_to_pdf(story, styles, target_name, current_lang):
    """Agrega im√°genes al PDF desde las rutas especificadas."""
    story.append(Spacer(1, 24))
    story.append(Paragraph(current_lang["pdf_additional_visualizations"], styles['Heading2']))
    
    model_folder_map = {
        'Regresi√≥n Lineal': 'RegresionLinealMulti',
        'Random Forest': 'RandomForest',
        'XGBoost': 'XGBoost'
    }

    target_suffix_map = {
        'Valoracion_Talla_Edad': 'talla_edad',
        'Valoracion_IMC_Talla': 'imc_talla'
    }
    
    current_target_suffix = target_suffix_map.get(target_name, '').lower()

    # --- Matrices de Confusi√≥n ---
    story.append(Spacer(1, 12))
    story.append(Paragraph(current_lang["pdf_confusion_matrices"], styles['Heading3']))
    
    confusion_matrix_files = {
        'Regresi√≥n Lineal': 'confusion_regresion.png',
        'Random Forest': 'confusion_randomforest.png',
        'XGBoost': 'confusion_xgboost.png'
    }

    for model_name, filename in confusion_matrix_files.items():
        filepath = os.path.join('confusion_matrices', filename)
        if os.path.exists(filepath):
            story.append(Paragraph(current_lang["pdf_confusion_matrix_for"].format(model_name), styles['Normal']))
            img = Image(filepath, width=3.5 * inch, height=3.0 * inch)
            story.append(img)
            story.append(Spacer(1, 6))
        else:
            story.append(Paragraph(current_lang["pdf_confusion_matrix_warning"].format(model_name, filepath), styles['Normal']))
            story.append(Spacer(1, 6))

    # --- Gr√°ficos de Rendimiento Espec√≠ficos por Modelo ---
    story.append(Spacer(1, 18))
    story.append(Paragraph(current_lang["pdf_performance_graphs"], styles['Heading3']))

    for model_name, folder_name in model_folder_map.items():
        if current_target_suffix:
            story.append(Spacer(1, 12))
            story.append(Paragraph(current_lang["pdf_graphs_for_model"].format(model_name, target_name.replace('_', ' ')), styles['Heading4']))
            
            plot_types = [
                f'Curvas_precision_recall_multiclase_modelo_{current_target_suffix}.png',
                f'Curvas_roc_multiclase_modelo_{current_target_suffix}.png',
                f'Graficos_calibracion_{current_target_suffix}.png'
            ]

            for plot_file in plot_types:
                filepath = os.path.join('Graficas', folder_name, plot_file)
                if os.path.exists(filepath):
                    friendly_title = plot_file.replace('_', ' ').replace('.png', '').replace(f'modelo {current_target_suffix}', '').strip()
                    story.append(Paragraph(current_lang["pdf_graph_title_prefix"].format(friendly_title), styles['Normal']))
                    img = Image(filepath, width=5.0 * inch, height=3.5 * inch)
                    story.append(img)
                    story.append(Spacer(1, 6))
                else:
                    story.append(Paragraph(current_lang["pdf_graph_warning"].format(plot_file, model_name, filepath), styles['Normal']))
                    story.append(Spacer(1, 6))
        else:
            story.append(Paragraph(current_lang["pdf_target_suffix_warning"].format(target_name), styles['Normal']))
            story.append(Spacer(1, 6))
    
    # --- NUEVO: Gr√°ficos de Residuos ---
    story.append(Spacer(1, 18))
    story.append(Paragraph(current_lang["pdf_residuals_graphs_heading"], styles['Heading3']))

    # Mapeo de nombres de modelo a nombres de archivo para los nuevos gr√°ficos de residuos
    # Aseg√∫rate de que estos nombres de archivo coincidan con los generados en generate_residual_plots
    residual_plot_types = {
        'histograma_residuos': current_lang["residuals_histogram_title"].format(""),
        'qq_plot_residuos': current_lang["qq_plot_title"].format(""),
        'residuos_vs_predicciones': current_lang["residuals_vs_predictions_title"].format("")
    }

    if current_target_suffix: # Asegura que tenemos un sufijo de objetivo v√°lido
        for model_name_raw, folder_name in model_folder_map.items():
            model_name_safe = model_name_raw.replace(" ", "_").lower()
            story.append(Spacer(1, 12))
            story.append(Paragraph(current_lang["pdf_graphs_for_model"].format(model_name_raw, target_name.replace('_', ' ')), styles['Heading4']))

            for plot_file_prefix, plot_title_template in residual_plot_types.items():
                filepath = os.path.join('Graficas', f'Residuals_{current_target_suffix}', folder_name, 
                                        f'{plot_file_prefix}_{model_name_safe}_{current_target_suffix}.png')
                
                if os.path.exists(filepath):
                    # Solo necesitas el nombre del modelo aqu√≠ para el t√≠tulo
                    friendly_title = plot_title_template.replace("{}", model_name_raw) 
                    story.append(Paragraph(current_lang["pdf_graph_title_prefix"].format(friendly_title), styles['Normal']))
                    img = Image(filepath, width=5.0 * inch, height=3.5 * inch)
                    story.append(img)
                    story.append(Spacer(1, 6))
                else:
                    story.append(Paragraph(current_lang["pdf_graph_warning"].format(f"{plot_file_prefix}_{model_name_safe}_{current_target_suffix}.png", model_name_raw, filepath), styles['Normal']))
                    story.append(Spacer(1, 6))
    else:
        story.append(Paragraph(current_lang["pdf_target_suffix_warning"].format(target_name), styles['Normal']))
        story.append(Spacer(1, 6))
    # --- FIN NUEVO ---

def generate_residual_plots(predictions, y_test, target_name, current_lang):
    """
    Genera histogramas, Q-Q plots y gr√°ficos de residuos vs. predicciones
    para cada modelo y guarda las im√°genes en la carpeta Graficas.
    """
    plots_saved_paths = []
    
    # Mapeo de nombres de modelo a nombres de carpeta
    model_folder_map = {
        'Regresi√≥n Lineal': 'RegresionLinealMulti',
        'Random Forest': 'RandomForest',
        'XGBoost': 'XGBoost'
    }

    # Definir sufijo para las carpetas dentro de Graficas
    target_suffix = {
        'Valoracion_Talla_Edad': 'talla_edad',
        'Valoracion_IMC_Talla': 'imc_talla'
    }.get(target_name, target_name.lower().replace('_', ''))

    base_dir = os.path.join('Graficas', f'Residuals_{target_suffix}')
    os.makedirs(base_dir, exist_ok=True) # Asegurarse de que la carpeta base exista

    for model_name, pred in predictions.items():
        residuals = y_test - pred
        
        # Obtener la carpeta espec√≠fica del modelo dentro de 'Graficas'
        model_sub_folder = model_folder_map.get(model_name, model_name.replace(' ', ''))
        save_dir = os.path.join(base_dir, model_sub_folder)
        os.makedirs(save_dir, exist_ok=True) # Crear subcarpeta para cada modelo

        # 1. Histograma de Residuos
        plt.figure(figsize=(8, 6))
        sns.histplot(residuals, kde=True)
        plt.title(f'{current_lang["pdf_report_title"].format(target_name.replace("_", " "))}\n{current_lang["residuals_histogram_title"].format(model_name)}')
        plt.xlabel(current_lang["residuals_label"])
        plt.ylabel(current_lang["frequency_label"])
        hist_path = os.path.join(save_dir, f'histograma_residuos_{model_name.replace(" ", "_").lower()}_{target_suffix}.png')
        plt.savefig(hist_path)
        plt.close()
        plots_saved_paths.append(hist_path)

        # 2. Gr√°fico Q-Q
        plt.figure(figsize=(8, 6))
        sm.qqplot(residuals, line='s', fit=True)
        plt.title(f'{current_lang["pdf_report_title"].format(target_name.replace("_", " "))}\n{current_lang["qq_plot_title"].format(model_name)}')
        qq_path = os.path.join(save_dir, f'qq_plot_residuos_{model_name.replace(" ", "_").lower()}_{target_suffix}.png')
        plt.savefig(qq_path)
        plt.close()
        plots_saved_paths.append(qq_path)

        # 3. Gr√°fico de Residuos vs. Predicciones
        plt.figure(figsize=(8, 6))
        plt.scatter(pred, residuals, alpha=0.5)
        plt.axhline(0, color='red', linestyle='--', linewidth=2)
        plt.title(f'{current_lang["pdf_report_title"].format(target_name.replace("_", " "))}\n{current_lang["residuals_vs_predictions_title"].format(model_name)}')
        plt.xlabel(current_lang["predicted_values_label"])
        plt.ylabel(current_lang["residuals_label"])
        plt.grid(True)
        residuals_vs_pred_path = os.path.join(save_dir, f'residuos_vs_predicciones_{model_name.replace(" ", "_").lower()}_{target_suffix}.png')
        plt.savefig(residuals_vs_pred_path)
        plt.close()
        plots_saved_paths.append(residuals_vs_pred_path)
        
    return plots_saved_paths

def create_pdf_report(metrics, training_times, statistical_results, df_info, target_name, train_size_percent, test_size_percent, current_lang):
    """Crear reporte PDF, incluyendo Friedman y post-hoc."""
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []
    
    # T√≠tulo (sin cambios)
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=16,
        spaceAfter=30,
        alignment=1
    )
    
    story.append(Paragraph(current_lang["pdf_report_title"].format(target_name.replace('_', ' ').upper()), title_style))
    story.append(Paragraph(current_lang["pdf_report_subtitle"], styles['Heading2']))
    story.append(Spacer(1, 12))
    
    # Informaci√≥n del equipo (sin cambios)
    story.append(Paragraph(current_lang["pdf_equipment_heading"], styles['Heading2']))
    equipment_data = [
        [current_lang["pdf_component_header"], current_lang["pdf_specification_header"]],
        [current_lang["pdf_processor"], 'Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz'],
        [current_lang["pdf_ram"], '8,00 GB (7,83 GB usable)'],
        [current_lang["pdf_storage"], '932 GB HDD, 238 GB SSD NVMe'],
        [current_lang["pdf_gpu"], 'NVIDIA GeForce GTX 1650 (4 GB)']
    ]
    
    equipment_table = Table(equipment_data, colWidths=[2*inch, 4*inch])
    equipment_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(equipment_table)
    story.append(Spacer(1, 12))
    
    # Informaci√≥n del dataset (sin cambios)
    story.append(Paragraph(current_lang["pdf_dataset_info_heading"], styles['Heading2']))
    story.append(Paragraph(current_lang["pdf_num_records"].format(df_info['rows']), styles['Normal']))
    story.append(Paragraph(current_lang["pdf_num_features"].format(df_info['columns']), styles['Normal']))
    story.append(Paragraph(current_lang["pdf_train_percent"].format(train_size_percent), styles['Normal']))
    story.append(Paragraph(current_lang["pdf_test_percent"].format(test_size_percent), styles['Normal']))
    story.append(Spacer(1, 12))
    
    # Tiempos de entrenamiento (sin cambios)
    story.append(Paragraph(current_lang["pdf_training_times_heading"], styles['Heading2']))
    time_data = [[current_lang["pdf_model_header"], current_lang["pdf_time_seconds_header"]]]
    for model, time_val in training_times.items():
        time_data.append([model, f"{time_val:.4f}"])
    
    time_table = Table(time_data, colWidths=[3*inch, 2*inch])
    time_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(time_table)
    story.append(Spacer(1, 12))
    
    # M√©tricas de rendimiento (sin cambios)
    story.append(Paragraph(current_lang["pdf_metrics_heading"], styles['Heading2']))
    metrics_data = [[current_lang["pdf_model_header"], current_lang["pdf_mse"], current_lang["pdf_rmse"], current_lang["pdf_mae"], current_lang["pdf_r2"]]]
    for model, metric in metrics.items():
        metrics_data.append([
            model,
            f"{metric['MSE']:.4f}",
            f"{metric['RMSE']:.4f}",
            f"{metric['MAE']:.4f}",
            f"{metric['R¬≤']:.4f}"
        ])
    
    metrics_table = Table(metrics_data, colWidths=[1.5*inch, 1*inch, 1*inch, 1*inch, 1*inch])
    metrics_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 9),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(metrics_table)
    story.append(Spacer(1, 12))
    
    # Pruebas estad√≠sticas (modificado para Friedman)
    story.append(Paragraph(current_lang["pdf_statistical_tests_heading"], styles['Heading2']))
    
    story.append(Paragraph(current_lang["pdf_residuals_normality_heading"], styles['Heading3']))
    for model_name_for_stats in metrics.keys(): # Iterar sobre los modelos para la secci√≥n de normalidad
        if model_name_for_stats in statistical_results:
            if 'note' in statistical_results[model_name_for_stats]:
                story.append(Paragraph(statistical_results[model_name_for_stats]['note'], styles['Normal']))
            elif statistical_results[model_name_for_stats]['test'] == 'Shapiro-Wilk':
                p_val = statistical_results[model_name_for_stats]['shapiro_p']
                interpretation = current_lang["normal_interpretation"] if p_val > 0.05 else current_lang["not_normal_interpretation"]
                story.append(Paragraph(current_lang["pdf_shapiro_wilk_result"].format(model_name_for_stats, p_val, interpretation), styles['Normal']))
            else: # Kolmogorov-Smirnov
                p_val = statistical_results[model_name_for_stats]['ks_p']
                interpretation = current_lang["normal_interpretation"] if p_val > 0.05 else current_lang["not_normal_interpretation"]
                story.append(Paragraph(current_lang["pdf_kolmogorov_smirnov_result"].format(model_name_for_stats, p_val, interpretation), styles['Normal']))
        else:
            story.append(Paragraph(current_lang["pdf_no_stats_found"].format(model_name_for_stats), styles['Normal']))
    story.append(Spacer(1, 12))

    # --- NUEVA SECCI√ìN: Prueba de Friedman y Post-Hoc ---
    story.append(Paragraph(current_lang["pdf_friedman_test_heading"], styles['Heading3']))
    if 'Friedman' in statistical_results:
        friedman_res = statistical_results['Friedman']
        if 'note' in friedman_res:
            story.append(Paragraph(friedman_res['note'], styles['Normal']))
        else:
            story.append(Paragraph(current_lang["pdf_friedman_result"].format(
                friedman_res['stat'], friedman_res['p_value'], # Pass the values directly
                current_lang["friedman_significant"] if friedman_res['p_value'] < 0.05 else current_lang["friedman_not_significant_interpret"]
            ), styles['Normal']))
            
            story.append(Spacer(1, 6))
            story.append(Paragraph(current_lang["pdf_posthoc_heading"], styles['Heading4']))
            if 'Nemenyi_posthoc' in statistical_results:
                story.append(Paragraph(current_lang["pdf_nemenyi_intro"], styles['Normal']))
                # Use Preformatted to keep the table-like structure of the string
                story.append(Preformatted(statistical_results['Nemenyi_posthoc'], styles['Code']))
            else:
                story.append(Paragraph(current_lang["pdf_no_posthoc_results"], styles['Normal']))
    else:
        story.append(Paragraph(current_lang["pdf_no_friedman_results"], styles['Normal']))
    story.append(Spacer(1, 12))
    # --- FIN NUEVA SECCI√ìN ---

    # --- AGREGAR IM√ÅGENES AL PDF (sin cambios) ---
    add_images_to_pdf(story, styles, target_name, current_lang) # Pass current_lang to image function

    doc.build(story)
    buffer.seek(0)
    return buffer

# Interfaz principal
def main():
    # Update current_lang at the beginning of main to reflect any language changes from sidebar
    global current_lang
    # Ensure 'lang' is initialized in session_state, defaulting to 'es' if not set
    if 'lang' not in st.session_state:
        st.session_state.lang = "es"
        
    current_lang = LANGUAGES[st.session_state.lang]

    st.sidebar.title(current_lang["sidebar_title"])
    
    # Define the language options to be displayed and their corresponding internal keys
    language_options_display = {
        "Espa√±ol": "es",
        "English": "en",
        "‰∏≠Êñá (Chino)": "zh",
        "Deutsch (Alem√°n)": "de",
        "Êó•Êú¨Ë™û (Japon√©s)": "ja",
        "Fran√ßais (Franc√©s)": "fr",
        "Portugu√™s (Portugu√©s)": "pt",
        "ÌïúÍµ≠Ïñ¥ (Coreano)": "ko"
    }

    # Get the display name for the current language key in session state
    current_lang_display = next(
        (display_name for display_name, lang_key in language_options_display.items()
         if lang_key == st.session_state.lang),
        "Espa√±ol" # Default to 'Espa√±ol' if the current lang key isn't found in display options
    )

    # Language selection selectbox
    language_selection_display = st.sidebar.selectbox(
        current_lang["select_language_label"], # This label should be defined in your LANGUAGES dict
        options=list(language_options_display.keys()),
        index=list(language_options_display.keys()).index(current_lang_display),
        key="language_selection"
    )

    # Get the internal language key based on the user's selection
    selected_lang_key = language_options_display[language_selection_display]

    # If the selected language is different from the current one, update and rerun
    if selected_lang_key != st.session_state.lang:
        st.session_state.lang = selected_lang_key
        st.rerun() # Rerun to update all texts
            
    # Re-fetch current_lang after potential rerun (ensures current_lang is correct after a language change)
    current_lang = LANGUAGES[st.session_state.lang]

    # Cargar datos
    st.subheader(current_lang["data_load_section"])
    df = load_data(current_lang)
    
    if df is not None:
        st.sidebar.success(current_lang["data_loaded_success"])
        st.sidebar.write(current_lang["records_label"].format(df.shape[0]))
        st.sidebar.write(current_lang["columns_label"].format(df.shape[1]))
        
        # Mostrar informaci√≥n del dataset
        st.subheader(current_lang["dataset_info_section"])
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(current_lang["first_rows_label"])
            st.dataframe(df.head())
        
        with col2:
            st.write(current_lang["statistical_info_label"])
            st.dataframe(df.describe())
        
        # Selecci√≥n de variables objetivo
        st.subheader(current_lang["target_variables_section"])
        target_columns = ['Valoracion_Talla_Edad', 'Valoracion_IMC_Talla']

        if "evaluated_data" not in st.session_state:
            st.session_state.evaluated_data = {}

        if st.button(current_lang["start_evaluation_button"], type="primary"):
            st.session_state.evaluated_data = {} # Reset previous data
            # Preprocesar datos
            with st.spinner(current_lang["preprocessing_spinner"]):
                df_processed, label_encoders = preprocess_data(df, current_lang)
                
                # Verificar si las columnas objetivo est√°n en el DataFrame procesado
                for target_column in target_columns:
                    if target_column not in df_processed.columns:
                        st.error(current_lang["column_not_found_error"].format(target_column))
                        return # Exit if column not found

                    # Separar caracter√≠sticas y variable objetivo
                    X = df_processed.drop(columns=[target_column])
                    y = df_processed[target_column]
                    
                    # Divisi√≥n train/test
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=0.2, random_state=42
                    )
                    
                    # Calculate and display train/test percentages
                    train_size_percent = (len(X_train) / len(df_processed)) * 100
                    test_size_percent = (len(X_test) / len(df_processed)) * 100
                    
                    st.write(f"---")
                    st.subheader(current_lang["data_split_section"].format(target_column))
                    st.write(current_lang["train_percent"].format(train_size_percent))
                    st.write(current_lang["test_percent"].format(test_size_percent))
                    st.write(f"---")

                    # Entrenar modelos
                    st.subheader(current_lang["model_training_section"].format(target_column))
                    with st.spinner(current_lang["training_spinner"].format(target_column)):
                        models, predictions, metrics, training_times = train_models(
                            X_train, X_test, y_train, y_test, current_lang
                        )
                    
                    st.success(current_lang["training_complete_success"].format(target_column))
                    
                    # Store results in session state
                    st.session_state.evaluated_data[target_column] = {
                        'metrics': metrics,
                        'training_times': training_times,
                        'predictions': predictions,
                        'y_test': y_test, # Store y_test for statistical tests later
                        'train_size_percent': train_size_percent,
                        'test_size_percent': test_size_percent
                    }
                    
                    # Display metrics immediately after training for visual feedback
                    st.subheader(current_lang["metrics_section"])
                    metrics_df = pd.DataFrame(metrics).T
                    st.dataframe(metrics_df.style.highlight_min(axis=0, subset=['MSE', 'RMSE', 'MAE']).highlight_max(axis=0, subset=['R¬≤']))
                    
                    # Tiempos de entrenamiento
                    st.subheader(current_lang["training_times_section"])
                    time_df = pd.DataFrame(list(training_times.items()), columns=[current_lang["model_label"], current_lang["time_seconds_label"]])
                    st.dataframe(time_df)
                    
                    # Pruebas estad√≠sticas
                    st.subheader(current_lang["statistical_tests_section"])
                    with st.spinner(current_lang["statistical_tests_spinner"].format(target_column)):
                        statistical_results = statistical_tests(predictions, y_test, current_lang)
                    
                    # Display statistical results
                    st.session_state.evaluated_data[target_column]['statistical_results'] = statistical_results
                    for model in models.keys():
                        if model in statistical_results:
                            if 'note' in statistical_results[model]:
                                st.write(f"- {statistical_results[model]['note']}")
                            elif statistical_results[model]['test'] == 'Shapiro-Wilk':
                                p_val = statistical_results[model]['shapiro_p']
                                interpretation = current_lang["normal_interpretation"] if p_val > 0.05 else current_lang["not_normal_interpretation"]
                                st.write(current_lang["shapiro_wilk_test"].format(model, p_val, interpretation))
                            else:
                                p_val = statistical_results[model]['ks_p']
                                interpretation = current_lang["normal_interpretation"] if p_val > 0.05 else current_lang["not_normal_interpretation"]
                                st.write(current_lang["kolmogorov_smirnov_test"].format(model, p_val, interpretation))
                        else:
                            st.write(current_lang["no_statistical_results"].format(model))
                    # --- NUEVO: Generar y guardar gr√°ficos de residuos ---
                    # Guardamos las rutas de los gr√°ficos generados para cada objetivo
                    st.session_state.evaluated_data[target_column]['residual_plots_paths'] = generate_residual_plots(
                        predictions, y_test, target_column, current_lang
                    )
            st.success(current_lang["evaluation_complete_success"])
            st.markdown("---") # Separator after all training is done

        # Display download buttons after all evaluations are done and stored in session_state
        if st.session_state.evaluated_data:
            st.subheader(current_lang["download_reports_section"])
            df_info = {'rows': df.shape[0], 'columns': df.shape[1]}
            for target_column, data in st.session_state.evaluated_data.items():
                metrics = data['metrics']
                training_times = data['training_times']
                statistical_results = data['statistical_results'] # Retrieved from session state
                train_size_percent = data['train_size_percent']
                test_size_percent = data['test_size_percent']

                try:
                    pdf_buffer = create_pdf_report(metrics, training_times, statistical_results, df_info, target_column, train_size_percent, test_size_percent, current_lang)
                    pdf_bytes = pdf_buffer.getvalue()
                    b64 = base64.b64encode(pdf_bytes).decode()
                    href = f'<a href="data:application/pdf;base64,{b64}" download="reporte_evaluacion_modelos_{target_column}.pdf">{current_lang["download_pdf_link"].format(target_column.replace("_", " "))}</a>'
                    st.markdown(href, unsafe_allow_html=True)
                except Exception as e:
                    st.error(current_lang["pdf_generation_error"].format(target_column, str(e)))

    else:
        st.error(current_lang["dataset_load_error"])

if __name__ == "__main__":
    main()